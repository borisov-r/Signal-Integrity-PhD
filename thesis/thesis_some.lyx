#LyX 1.3 created this file. For more info see http://www.lyx.org/
\lyxformat 221
\textclass book
\begin_preamble
\usepackage{lettrine}
\usepackage{hyperref}
\end_preamble
\language english
\inputencoding auto
\fontscheme newcent
\graphics default
\paperfontsize 12
\spacing double 
\papersize a4paper
\paperpackage a4
\use_geometry 1
\use_amsmath 0
\use_natbib 0
\use_numerical_citations 0
\paperorientation portrait
\leftmargin 1.5in
\topmargin 1.6in
\rightmargin 1.2in
\bottommargin 1.6in
\headheight 1.5in
\headsep 0.3in
\footskip 0.8in
\secnumdepth 2
\tocdepth 2
\paragraph_separation skip
\defskip bigskip
\quotes_language english
\quotes_times 2
\papercolumns 1
\papersides 1
\paperpagestyle plain
\bullet 1
	2
	6
	-1
\end_bullet
\bullet 2
	2
	12
	-1
\end_bullet
\bullet 3
	1
	25
	-1
\end_bullet

\layout Title


\series bold 
Unifying Models and Registration:
\newline 
A Framework for Model-based
\newline 
Registration and Non-rigid 
\newline 
Registration Assessment
\begin_inset ERT
status Open

\layout Standard

\backslash 
date{ }
\end_inset 


\layout Author

A thesis submitted to the University of Manchester
\newline 
for the degree of Doctor of Philosophy in the
\newline 
Faculty of Medical and Human Sciences
\newline 
2006
\newline 

\newline 

\newline 
Roy Samuel Schestowitz
\newline 

\newline 
Division of Imaging Science and Biomedical Engineering
\layout Standard
\pagebreak_bottom 

\begin_inset Note
collapsed false

\layout Standard

Use LaTeX and use Davies' thesis as a format model.
 There is already a LyX template that I made.
 Chris says there are strict requirements.
 Kola's thesis Indeed looks similar to Davies'.
\layout Standard

NOTE: BELOW THERE ARE SOME PAGE BREAKS THAT ARE NOT PROPER.
 SEE CONTINUATION REPORT FOR MORE CORRECT ORDER.
\layout Standard

SEE ALL COMMENTS AND CONTENT IN CONTINUATION REPORT AND MERGE CONTENT, ACK.
 et cetera.
\layout Standard

See comments in Reports WWW memo
\layout Standard

Check that quotes appear in all section and are NOT a repeat from Cont.
 Report
\layout Standard

Older title from 2004:
\layout Standard


\series bold 
Model-based Image Registration:
\newline 
Alignment by Minimisation of
\newline 
Statistical Models Complexity
\layout Standard

Plan from August 2005
\layout Standard

I haven't received results from Bill yet.
 He said that all results would be ready "early this week" and we need these
 results for a sanity check.
 I can then begin to focus my full attention on getting resources on which
 to run our experiments.
 I can possibly use my machine at Manchester Computing and have it working
 24/7 (assuming I can compile successfully).
 Either way, I am certain we can find the necessary resources.
\layout Standard

In the mean I have been working on a template for the thesis (I even shared
 that LyX template some days ago it has become popular among the LyX community).
 In that respect, everything is more or less complete apart from text and
 figures.
 I also included some 'skeleton structure', which I think makes a cohesive
 flow of arguments.
 The 'meat' of it all begins with a model-based/MDL objective function,
 resulting models and registration, improving efficiency including reference
 to subsets in construction of optimal shape models.
 It then carries on to 3-D registration and automatic construction of appearance
 models using registration.
 Later we can describe the evaluation of appearance models, assessment of
 registration using the method, results of model evaluation, description
 of a perturbation scheme and some results from evaluation of non-rigid
 registration (in the absence ground truth).
\layout Standard

That's the gist anyway.
 I have plenty of separable videos (registration in 1-D, automatically construct
ed models in 1-D, automatic construction of shape models of the hand and
 the bump, 3-D registration in VXL, model animations of automatically-constructe
d models of the brain, face models evaluated and perturbed...).
 I will produce and convert videos to GIF animations (open format, no codecs
 involved) later today.
 By no means do I hurry towards completion, but the more time we have in
 our hands, the more we can embellish and extend to make the work stand
 out.
\layout Title


\series bold 
\size giant 
\noun on 
Continuation Report
\series default 
\size default 
\noun default 

\newline 

\emph on 
First Year Summary of
\newline 
Progression and Outcomes
\layout Author
\pagebreak_bottom 

\begin_inset Graphics
	filename ./Graphics/UoMLogo.eps
	display none
	scale 17

\end_inset 


\newline 

\begin_inset Graphics
	filename ./Graphics/isbe.eps
	display none
	scale 70

\end_inset 


\newline 

\noun on 
R.
 S.
 Schestowitz
\newline 
Imaging Science and Biomedical Engineering
\newline 
Victoria University of Manchester
\newline 
United Kingdom 
\newline 

\noun default 

\begin_inset Graphics
	filename ./Graphics/normalline.eps
	display none
	scale 80

\end_inset 


\series bold 
\noun on 

\newline 

\bar under 
Degree Programme:
\bar default 
 \SpecialChar ~
\SpecialChar ~
\SpecialChar ~
\SpecialChar ~
Ph.
 D.
 Medical Biophysics
\newline 

\bar under 
Project Supervisor:
\bar default 
\SpecialChar ~
\SpecialChar ~
\SpecialChar ~
\SpecialChar ~
C.
 J.
 Taylor\SpecialChar ~
\SpecialChar ~
\SpecialChar ~
\SpecialChar ~
\SpecialChar ~
\SpecialChar ~
\SpecialChar ~
\SpecialChar ~
\SpecialChar ~
\SpecialChar ~
\SpecialChar ~
\SpecialChar ~
\SpecialChar ~
\SpecialChar ~
\SpecialChar ~
\SpecialChar ~
\SpecialChar ~
\SpecialChar ~
\SpecialChar ~
\SpecialChar ~
\SpecialChar ~
\SpecialChar ~
\SpecialChar ~
\SpecialChar ~
\SpecialChar ~
\SpecialChar ~
\SpecialChar ~
\SpecialChar ~
\SpecialChar ~
\SpecialChar ~

\end_inset 


\layout Standard
\paragraph_spacing single 
\pagebreak_bottom 

\begin_inset LatexCommand \index{Table of Contents}

\end_inset 


\size footnotesize 

\begin_inset LatexCommand \tableofcontents{}

\end_inset 


\layout Standard
\paragraph_spacing single 
\pagebreak_bottom 

\begin_inset LatexCommand \index{List of Figures}

\end_inset 


\size small 

\begin_inset FloatList figure

\end_inset 


\begin_inset Note
collapsed false

\layout Standard
\paragraph_spacing other 2.20 


\begin_inset LatexCommand \index{Index}

\end_inset 


\begin_inset LatexCommand \printindex{}

\end_inset 


\layout Standard
\pagebreak_bottom 

\begin_inset Note
collapsed false

\layout Standard

A blank chapter to fix headings in subsequent parts was attempted but replaced
 by index since it did not work.
\end_inset 


\layout Standard
\paragraph_spacing single 
\pagebreak_bottom 

\begin_inset LatexCommand \index{List of Tables}

\end_inset 


\size small 

\begin_inset FloatList table

\end_inset 


\end_inset 


\layout Chapter*


\begin_inset LatexCommand \label{cha:Abstract}

\end_inset 


\begin_inset LatexCommand \index{Abstract}

\end_inset 

Abstract
\layout Standard


\begin_inset Note
collapsed false

\layout Standard

OLD NOTES
\layout Standard

rewrite this -- "potential exists...robust model of appearance": not very insightfu
l.
 Consider using abstract from presentation.
\layout Standard

Structure of the report is too flat
\layout Standard

-- and concise models...
\layout Standard

ONLY ONE BLOCK IN THESIS - ONE PAGE!!!!!!!!!
\end_inset 


\layout Standard

Statistical models of shape and appearance are widely used for the analysis
 of biomedical images.
 Two deficiencies of these models is that they require annotation across
 a large number of images in order to be built and, having built such models,
 it is then difficult to reason about their validity or assess their quality.
 Herein, a method is described which addresses both problems and establishes
 a unified solution.
 In order to construct the models rapidly, corresponding structures must
 be brought into the state of dense overlap.
 Image registration is the mechanism whereby a set of images can be analysed
 in a common frame of reference and models then derived from it.
 The thesis provides a solution to the recurring need to compare such models
 and extends the method as to provide an image registration assessment method,
 which does not require ground truth.
 The thesis also deals with a complementary case where images are registered
 by minimising the complexity of models.
 Overall, the proposed framework can be perceived as one which ucombines
 registration and modelling, taking advantage of the fact that they are
 innately the same.
 Registration provides correspondence across images and, given that corresponden
ce, models of appearance can be built and registration then assessed, without
 the need for ground-truth data.
\layout Standard


\begin_inset Note
collapsed false

\layout Standard

Remainder from continuation report:
\layout Standard

Autonomous construction of robust statistical models has for some time been
 an arduous goal to achieve.
 This is particularly due to the need to establish dense correspondence
 across the training set.
 Numerous attempts have been made to automate the formation of good active
 appearance models, but none has yet been very successful.
 Potential exists, however, in the unification of model construction and
 image registration.
 The evaluation of non-rigid registration, which is based on non-linear
 warps, has been another subject exhibiting great difficulties and automatic
 selection of good warps is far from trivial.
 In active appearance models, the main problem is the inability to select
 good landmark points without human judgement, as well as the difficulty
 in location and annotation of these landmarks using brute-force only.
 Non-rigid registration is a quickly emerging technique that can be used
 to warp multiple data instances and produce a group-wise optimal model.
 Contrariwise, past attempts sought a model which is derived from pair-wise
 registration and therefore depended on an arbitrary choice of a reference.
 These argument quotes highlight the benefits summoned by the combination
 of these two techniques -- active appearance model can aid the selection
 of good warps in non-rigid registration and the functionality of non-rigid
 registration can help obtain more compact and robust models of appearance
 or deformation, as well as diminish the necessity of manual annotation.
 This report outlines some previous work in the field and a summary of the
 current successful progress.
 It also explains some concepts that bear potential or whose realisation
 can contribute to future endeavours and strengthening of the current algorithm.
 Work throughout the year made registration using appearance model practical
 and powerful.
 The selection of warps is driven purely by the quality of a model and the
 warping space itself describes the range of legal deformations.
 It is safe to state that the goal of automatic construction of deformation
 models, based on registration, has been comfortably approached.
\end_inset 


\layout Standard


\begin_inset Note
collapsed false

\layout Standard

Earlier sections critically surveys some existing work and techniques.
 Effort is to identify some existing gaps where substantial improvements
 can be still made and describe the research planned with its aims and intermedi
ate milestones.
\layout Standard

Thesis: Put new abstract here.
 One or two pages depending on what RHHD did.
\end_inset 


\layout Chapter*
\pagebreak_top 
Declaration
\layout Standard

No portion of the work referred to in the thesis has been submitted in support
 of an application for another degree or qualification of this or any other
 university or other institute of learning.
\layout Chapter*
\pagebreak_top 
Copyright
\layout Comment

Some longer description here..
\layout Enumerate

Copyright in text of this thesis rests with the Author.
 Copies (by any process) either in full, or of extracts, may be made 
\series bold 
only
\series default 
 in accordance with instructions given by the Author and lodged in the John
 Rylands University Library of Manchester.
 Details may be obtained from the Librarian.
 This page must form part of any such copies made.
 Further copies (by any process) of copies made in accordance with such
 instructions may not be made without permission (in writing) of the Author.
\layout Enumerate

The ownership of any intellectual property rights which may be described
 in this thesis is vested in the University of Manchester, subject to any
 prior agreement to the contrary, and may not be made available for use
 by third parties without the written permission of the University, which
 will prescribe the terms and conditions of any such agreement.
\layout Enumerate

Further information on the conditions under which disclosures and exploitation
 may take place is available from the Head of the Division of Imaging Science
 and Biomedical Engineering.
\layout Chapter*
\pagebreak_top 

\begin_inset LatexCommand \label{cha:Dedication}

\end_inset 

Dedication
\layout Standard

I dedicate this thesis to my grandmother, who passed away amidst my studies.
\layout Chapter*
\pagebreak_top 

\begin_inset LatexCommand \label{cha:Acknowledgements}

\end_inset 


\begin_inset LatexCommand \index{Acknowledgements}

\end_inset 

Acknowledgements
\layout Standard


\begin_inset Note
collapsed false

\layout Standard

I must dearly thank the following individuals:
\layout Standard

* Put Palm Notes here.....
\layout Standard

* ISBE Thesis
\layout Standard

* ACKNOWLEDGEMENTS
\layout Standard

* Acknowledge people in obituary (should be up-to-date)
\layout Standard

* OM Report acknowledgements (ACS, Ian Pratt...)
\layout Standard

* See cont.
 report
\end_inset 


\layout Standard


\begin_inset Note
collapsed false

\layout Standard

....Text from Palm...
\layout Standard

Written in plane.
 Use in Thesis.
\end_inset 


\layout Standard


\begin_inset Note
collapsed false

\layout Standard

THE TEXT BELOW WAS NEVER USED...
 RESERVED FOR THESIS PERHAPS...
\layout Standard

* My supervisor Prof.
 Chris Taylor for making the most out of my abilities and putting in a great
 capacity of time for support.
\layout Standard

* My advisor Prof.
 Williams for giving good advice at all stages of my research.
 
\layout Standard

* Mark O'Leary for allowing me to carry on with all aspects of research
 in the office at work.
\end_inset 


\layout Standard


\begin_inset Note
collapsed false

\layout Standard

Below are doubtful ones
\layout Itemize

??Dr.
 Beatty? ABORTED
\layout Itemize

?Nadav Mor? ABORTED
\layout Itemize

All siblings
\layout Itemize

Mother
\layout Itemize

Grandmother???
\layout Itemize

Anybody else from family?
\layout Itemize

Anybody from gym w.r.t.
 academic advice e.g.
 Chris in Biology? (find out last name)
\end_inset 


\layout Standard


\begin_inset Note
collapsed false

\layout Standard

NEW TEXT BEGINS
\end_inset 


\layout Standard

I would like to express my thanks to:
\layout Itemize

A Supervisor and role model, Chris Taylor, for investing plenty of time
 and effort to make my project a success.
\layout Itemize

My Advisor, Steve Williams, for support, kind words of advice and perpetual
 encouragement.
\layout Itemize

Katherine Smith, Carole Twining, and Stephen Marsland, who initiated much
 of the work which the thesis relates to, as well as builds upon.
\layout Itemize

Tim Cootes, who helped me cope with C++ and VXL (among other technicalities).
 He has always done so while remaining patient and keeping pressure (or
 sense of demand) at a bare minimum.
\layout Itemize

The EPSRC, for funding the project and connecting me with those who are
 involved in the MIAS-IRC.
 This 'umbrella' offered valuable feedback, advice, and a very motivational
 setting.
\layout Itemize

My parents and siblings, as well as my grandfather, Avner Werner Max, for
 full financial support from my very first day at the University.
\layout Itemize

My grandmother, who is no longer among us (passed away in 2005).
 She was a supportive and loving figure in a family which has been volatile
 for the past 2 years.
\layout Itemize

Dr.
 David Baxter, whose advice led me to consider research at Manchester University
 and, more particularly, the division where I ended up enrolling for this
 degree.
\layout Itemize

Prof.
 Tony Hegarty, who urged me to accept an academic route, rather than be
 distracted by the wrong career paths.
\layout Itemize

David Robinson, who offered valuable advice and encouraging words towards
 the end of my Ph.D.
 He was one of those who urged me to put in extra time and rigour, gearing
 up towards completion.
\layout Itemize

Other friends at the health club, who inspired and provided comfort whenever
 things went amiss or uncertainties loomed over.
\layout Itemize

The Open Source community, which enabled this research to be carried out
 using versatile, distributable, Free software.
\layout Itemize

Mathworks, for enabling me to share code in their Web site and thereby reach
 a very wide audience, putting to use some personal programming ambitions.
 Many of my endeavours were boosted by knowledge that the outcome would
 be shared among the MATLAB users community.
\layout Itemize

Roland Selby, Mark O'Leary and several other people at Manchester Computing,
 who permitted me to concentrate on my Ph.D.
 studies while at work.
 They were surprisingly understanding, particularly when pressure was mounting.
\layout Itemize

David Kennedy of the Center for Morphometric Analysis at MGH, for providing
 the fully-annotated brain images.
 Additional images from age-matched normals in a dementia study were generously
 provided by Prof.
 Alan Jackson, University of Manchester.
\layout Standard


\begin_inset Note
collapsed false

\layout Standard

NEW END
\end_inset 


\layout Standard


\begin_inset Note
collapsed false

\layout Standard

What lies below is included in cont.
 rep.
 already in some form or another
\end_inset 


\layout Standard


\begin_inset Note
collapsed false

\layout Standard

OLD TEXT BELOW - CONT.
 REPORT...
 changed slightly
\end_inset 


\layout Chapter*

Publications
\layout Standard

Portions of the work described in this thesis has also appeared in: 
\layout Subsection*

Conference papers
\layout Itemize

Carole Twining, Tim Cootes, Stephen Marsland, Vladimir Petrovic, Roy Schestowitz
, and Chris Taylor.
 A Unified Information-Theoretic Approach to Groupwise Non-Rigid Registration
 and Model Building.
 Presented in 
\emph on 
Information Processing in Medical Images (IPMI)
\emph default 
, Lecture Notes in Computer Science, vol.
 3565, pp.
 1-14, 2005.
\layout Itemize

Tim Cootes, Carole Twining, Vladimir Petrovic, Roy Schestowitz, and Chris
 Taylor.
 Groupwise Construction of Appearance Models using Piece-wise Affine Deformation
s.
 Presented in 
\emph on 
British Machine Vision Conference (BMVC)
\emph default 
, vol.
 2, pp.
 879-888, 2005.
 
\layout Itemize

Roy schestowitz, Carole Twining, Tim Cootes, Vladimir Petrovic, Chris Taylor,
 and Bill Crum.
 Assessing the Accuracy of Non-Rigid Registration With and Without Ground
 Truth.
 In 
\emph on 
IEEE International Symposium on Biomedical Imaging (ISBI)
\emph default 
, 2006.
\layout Itemize

Carole Twining, Tim Cootes, Stephen Marsland, Vladimir Petrovic, Roy schestowitz
, and Chris Taylor.
 Information-Theoretic Unification of Groupwise Non-Rigid Registration and
 Model Building.
 In 
\emph on 
Medical Image Understanding and Analysis (MIUA), 
\emph default 
vol.
 2, pp.
 226-230, 2006
\emph on 
.
\layout Itemize

Roy Schestowitz, Carole Twining, Tim Cootes, Vladimir Petrovic, and Chris
 Taylor.
 A Generic Method for Evaluating Appearance Models.
 Presented in 
\emph on 
Proceedings of MIAS-IRC Plenary Meeting
\emph default 
, 2006.
 
\layout Itemize

Roy schestowitz, Carole Twining, Tim Cootes, Vladimir Petrovic, Bill Crum,
 and Chris Taylor.
 Non-Rigid Registration Assessment Without Ground Truth.
 Presented in 
\emph on 
Medical Image Understanding and Analysis
\emph default 
 
\emph on 
(MIUA)
\emph default 
, vol.
 2, pp.
 151-155, 2006.
\layout Subsection*

Peer-reviewed papers/symposia
\layout Itemize

Roy Schestowitz, Carole Twining, Tim Cootes, and Chris Taylor.
 Image Registration by Model Criteria.
 Presented in 
\emph on 
Proceedings of MIAS-IRC Plenary Meeting
\emph default 
, pp.
 16-17, 2004.
\layout Itemize

Roy Schestowitz, Bill Crum, Vladimir Petrovic, Carole Twining, Tim Cootes,
 and Chris Taylor.
 Assessing the Accuracy of Non-Rigid Registration.
 Presented in 
\emph on 
Proceedings of MIAS-IRC Plenary Meeting
\emph default 
, pp.
 25-26, 2005.
 
\layout Itemize

Vladimir Petrovic, Tim Cootes, Carole Twining, Roy Schestowitz, and Chris
 Taylor.
 Groupwise Construction of Appearance Models using Piece-wise Affine Deformation
s.
 Presented in 
\emph on 
Proceedings of MIAS-IRC Plenary Meeting
\emph default 
, pp.
 21-22, 2005.
 
\layout Subsection*

Journals (submitted, under review)
\layout Itemize

Roy schestowitz, Carole Twining, Vladimir Petrovic, Tim Cootes, Bill Crum,
 and Chris Taylor.
 Evaluating Non-Rigid Registration without Ground Truth.
 
\emph on 
IEEE Transactions on Medical Imaging
\emph default 
.
\layout Standard


\begin_inset Note
collapsed false

\layout Itemize

BMVC 2005
\layout Itemize

ISBI Submission?
\layout Itemize

ECCV?
\layout Itemize

Journal Cootes
\layout Itemize

Journal me?
\layout Itemize

Any submissions in 2006?
\end_inset 


\layout Standard

Code and material produced throughout the project was generalised and publicised
 in the form of utilities and tutorials.
 It received over 35,000 downloads at MATLAB Central and had the author
 ranked 
\begin_inset Formula $1^{st}$
\end_inset 

 in the world at one point.
 This work is now internationally recognised and receives close to 2,000
 downloads per month.
\layout Standard


\begin_inset Note
collapsed false

\layout Standard

REMEMBER ERT 
\backslash 
s for all sections...
 BRING ALL UP-TO-DATE
\end_inset 


\layout Standard
\pagebreak_bottom 

\begin_inset Note
collapsed false

\layout Standard

A blank chapter to fix headings in subsequent parts was attempted but replaced
 by index since it did not work.
\layout Standard


\begin_inset LatexCommand \index{Index}

\end_inset 


\begin_inset LatexCommand \printindex{}

\end_inset 


\end_inset 


\layout Standard


\begin_inset Note
collapsed false

\layout Standard

(NOTE: same as Rhoderi's...
 customise that)
\end_inset 


\layout Chapter*
\pagebreak_top 
Accompanying CD-ROM
\layout Standard

Videos demonstrating parts of the thesis have been put on a supplementary
 CD-ROM.
 This CD-ROM is bound to back cover of this thesis.
 It contains illustrative animations that are sometimes referenced in the
 text.
 The filenames on the CD-ROM are either arbitrary, chronological, or correspond
 to figure/section numbers in the text.
\layout Standard


\begin_inset Note
collapsed false

\layout Standard

old section title: Demonstration Videos
\end_inset 


\layout Standard


\begin_inset Note
collapsed false

\layout Standard

RHHD: The CD-ROM inside the back cover of this thesis contains several animation
s that are referenced in the text.
 The filenames on the CD correspond to the figure numbers in the text:
\end_inset 


\layout Standard


\begin_inset Note
collapsed false

\layout Standard

.......
 and the index follows
\end_inset 


\layout Standard


\begin_inset Note
collapsed false

\layout Standard

AART videos - use ALL different types..
 all on Web - Rotation surface, model modes (from presentation)
\layout Standard

shape models - include hands and bump model examples - animations - several
 for comparison
\layout Standard

Stitch up video of VXL registration (in January 2005) presentation...
\layout Standard

Show model animation - model of brain, model of face, model from hand-annotated
 data (surrey faces and brain), model from auto-built brains using different
 methods (about 6 of these to compare - use Tim's registrations) - also
 show perturbed models!!! Of the face, for example..
\layout Standard

Make copy of CD on hard-drive (maybe compress videos, maybe make them GIF's),
 make copy of CD on WEB!!!
\layout Standard

Build illustrative video for model evaluation???????? Probably unhelpful...
\end_inset 


\layout Standard


\begin_inset Note
collapsed false

\layout Itemize


\series bold 
figure 1.2:
\series default 

\newline 

\family sans 
figure8_2.avi
\layout Itemize


\series bold 
figure 10.2:
\series default 

\newline 

\family sans 
figure10_2_1.avi
\newline 
figure10_2_a.avi
\family default 

\newline 

\newline 

\newline 
...
\end_inset 


\layout Standard


\series bold 
Peripheral files (GIF-formatted):
\newline 

\layout Itemize


\family sans 
p1.gif
\family typewriter 
:
\family default 
\series bold 
 
\series default 
combined model built from the MGH data.
 7 modes of variation are normally (i.e.
 drawn from Gaussian distribution) varied simultaneously.
\layout Itemize


\family sans 
p2.gif:
\family default 
\series bold 
 
\series default 
combined model built from the MGH data.
 10 modes of variation are normally varied simultaneously.
\layout Itemize


\family sans 
p3.gif
\family default 
: the registration assessment framework illustrated schematically
\layout Itemize


\family sans 
p4.gif
\family default 
: discrepancy image (checkerboard-type composition) of 2 brain images.
 The sequence shows the discrepancy image as an SSD-based registration proceeds
 and, in response, the discrepancy image evolves.
\layout Itemize


\family sans 
p5.gif
\family default 
: one-dimensional registration example.
 Rows in the matrix represent intensity vectors (1-D images) being registered
 to the remainder of the vector set in a pair-wise fashion.
 
\layout Standard


\series bold 
Larger peripheral files (compressed or uncompressed AVI format, no proprietary
 codecs required):
\newline 

\layout Itemize


\family sans 
p6.avi:
\family default 
 a set of 10 1-D vectors are being aligned using multi-edge clamped plate
 spline (CPS) warps.
 10 iterations (passes) through the data are shown, unregistered images
 on the left and progressively re-registered images on the right.
\layout Itemize


\family sans 
p7.avi:
\family default 
 a set 10 1-D vectors, as visualised in 3-D space, are being aligned.
 50 iterations through the data are shown in the sequence.
\layout Itemize


\family sans 
p8.avi:
\family default 
 the first and second modes of a combined (shape and intensity) model which
 is automatically built
\layout Itemize


\family sans 
p9.avi:
\family default 
 two 1-D images are being registered.
 Unregistered images are shown on the left and progressively registered
 -- on the right.
\layout Itemize


\family sans 
p10.avi:
\family default 
 1-D vectors being registered using a model-based objective function
\layout Itemize


\family sans 
p11.avi:
\family default 
 10 simplified 1-D vectors, which are composed of 4 edges, are being registered.
 The objective function is based on mean-squared-differences.
\layout Itemize


\family sans 
p12.avi:
\family default 
 10 1-D vectors with are being registered using an objective function that
 based on minimisation of the complexity of a point distribution function
\layout Itemize


\family sans 
p13.avi:
\family default 
 A large number of 1-D vectors (visualised as rows) being registered by
 considering just one vector at a time
\layout Itemize


\family sans 
p14.avi:
\family default 
 automatically-built combined model of a bump.
 The model is built automatically from the raw training set.
\layout Itemize


\family sans 
p15.avi:
\family default 
 A large-scale illustration of 1-D bump registration
\layout Standard


\begin_inset Note
collapsed false

\layout Chapter*
\pagebreak_bottom 

\begin_inset LatexCommand \label{cha:prologue}

\end_inset 


\begin_inset LatexCommand \index{Prologue}

\end_inset 

Prologue
\end_inset 


\layout Chapter*
\pagebreak_top 
Prologue
\layout Standard

\SpecialChar ~
\SpecialChar ~
\SpecialChar ~
\SpecialChar ~
\SpecialChar ~
\SpecialChar ~

\size large 

\begin_inset Quotes eld
\end_inset 

T
\size default 
he
\emph on 
 
\emph default 
classical 
\emph on 
synthesis problem
\emph default 
 of computer graphics can be formulated as the problem of generating novel
 images corresponding to an appropriate set of parameters describing the
 camera viewpoint and aspects of the scene.
 The inverse 
\emph on 
analysis problem
\emph default 
 of estimating object labels as well as scene parameters from images is
 the classical problem of computer vision...
\begin_inset Quotes erd
\end_inset 


\layout Standard
\align right 
-- 
\emph on 
David
\emph default 
 
\emph on 
Beymer
\emph default 
 
\begin_inset LatexCommand \cite{Beymer_Poggio}

\end_inset 


\emph on 
.
\layout Standard
\pagebreak_bottom 

\begin_inset Note
collapsed false

\layout Standard

From 2004 Thesis plan...
\layout Standard
\pagebreak_top 

\begin_inset Quotes eld
\end_inset 

Some nice long quote here, maybe to do with computer vision xxxxxxxxxxxxxxxxxxx
 xxxxxxxxxxxxxxxxxxx xxxxxxxxxxxxxxxxx xxxxxxxxxxxxxx xxxxxxxx xxxxxxxxxxx......
\begin_inset Quotes erd
\end_inset 


\layout Standard
\align right 
--
\emph on 
FirstName LastName [citation number]
\emph default 
.
\end_inset 


\layout Standard


\begin_inset Note
collapsed false

\layout Standard


\begin_inset Note
collapsed false

\layout Chapter*
\pagebreak_bottom 

\begin_inset LatexCommand \label{cha:prologue}

\end_inset 


\begin_inset LatexCommand \index{Prologue}

\end_inset 

Prologue
\end_inset 


\layout Standard


\begin_inset Note
collapsed false

\layout Standard

JUNE 2006:
\layout Standard

DONE -- Seem
\layout Standard

more references
\layout Standard

intro star
\layout Standard

assess
\layout Standard

more applic
\layout Standard

margins
\layout Standard

3rd para in chap 2
\layout Standard

inter intha chap 2
\layout Standard

why NRR in first para
\layout Standard

definitions
\layout Standard

back motivation
\end_inset 


\end_inset 


\layout Chapter


\noun on 

\begin_inset LatexCommand \label{cha:Introduction}

\end_inset 


\begin_inset LatexCommand \index{Introduction}

\end_inset 


\noun default 
Introduction
\layout Standard
\align right 

\size large 

\begin_inset Quotes eld
\end_inset 

A
\size small 
 mathematician is a device for turning coffee into theorems.
\begin_inset Quotes erd
\end_inset 


\newline 
-- 
\emph on 
Paul Erods.
\layout Standard


\begin_inset ERT
status Open

\layout Standard

\backslash 
lettrine{T}{ his}
\end_inset 

 thesis outlines a novel approach to the evaluation of statistical modelbs
 of appearance 
\begin_inset LatexCommand \cite{Edwards_98_AAM}

\end_inset 

, which can also be used to assess the quality of non-rigid registration
 (NRR) algorithms.
 Additionally, a method is presented for registering images, using model
 complexity as a criterion which provides a figure of merit 
\begin_inset LatexCommand \cite{schestowitz-model-based-nrr}

\end_inset 

.
 The work is motivated by the observation that, given a set of registered
 (i.e.
 fully-aligned) images, appearance models can be built automatically and
 then be evaluated 
\begin_inset LatexCommand \cite{schestowitz_isbi}

\end_inset 

.
 Another key observation is that generative models of any reasonable form
 can become the direct product of registered images, which need not necessarily
 be non-rigidly aligned.
 By reconstructing/generating images from the model, these registrations
 can be assessed.
 The ability to assess registration algorithm is important for benchmarks
 and comparative studies that help improve or hand-tweak a given NRR algorithm.
 
\layout Standard

This work contributes to the framework of modelling, as well as the popular
 and intricate study of non-rigid image registration 
\begin_inset LatexCommand \cite{Hajnal_book}

\end_inset 

.
 The approach is broad and generic, but the thesis will focus on 2-D brain
 images, alluding to the existing extension and implementation in 3-D, as
 well as similar work on face images.
 At the 'proof-of-concept' stages, 1-D images are used as well.
 These are helpful in validation experiments that exploit synthetic images
 whose nature is well understood.
\layout Standard

The overall aim of the work is to demonstrate that appearance models can
 be built automatically and registration be driven by the quality of appearance
 models.
 Concurrently, both models and registration are implicitly evaluated, owing
 to their innate bond.
 This reciprocal relationship is not only proven, but it is also shown to
 have promise in practical applications.
 This facilitates and manifests a variety of important experiments, including
 benchmarks that help discern one registration or model construction algorithm
 from inferior ones 
\begin_inset LatexCommand \cite{schestowitz-model-evaluation}

\end_inset 

.
\layout Section

Image Registration
\layout Standard

In medical imaging, one particularly important task to tackle is that which
 involves simplification of the vast amounts of information at hand.
 With advancements in technology, more data is gathered than a human is
 able to analyse.
 The level of redundancy and excess in the available data requires that
 various steps should make it more manageable.
 By reducing the complexity or data and making it more cohesive, valuable
 information can be extracted from it, whereas unwanted residues are left
 aside.
\layout Standard

An expert in a specialised field, for example, may wish to perform an analysis
 on a considerable number of images acquired from particular groups of subjects.
 Each group will often be characterised by various distinguishing features,
 but in order to study the group 
\emph on 
as a whole
\emph default 
, images from each subject need be better assimilated, e.g.
 through transformation, to the remainder.
 As a result of applying sensible transformations to the image, understanding
 of structural change, whether pathological or not 
\begin_inset LatexCommand \cite{atlases_disease_specific}

\end_inset 

, becomes more trivial.
 There are two common cases where such studies have significant merits:
\layout Enumerate


\series bold 
An intra-subject study.
 
\series default 
This involves analyzing a series of images taken from the same subject and
 comparing them.
 These images can be acquired over a period of time, as means of learning
 the progression and regression of atrophies 
\begin_inset LatexCommand \cite{atlases_disease_specific}

\end_inset 

, for instance.
 In other scenarios, the images might be a series of analogous slices, which
 are extracted from a three-dimensional volume, where there is a need to
 correct and compensate for motion.
\layout Enumerate


\series bold 
An inter-subject study.

\series default 
 Typically, such studies involve a comparison between two (or more) groups
 of subjects.
 In a medical context, this makes possible the discovery of symptoms for
 a certain groups of patients, observing how they deviate from 'normals'.
\layout Standard

It is evident that the need to compare images is rather fundamental.
 It forms the very basis for much of the above to become practical.
 Non-rigid registration (NRR) is the methodology used to address problems
 of this kind.
 NRR algorithms are intended to annul variations in pose, as well as in
 form, across a collection of images.
 Given a set of images, all of which contain something similar, one wishes
 to repeatedly transform them until they appear most identical 
\begin_inset LatexCommand \cite{NRR_ISBI2002}

\end_inset 

.
 There is no consensus which suggests that only one particular algorithm
 should be used.
 The problem is highly under-constrained and many different algorithms have
 been proposed to solving it.
 There is a wealth of algorithms that compete over performance, where a
 measure of performance is, in itself, subjective.
 There is a clear distinction, however, between two general approaches:
 groupwise and pairwise.
 Each case will be considered in turn.
\layout Standard

NRR of both pairs or groups of images is used widely as a basis for medical
 image analysis and actual applications include structural analysis, atlas
 matching and change analysis 
\begin_inset LatexCommand \cite{Crum_BJR}

\end_inset 

.
 The aim of NRR is to find, automatically, a meaningful dense correspondence
 between a pair (
\emph on 
pairwise
\emph default 
 registration), or across a group of images
\emph on 
 groupwise
\emph default 
 registration).
 A typical algorithm consists of a representation of the deformation fields
 that encode the spatial variation between images, an objective function
 that quantifies the degree of misregistration, and a method of optimising
 the objective function with respect to the deformation fields.
 As different algorithms generally produce different results when applied
 to the same set of images 
\begin_inset LatexCommand \cite{Zitova_2003}

\end_inset 

, there is also a clear need for methods to evaluate the results of NRR.
 One interesting question to address, for instance, is whether a groupwise
 registration outperforms a similar pairwise approach.
\layout Standard

Various methods of evaluation have been proposed 
\begin_inset LatexCommand \cite{Hellier,Validation-NRR,schnabel}

\end_inset 

.
 One approach is to construct artificial test data, applying known deformations
 to real or synthetic images.
 This allows algorithms to be evaluated by attempting to recover the applied
 deformations, but does not allow the results of NRR to be assessed 'in-line'
 in real applications.
 An alternative approach is to provide anatomical ground truth for the images
 to be registered, then measure the degree of anatomical correspondence
 following NRR.
 One such method is described in this thesis as a 'gold standard', but the
 need for expert annotation of the images renders the approach too time-consumin
g and subjective for routine application.
 These problems motivate the search for a method of evaluation that can
 be used routinely in real applications, without the need for ground truth.
 There is potential in the use of statistical models -- a potential that
 arises owing to numerous overlaps between NRR and modelling.
\layout Section

Models and Registration
\layout Standard

The approach adopted for assessment is based on the observation that, given
 a set of non-rigidly registered images -- however obtained -- it is possible
 to construct a statistical model of appearance that takes account of both
 the shape and texture variation across the set.
 Models of this type have been used extensively as a basis for image interpretat
ion by synthesis 
\begin_inset LatexCommand \cite{Cootes_ECCV_1998}

\end_inset 

.
 To build a model one can exploit the dense correspondence across the set
 of images established by the NRR.
 The key idea that underpins the approach is that, if the correspondence
 is poor, the resulting appearance model will be unsatisfactory.
 When the correspondences are correct, the model will be simpler.
 The model will also faithfully reflect on and be able to reproduce the
 correspondent images.
 This observation transforms the problem of evaluating non-rigid registration
 into one of evaluating the model generated from the result of registration.
\layout Comment

Assessment of Registration Without Ground Truth
\layout Standard


\begin_inset Note
collapsed false

\layout Standard

From TMI
\end_inset 


\layout Section

Exploiting the Tie Between Registration and Models
\layout Standard

The main merit of the work is the introduction of a generic method for assessing
 the quality of non-rigid registration 
\begin_inset LatexCommand \cite{schestowitz_isbi}

\end_inset 

.
 The method 
\emph on 
does not
\emph default 
 require ground truth, but rather depends solely on the registered images.
 Consider the case where NRR is applied to a 
\emph on 
set
\emph default 
 of images, providing a dense correspondence between images.
 Given this correspondence, it is possible to build a generative statistical
 model of appearance variation for the set.
 The quality of the resulting model will depend on the quality of the correspond
ence.
 Measures of model 
\emph on 
specificity
\emph default 
 and 
\emph on 
generalisation
\emph default 
 can be used to assess the quality of the model and, hence, the quality
 of the correspondence from which it is derived.
 The approach does not depend on the specifics of the registration algorithm
 or the form of the model.
\layout Standard

Validation of this approach is performed by measuring the change in model
 quality, as the correspondence of an initially registered set of MR images
 of the brain is progressively perturbed, and comparing the results with
 those obtained using a method based on the overlap of ground-truth anatomical
 labels.
 This demonstrates that, not only is the proposed approach capable of assessing
 NRR reliably without ground truth, but that it also provides a more sensitive
 measure of misregistration than the overlap-based approach.
 It is then possible apply the new method to compare the performance of
 different registration algorithms on a several sets of MR images of the
 brain, demonstrating that the method is able to discriminate between different
 methods of registration in a practical setting.
\layout Standard

Since models are used throughout the entire process, evaluating the quality
 of models is possible and different methods of constructing appearance
 models can thus be compared 
\begin_inset LatexCommand \cite{schestowitz-model-evaluation}

\end_inset 

.
 Also of interest are methods that enable models to be built directly from
 the data whilst models serve as the similarity measure in the objective
 function.
 This is essentially a case or reversing the problem, attaining good registratio
n by optimising the quality a model whose data is manipulated 
\begin_inset LatexCommand \cite{schestowitz-model-based-nrr}

\end_inset 

.
\layout Section

Contributions
\layout Standard

The contribution of the work is two-fold.
 On the one hand, it is demonstrated that one is able to evaluate the quality
 of NRR, without needing ground-truth data.
 Thus, a comparison between numerous NRR algorithms can be made without
 cumbersome manual annotation.
 On the other hand, one is also able to build models automatically, using
 registration algorithms, and then evaluate the resultant models.
 All in all, this provides a framework for automatic or semi-automatic analysis
 of arbitrarily large amount of data, assuming that enough images are made
 available for an appearance model to be constructed (the caveat).
\layout Comment

(Section) Non-rigid Image Registration
\layout Section

Thesis Organisation
\layout Standard

The structure of the thesis is as follows:
\layout Standard


\series bold 
Chapters 2 and 3
\series default 
 provide an augmented description of the background to both the assessment
 of registration, and the construction of appearance models (respectively),
 explaining in more detail the link between the two.
\layout Standard


\series bold 
Chapter 4
\series default 
 outlines previous work on MDL for shape model.
 This work is essential as it comprises some of the ground work, upon which
 this thesis is based.
\layout Standard


\series bold 
Chapter 5
\series default 
 briefly outlines an algorithm that enables non-rigid registration algorithms
 to be driven by minimisation of model complexity and it also shows some
 corresponding results.
 The results are not only include a registered set of images, but also their
 appearance model.
\layout Standard


\series bold 
Chapter 6
\series default 
 defines two quantitative measures of model quality as well as registration
 quality, and discusses their implementation.
\layout Standard


\series bold 
Chapter 7
\series default 
 is intended to focus on method validation.
 The behavior of aforementioned measures is investigated by measuring the
 effect of deliberately perturbing the registration of an initially registered
 set of images.
 The results are compared to those obtained using a 'gold standard' method
 of assessment, based on measuring the overlap of manually-annotated ground
 truth.
 The results demonstrate that our new measures are closely correlated with
 those based on ground-truth, and that the proposed approach is actually
 
\emph on 
more
\emph default 
 sensitive to misregistration
\layout Standard


\series bold 
Chapter 8
\series default 
 presents practical applications.
 The measures developed are used to compare three NRR algorithms applied
 to the registration of sets of 2-D MR brain images, demonstrating the superiori
ty of a fully groupwise registration algorithm over a repeated pairwise
 approach.
\layout Standard


\series bold 
Chapter 9
\series default 
 described the extension of the method to 3-D, as well as limitations.
\layout Standard


\series bold 
Chapter 10
\series default 
 lists several possible extensions and several ways forward.
\layout Standard


\series bold 
Chapter 11
\series default 
 draws conclusions and contains a summary of the contributions of the work.
\layout Standard


\begin_inset Note
collapsed false

\layout Standard

BOOKMARK
\layout Standard

OLD TEXT BELOW
\end_inset 


\layout Comment

CJT: Say something about MDL models?
\layout Comment


\begin_inset Note
collapsed false

\layout Standard

The thesis also covers a complementary and reverse approach to the assessment
 of NRR.
 One can use the existing technology to 
\emph on 
model
\emph default 
 all of the images in the set and use this modelling process to minimise
 a term of complexity.
 The basic contention is that when this term is minimised, better similarity
 across the set of data is granted and a single unique solution is always
 reached.
\layout Standard

This process above is very beneficiary because one if its byproducts is
 a description of a group of transformations -- the transformations that
 were used to manipulate data to attain identity.
 Such descriptions can be used, in a process of learning, to form knowledge
 about the observed differences in the data set.
 They can describe how to transform a single data object in a way which
 preserves prevalent, well-ground variations.
 They can be used to construct models which are capable of regenerating
 existing and yet unseen data that exhibits similar properties.
 
\layout Standard

For raw data (as described above) to be modelled properly, knowledge about
 corresponding patterns and points in the data, must be gained.
 Thus far, human understanding of the data aided a process of annotation.
 That process involved mark-up of data regions or points that are homologous.
 However, once data is made merely identical, mark-up becomes trivial.
 This is because points tend to lie at identical position.
 Significantly enough, no manual mark-up of the data is necessary once the
 approach outlined above successfully works.
 The questions that remain are: Can data sets be transformed to reach a
 state of identity? Will the framework of models transcend the peril of
 data being changed?
\layout Comment


\begin_inset LatexCommand \label{sub:General-Project-Description}

\end_inset 

Subsection: Description of Task
\layout Standard

The continuous research work invested in two separate yet related fields
 calls for a strategic merger which takes advantage of the best of both.
 These fields are statistical models of appearance and non-rigid registration
 whose wide-spread use consequently made them independently usable and powerful.
 As they deal with problems that have a great deal in common, attempts have
 been made, and still are being made, to discover how one field is able
 benefit the other and to what capacity.
\layout Standard

The broad field of image registration includes some important techniques
 that academic and clinical research groups have reasonable interest in
 
\begin_inset LatexCommand \cite{Joshi_reg,Wang_reg,West_reg,Xu_reg,Younes_reg}

\end_inset 

.
 An evident rise can be shown in the number of papers published in the field,
 medical context being a noticeable focus.
 It turns out that registration is in many respects highly-applicable to
 polymorphous bio-medical data as later discussions stress.
\layout Standard

Registration is concerned with the assembly of data which is taken either
 at different points in time or at some arbitrary time instances where changes
 due to the passage of time can be ignored.
 Registration sees the most use in scenarios where multiple 
\emph on 
different
\emph default 
 objects or subjects
\begin_inset Foot
collapsed false

\layout Standard

From this point onwards, there will be a clear focus on 2-D imaging of the
 anatomical.
 This narrower view can be considered a case study for image registration
 and it allows descriptions to be easier to follow.
\end_inset 

 \SpecialChar ~
are being scanned or where the acquisition method varies.
 In the case of medical imaging, registration is commonly mentioned in one
 of three distinct circumstances: intra-subject registration, inter-subject
 registration and multi-modality imaging.
 This corresponds to the investigation of changes in one specific subject
 over time, the investigation and comparison between more than one subject
 and the fusion of data acquired from different modalities (e.g.
 CT, PET and MRI
\begin_inset Foot
collapsed false

\layout Standard

See list of acronyms and abbreviation in the Appendix 
\begin_inset LatexCommand \vpageref{cha:Appendix-EList-of}

\end_inset 

.
\end_inset 

) respectively.
 Most typically, however, only a single subject is involved.
\layout Standard

The main problem that registration is determined to overcome is the 
\emph on 
alignment
\emph default 
 of several images with the aim of achieving better 
\emph on 
correspondence
\emph default 
 across the entire set of images to be dealt with.
 This quality of correspondence can be evaluated by similarity measures,
 examples of which are given later (
\begin_inset LatexCommand \ref{sub:Measuring-Similarity}

\end_inset 

 in Chapter 
\begin_inset LatexCommand \ref{cha:Non-rigid-Registration}

\end_inset 

).
 With suitable overlap of some given object
\begin_inset Foot
collapsed false

\layout Standard

The word 
\begin_inset Quotes eld
\end_inset 

object
\begin_inset Quotes erd
\end_inset 

 will from here onwards refer to a structure of interest in 
\begin_inset Formula $n$
\end_inset 

-dimensional space.
\end_inset 

 \SpecialChar ~
within a group of images, segmentation, analysis and comparison become
 significantly more straight-forward; these are almost impossible to guarantee
 in the absence of that overlap.
 Correspondence is not always simple to achieve algebraically since the
 object inspected or the aperture
\begin_inset Foot
collapsed false

\layout Standard

In the case of medical imaging, there are even more factors to be considered,
 as opposed to a camera's aperture.
\end_inset 

 \SpecialChar ~
may change position and angle over time or acquisition site.
 In reality, additional unwanted effects such as noise, distortion and change
 in form must be carefully accounted for.
 In some real-world applications, biological being an ideal exemplar, variabilit
y must be handled sensibly in order to understand the changing structures
 (as in soft tissue in the brain) that are present in an image.
 Therefore, the correspondence, as well as the permissible degree of freedom,
 must not be excessively rigid
\begin_inset Foot
collapsed false

\layout Standard


\begin_inset Quotes eld
\end_inset 

Rigid
\begin_inset Quotes erd
\end_inset 

 refers to constrained variability and low model generalisability as explained
 later.
 It is significantly different from the term 
\begin_inset Quotes eld
\end_inset 

rigid
\begin_inset Quotes erd
\end_inset 

 in the actual context of registration.
\end_inset 

.
 It is important to ensure that the chosen analysis mechanism caters for
 some level of flexibility to enable a rigorous registration process that
 is immune to high levels of misalignment.
\layout Standard

The problem of registration would have been rather simple if it were not
 for the innate changes that are an integral part of any biological entity,
 e.g.
 brain 
\begin_inset LatexCommand \cite{Brain_warping_book}

\end_inset 

, spine, etc.
 Simple alignment is therefore not necessarily sufficient to give good a
 solution -- that is -- plausible correspondence.
 As explained in Chapter 
\begin_inset LatexCommand \vref{cha:Non-rigid-Registration}

\end_inset 

 of this report, registration methods can be further broken down into different
 classes, but their aims remain the same in essence.
 The methods aspire to find some correlation between two or more images,
 in which case a new entity is obtained that expresses the informative relations
 between the distinct images.
\layout Comment

The sentence below requires models introduction
\layout Standard

Image registration is said to be capable of positively affecting the performance
 of statistical models; possibly this holds the other way around too.
 More compact (and hence preferable) models of variability can be constructed
 if registration procedures are applied to its training data (see 
\begin_inset LatexCommand \cite{Mitchell}

\end_inset 

 for more details on learning and training and 
\begin_inset ERT
status Open

\layout Standard

\backslash 
S
\end_inset 

 
\begin_inset LatexCommand \ref{cha:Active-Appearance-Models}

\end_inset 

 on models).
 This is obvious because registration clearly minimises the witnessed variabilit
y, that variability simply being change or difference in the data.
 The earlier parts of this report, and in particular the next two chapters,
 attempt to explain and show the commonality between the two techniques,
 whereas the latter parts explain in greater depth how the two techniques
 might (and possibly should) come together.
 It also insinuates that as soon as one can be incorporated within the other,
 detrimental issues that recur can finally be resolved.
\layout Standard

In some previous work, the formation of appearance models, based on registered
 images, provided a fair indication of how desirable a prior process of
 registration was.
 However, the process was slow and therefrom emerged a need to find better
 ways of using the two techniques in a cunning and hence more efficient
 manner.
\layout Standard

Quite broadly and even wishfully, some current research activities intend
 to bring together different phases of the handling of an image, from the
 moment when images are registered to the point where these are coupled
 with an appropriate statistical model (and even get segmented and measured).
 Research that this document describes can hopefully form a small part of
 such a large-scale goal.
 Arguably
\begin_inset Foot
collapsed false

\layout Standard

Ideas such as this are overly optimistic perhaps.
\end_inset 

, it would not be venturous to state that model fitting, shape analysis,
 non-rigid registration, feature detection and segmentation can and should
 be put under one 
\emph on 
single framework
\emph default 
.
 At least a few of these might become inseparable in the future.
\layout Standard

In this way, by unifying image analysis phases, more compact and powerful
 representation of images can be used -- images can be described by the
 parameters of non-rigid transforms that ought to generate them from a basal
 mean image.
 This is in fact what makes this unification of several methods quite appealing
 when compared with stand-alone active appearance models where construction
 is subjective and time-consuming.
\layout Section


\begin_inset LatexCommand \label{sub:Goals}

\end_inset 

Principal Goals
\layout Standard

As will be explicated in the later chapters, this project aims to discover
 a new way of registering data, i.e.
 aligning a set of images or volumes.
 Past work has motivated the belief that there are advanced criteria by
 which registration can be carried out.
 Not only will such registration be as powerful as desired, but also, as
 somewhat of a residue, one should be left with an entity expressing the
 data variation that was observed.
 What this means in simpler terms is that two disjunct contributions can
 be made by this work, assuming it ends up being successful.
 As it currently stands, not only were the goals better realised, but a
 significant step was made towards their establishment (Sections 7-11 reflect
 and support this argument).
\layout Standard

Just as one would expect, research work involves a learning curve and the
 development of working relationships.
 A mentioning of this point-of-view can be found in this document although
 little emphasis has been put into unnecessarily or detailed bits of information.
 These are not pre-requisite formal goals, yet they are integrally used
 to serve the main goals which are purely scientific
\begin_inset Foot
collapsed false

\layout Standard

This text is goal-oriented and it embraces the technical, not much of the
 inter-personal and curricular.
\end_inset 

.
\layout Standard

In summary, goals have been realised at a much earlier stage and have so
 far been reached and fulfilled in a way that is debatably beyond satisfactory.
 This report aspires to prove that this is indeed the case.
 It is not inclined to concentrate too much on certain aspects such as the
 daily contributory involvements, but rather show the progress made, the
 experiments performed and some results and conclusions, of which there
 are plenty.
 
\layout Comment

The large amount of information that is usually necessary to hold information
 about intensity values is no longer of need.
 It resides in just one original model or reference and its generalisation
 is expressed by the legality of warps that manipulate these intensity values.
\end_inset 


\layout Chapter
\pagebreak_top 

\noun on 

\begin_inset LatexCommand \label{cha:Non-rigid-Registration}

\end_inset 


\begin_inset LatexCommand \index{Non-rigid Registration}

\end_inset 


\noun default 
Non-rigid Registration
\layout Standard
\align right 

\size large 

\begin_inset Quotes eld
\end_inset 

H
\size small 
aving a set, popular formula does inhibit you.
\begin_inset Quotes erd
\end_inset 


\newline 
-- 
\emph on 
George Shearing.
\layout Standard


\begin_inset Note
collapsed false

\layout Standard

TMI text
\end_inset 


\layout Standard


\begin_inset ERT
status Open

\layout Standard

\backslash 
lettrine{T}{ he}
\end_inset 

 aim of non-rigid registration is to identify an anatomically-meaningful,
 dense (i.e., pixel-to-pixel or voxel-to-voxel) correspondence across a set
 of images.
 This correspondence is typically encoded as a set of spatial deformation
 fields, one for each image, such that when the deformations are applied
 to the images, corresponding structures are brought into alignment.
\layout Standard

A typical registration algorithm proceeds by optimising an objective function,
 which depends on the similarity of the images after alignment, with respect
 to the set of deformations 
\begin_inset LatexCommand \cite{Pluim_MI}

\end_inset 

.
 As well as the objective function, it is necessary to define the representation
 used for the deformation fields and the method for finding the optimum
 of the objective function.
 Different choices lead to different registration results and competing
 methods of NRR -- hence the need for an objective, easily-applied method
 of assessment, as described in the remainder of this chapter.
\layout Standard


\begin_inset Note
collapsed false

\layout Standard

CJT: review the one below
\end_inset 


\layout Standard

While the thesis' primary point of focus is assessment and comparison of
 NRR algorithms 
\begin_inset LatexCommand \cite{schestowitz_isbi,Crum_MICCAI_2005}

\end_inset 

, the remainder of the chapter explains how constituent parts of the registratio
n process interact with one another.
 It also surveys a variety of methods that are actively used to achieve
 a fully-functional NRR algorithm, alluding to the new model-based algorithm,
 which is described in Chapter 6.
\layout Standard


\begin_inset Note
collapsed false

\layout Standard

From Cont.
 Report below
\end_inset 


\layout Section


\begin_inset LatexCommand \label{sec: NRR Introduction}

\end_inset 

Background
\layout Standard

Image registration is an essential image processing step, which has entered
 several domains where reliable acquisition of fully-aligned images cannot
 be assured 
\begin_inset LatexCommand \cite{Hajnal_book,3d-ultrasound-nrr}

\end_inset 

 or relationships between images turn out to be overly complex.
 The significance of this problem is made most apparent when alignment of
 large 
\emph on 
groups
\emph default 
 of images needs to be achieved 
\begin_inset LatexCommand \cite{IPMI_2005_ISBE}

\end_inset 

.
 In some cases, the images under consideration are rather different in terms
 of their nature, even though they contain exactly the same type of object.
 This leaves place for ambiguity -- and consequently -- misinterpretation.
\layout Standard

Misalignment in images can result from movement of subjects or objects of
 interest, change in view-point, or changes to general conditions at the
 acquisition site.
 Misalignments can also be artifacts of morphological changes, or physical
 anomalies that are due to change in mass and elasticity of organs 
\begin_inset LatexCommand \cite{Haker}

\end_inset 

.
 Changes in form can be observed over time somewhere within an object's
 constituent parts, e.g.
 the involuntary changes in the form of the subject's lungs.
 In some circumstances, as later discussed, misalignment incurs due to profound
 changes in the form of objects (typically 
\emph on 
subject
\emph default 
s and their anatomy) being scanned.
 A state of near-perfect alignment, which is reached through NRR algorithms,
 is a key step that should often be completed before any analysis stage
 of a collection of images is safely embarked on.
 This facilitates and caters for better understanding of the contents of
 several images (and more cohesively so, as a group).
\layout Standard

Given a collection of images, all of which depict the same object, one wishes
 to 
\emph on 
transform
\emph default 
 them in one way or another, so that they appear as similar as possible
 to one another.
 The solution to this problem is never unique as there will be infinitely
 many solutions, i.e.
 transformations, which lead to similar results.
 As such images may not contain precisely the same elements, there is rarely
 a ground-truth solution either, i.e.
 there is no definite one-to-one correspondence between imaged objects.
 Absence of or reappearance of finer elements, for example, implies that
 no point-to-point correspondence can always be determined, so good solutions
 need be 
\emph on 
approximated
\emph default 
 instead.
\layout Standard

The field which is associated with this problem is uniformly referred to
 in the literature as 
\begin_inset Quotes eld
\end_inset 

non-rigid registration
\begin_inset Quotes erd
\end_inset 

.
 The work described in subsequent chapters underlines and extends a methodology
 that is devised to assess the quality of NRR, based on solutions reached
 by NRR algorithms.
 It is therefore important to elaborate on what is involved in any NRR algorithm
, highlighting different approaches and parts of the process.
 Principles of registration, particularly with respect to approaches which
 this thesis revolves around, will be dealt with in turn.
 The subject is by all means broad and for deeper understanding of alternative
 approaches, cited literature can be carefully read 
\begin_inset LatexCommand \cite{Hajnal_book}

\end_inset 

.
\layout Standard


\begin_inset Note
collapsed false

\layout Standard

Was: introduction
\end_inset 


\layout Standard


\begin_inset Note
collapsed false

\layout Standard

This must 'spill' over to the next page or new section added...
\end_inset 


\layout Standard

Approaches to NRR -- those on which research around the world is based --
 are rather distinct, but are all built upon the same ideas.
 There are commonalities and so-called 'components', which NRR is logically
 based on.
 This chapter identifies these components, giving an overview with special
 emphasis on methods which are said to hold the very key to better NRR algorithm
s.
\layout Standard


\begin_inset Note
collapsed false

\layout Standard

the author and his colleagues consider to be a way forward.
\end_inset 


\layout Standard


\begin_inset Note
collapsed false

\layout Section


\begin_inset LatexCommand \label{sub:Image-Registration}

\end_inset 

Registration
\end_inset 


\layout Comment

Old -- something which is hard to achieve in the lack of 
\emph on 
consistency
\emph default 
.
\layout Section


\begin_inset LatexCommand \label{sub:Transformations}

\end_inset 

Transformation
\layout Subsection

Overview
\layout Standard

Image registration ordinarily involves the manipulation of image pixels
 (or in a volumetric context 
\begin_inset LatexCommand \cite{Ashburner}

\end_inset 

 -- voxels).
 The product of this is dense mapping that describes where each pixel/voxel
 moves once the transformation (or warp) gets applied.
 This morphometric manipulation is done in accordance to a set of rules
 and with a common grand goal, which requires that transformation as a whole
 is sufficiently versatile.
 There are various image warping methods that achieve a full transformation
 which affects an entire image.
 The warps are subjected to conditions that make them valid, i.e.
 transformation is carried out under the imposition of strict constraints.
\layout Standard

It is commonly desirable to attain a maximal cross-image similarity estimate
 
\begin_inset LatexCommand \cite{Similarity measures}

\end_inset 

 as images are being warped.
 In essence, a greater degree of overlap amongst a group of images is sought.
 This similarity can be reach by applying warps to the images and this should
 optimally be done with minimal extents of distortion because the integrity
 of the image should be preserved.
 Better similarity is achieved by applying 
\emph on 
changes
\emph default 
 to these images, which is where transformation fits in.
 Transformation is the means by which one approaches greater similarity
 among several images.
\layout Subsection

Transformation Types
\layout Standard

One can perceive the different transformation types as though they pertain
 to different levels of 'interference' -- that is -- the interference to
 analysis and intervention with the integrity of data being manipulated.
 Some of the more permissive transformations violate and eliminate a state
 of reversibility.
 Once applied, there is ambiguity which prevents the transformation from
 being retracted (applied in reverse).
 A typical classification of transformation types is as follows (ordered
 by increasing interference or severity):
\layout Description

Rigid\SpecialChar ~
Transformation.
 Permits translation (relocation in space), rotation, and scaling (albeit
 only uniform size changes, i.e.
 shrinkage and enlargement)
\begin_inset Foot
collapsed false

\layout Standard

More strictly, the inclusion of scaling makes this a Similarity transformation,
 rather than rigid.
\end_inset 

.
 In hyperspace, normalised shape attributes are altogether preserved, so
 the process is usually concerned with a more fundamental alignment
\emph on 
.
 
\emph default 
Such alignment is ordinarily intended to position all data instances (images
 or volumes) upright and centred at the origin of a hyperspace, with a fixed
 size of 1 unit at most (fixed-sized hypersphere).
 All images are virtually confined to lie inside a bounding structure (a
 circle or sphere, in 2-D and 3-D respectively).
 In 3-D, for instance, there is a total of 6 degrees of freedom so a rigid
 transformation will be wholly characterised by a tuple of 6 parameters
\begin_inset Foot
collapsed false

\layout Standard

1 value for scaling, 3 for 
\emph on 
x, y 
\emph default 
and 
\emph on 
z
\emph default 
 coordinates and 2 for rotation, e.g.
 the 
\emph on 
xy
\emph default 
 and 
\emph on 
yz
\emph default 
 angles 
\begin_inset Formula $\theta_{1}$
\end_inset 

 and 
\begin_inset Formula $\theta_{2}$
\end_inset 

.
\end_inset 

.
 These parameters fully describe a rigid transformation.
\layout Comment

CJT ON THE ABOVE: STRICTLY SIMILARITY IF YOU INCLUDE SCALING -- DONE
\layout Comment

ABOUT THE LAST SENTENCE ON DEGREES OF FREEDOM: THIS___DOES___ DESCRIBE A
 RIGID TRANSFORM -- DONE, added a sentence
\layout Description

Affine\SpecialChar ~
Transformation.
 Allows an image to 
\emph on 
stretch and skew
\emph default 
 along at least one axis (corresponding to a parametric dimension), yet
 not 
\emph on 
necessarily
\emph default 
 along several of them simultaneously.
 This ensures that a homogeneous scaling -- that which affects all dimensions
 uniformly -- will not be invalidated.
 Despite the fact that consistency is compromised, lines which were parallel
 before an affine transformation is applied will remain parallel after the
 transformation is applied
\emph on 

\begin_inset Foot
collapsed false

\layout Standard

Other transformations such as shear and taper, on the contrary, are not
 parallelism-preserving.
 The importance of this rigorous constraint is that the distance between
 any two points remains proportional to the transformation.
\end_inset 


\emph default 
.
 Reconstruction is said to be possible so this transformation is invertible.
 Essentially, for a given affine transformations 
\begin_inset Formula $T_{a}(x)$
\end_inset 

, where 
\begin_inset Formula $x$
\end_inset 

 is a vectorised representation of an image (or volume), and its inverse
 
\begin_inset Formula $T_{a}^{-1}(x)$
\end_inset 

, the expression 
\begin_inset Formula $T(T_{a}^{-1}(x)=Id(x)$
\end_inset 

 must hold true.
 It retains a level of simplicity, which makes it easy to determine and
 resolve.
 This proves to be an important constraint when the practicability of warps
 is further debated.
\layout Description

Non-rigid\SpecialChar ~
Transformation.
 All other valid transformations fall into this category 
\begin_inset LatexCommand \cite{NRR_ISBI2002}

\end_inset 

.
 In principle, no inviolable constraints are in place, but quite clearly,
 in a practical setting, a non-rigid transformation attempts to preserve
 some of the key structures
\begin_inset Foot
collapsed false

\layout Standard

A random uncontrollable transformation will disintegrate basic structures
 in the image and can make valid interpretation impossible.
\end_inset 

 \SpecialChar ~
in the image while abstaining from excessive tearing and folding 
\begin_inset LatexCommand \cite{Rueckert_non_rigid,CT_bmvc_2004}

\end_inset 

.
 This means that each pixel in the range must map to another and no pixel
 is left undefined.
 More on this is to be discussed later, in the context of diffeomorphism.
\layout Standard

The images of an apple in Figure 
\begin_inset LatexCommand \ref{cap:Registration-examples;-from}

\end_inset 

 illustrate the effect that each transformation type is permitted to have
 on the original image shown on the left.
\layout Standard


\begin_inset Float figure
wide false
collapsed false

\layout Standard
\align center 

\begin_inset Graphics
	filename ./Graphics/reg.eps
	display none
	scale 70.00

\end_inset 


\layout Caption


\begin_inset LatexCommand \label{cap:Registration-examples;-from}

\end_inset 


\size small 
Registration examples.
 On the left column: the original, unwarped image; on the right column,
 from top to bottom: rigid, affine, and non-rigid transformations.
\end_inset 


\layout Standard

As the figure suggests, the appearance of an object remains identical under
 rigid transformations.
 Images objects are allowed strictly to grow, shrink, move, and rotate.
 Affine transformation allows an object to lose its original form whereas
 non-rigid registration is far more permissive, so the object can be subjected
 to rather arbitrary deformations.
\layout Standard


\begin_inset Float figure
wide false
collapsed false

\layout Standard
\align center 

\begin_inset Graphics
	filename ./Graphics/warp2.eps
	scale 70.00

\end_inset 


\layout Caption


\begin_inset LatexCommand \label{cap:CPS-non-rigid-warp}

\end_inset 


\size small 
A pseudo-non-rigid warp example.
 The effect of the warp is shown on the right hand side.
\end_inset 


\layout Subsection


\begin_inset LatexCommand \label{sub:Diffeomorphism}

\end_inset 

Diffeomorphism
\layout Standard

There are important factors to consider when selecting a transformation
 method.
 Ideas which were introduced so far in this section confirm that there is
 an ever-increasing need for non-rigid registration algorithms that prevent
 the 'erosion' of image structures.
 Diffeomorphic 
\begin_inset LatexCommand \cite{diffeomorphism}

\end_inset 

 functions are 
\emph on 
invertible, continuous 
\emph default 
and
\emph on 
 one-to-one
\emph default 
 mappings, which can be applied to a given image
\begin_inset Foot
collapsed false

\layout Standard

More generally, such functions are mappings defined over a matrix or a vector,
 which herein is analogous to an image.
\end_inset 

.
 These functions can be described by local geometric transformations that
 have an effect on groups of pixels, or the plane that pixels are embedded
 in.
\layout Standard

Diffeomorphic transformations that are used in this work were initially
 devised by Twining and Marsland 
\begin_inset LatexCommand \cite{twining_diffeo}

\end_inset 

.
 These benefit from having continuous derivatives at the boundaries, unlike
 for example, these proposed by Ltjnen and Mkel 
\begin_inset LatexCommand \cite{Lotjonen_and_Makela}

\end_inset 

.
 Diffeomorphism is a key property which is not a necessity.
 It is, however, a good warp attribute to have in real-world applications.
\layout Standard


\begin_inset Float figure
wide false
collapsed false

\layout Standard
\align center 

\begin_inset Graphics
	filename ./Graphics/brain.eps
	scale 70.00

\end_inset 


\layout Caption


\begin_inset LatexCommand \label{cap:Brain-image-warping(}

\end_inset 


\size small 
An example of image warping in medical contexts (the human brain).
 Red points that are overlaid on the skull depict knot-points for the splines
 that render a transformation, which is based on clamped plate splines.
\size default 

\begin_inset Note
collapsed false

\layout Standard

RSS: ( images from Twining and Marsland?).
 UPDATE RSS: Not so!
\end_inset 


\end_inset 


\layout Standard

What
\emph on 
 
\emph default 
Invertibility, continuity
\emph on 
 
\emph default 
and
\emph on 
 
\emph default 
one-to-one mappings mean, in simpler terms, is that for each transformation:
\layout Enumerate

The transformation has an calculable inverse transformation.
 This way, any transformation can be reversed, i.e.
 its effect retracted.
\layout Enumerate

The transformation affects 
\emph on 
all
\emph default 
 data (e.g.
 image pixels) within its boundaries so it has a spatially-contained effect
\begin_inset Foot
collapsed false

\layout Standard

A pixel of course can be mapped onto the exact same original position, but
 the idea is that a continuous flow should prevail.
\end_inset 

.
 This means that every point must move as would be expected to give a continuous
 flow of intensities.
\layout Enumerate

No two points should be mapped onto the same point as this would 'strip
 off' areas of the image, depleting them from data.
 These effects are also known as tearing and folding, both of which are
 notorious artifacts that need to be avoided.
\layout Standard


\begin_inset Note
collapsed false

\layout Subsection


\begin_inset LatexCommand \label{sub:Reparameterisation}

\end_inset 

Reparameterisation
\end_inset 


\layout Comment

CJT: ALTHOUGH IT IS LOGICAL TO PUT IT IN HERE, IT DOES NOT FIT...
\layout Comment

RSS: MAYBE RENAME THIS SECTION OR MERGE -- DONE BY MOVING TO SUBSECTION
\layout Comment


\begin_inset Note
collapsed false

\layout Standard

Taking again an example from work on shapes
\begin_inset Foot
collapsed false

\layout Standard

The principles are better described by borrowing some concepts from work
 on landmark selection in shapes (to be further seen in Section 
\begin_inset LatexCommand \ref{cha:MDL Models}

\end_inset 

).
 Similar methods as applied to images have not thoroughly been investigated
 yet.
\end_inset 

, a shape can be described by a collection of landmarks as shown in Figure
 
\begin_inset LatexCommand \ref{cap:Landmark-identification}

\end_inset 

 earlier in this report.
 The landmarks are usually located at corners, T-junctions and edges that
 are easy to locate.
 Also, other additional points in between these landmarks can chosen to
 expand the representation of that shape and make it richer, though ideally
 curves should be continuous and the number of points that make them up
 arbitrary.
 To register multiple images, all corresponding landmarks and points must
 overlap in as accurate a way as possible.
 They must correspond to one another in one common spatial reference
\begin_inset Foot
collapsed false

\layout Standard

This can be thought of as a space which defines a common (non-linear) grid.
 In this grid, mappings between corresponding points become clearer, visually.
\end_inset 

 
\end_inset 


\layout Standard


\begin_inset Note
collapsed false

\layout Standard

(CJT DOES NOT LIKE THE TERM 'COMMON GRID') -- RSS: moved and expanded
\end_inset 

 Diffeomorphic warps are applied to the space in which images will be embedded.
 That newly-defined plane is intended to bring the collection of structures
 across the set of input images closer together.
 This ultimately brings a number of images to correspondence of better quality.
 The quality varies depending on a pre-defined objective function, as well
 as the warp representation and the similarity measures, as later explained.
\layout Standard

Looking more closely at diffeomorphic functions, the spread of resampled
 points can be defined purely by a function and a reparameterisation which
 alters this function to find preferable matches.
 A monotonically-increasing function describes the distance of all points
\begin_inset Foot
collapsed false

\layout Standard

A continuous function is independent of the number of points.
 Therefore, the complexity can be increased progressively to obtain finer,
 more accurate results.
\end_inset 

 \SpecialChar ~
from an arbitrary point on the curve in such a way that will not violate
 their original sequential order.
\layout Standard


\begin_inset Float figure
wide false
collapsed false

\layout Standard
\align center 

\begin_inset Graphics
	filename ./Graphics/mono.eps
	scale 70.00

\end_inset 


\layout Caption


\begin_inset LatexCommand \label{cap:Monotonically-increasing-function}

\end_inset 


\size small 
Monotonically-increasing function illustrated in a simplistic case.
 Each point is mapped from position S onto position S' along a one-dimensional
 curve.
\end_inset 


\layout Standard

Figure 
\begin_inset LatexCommand \ref{cap:Monotonically-increasing-function}

\end_inset 

 shows what is meant by a monotonically-increasing function.
 The following expression is a more formal description and its exact inverse
 may hold instead (alluding to a monotonically-decreasing function).
 Consider the case
\layout Standard


\begin_inset Formula \begin{equation}
\forall(u\in S\wedge v\in S\wedge u<v)\rightarrow f_{mon}(u)<f_{mon}(v)\label{eq: diffeomorphism}\end{equation}

\end_inset 


\layout Comment

OLD COMMENT: show some monotonically increasing curve
\layout Standard

where 
\begin_inset Formula $f_{mon}$
\end_inset 

 is the monotonically-increasing function used and 
\begin_inset Formula $f_{mon}(S)=S'$
\end_inset 

.
 More simply, the derivative at any point must be positive, i.e.
 
\begin_inset Formula $0<\theta<90$
\end_inset 

 so that 
\begin_inset Formula $0<tan(\theta)<1$
\end_inset 

.
 In Figure 
\begin_inset LatexCommand \ref{cap:Monotonically-increasing-function}

\end_inset 

, the distance or offset along the curve is guided by the value which was
 determined by the function above.
 In this particular way, all points which lie on the curve can be moved
 
\emph on 
simultaneously,
\emph default 
 without 'colliding' with one another and new descriptors of shape become
 available.
 Instead of describing the movement of each individual point, an arbitrary
 number of points can be shifted according to one modifiable function.
\layout Standard


\begin_inset Note
collapsed false

\layout Standard

Davies 
\emph on 
et al.

\emph default 
 used this technique to optimise a shape model by evaluating the selection
 of landmark points.
 For each such reparameterisation, the specificity, generalisability and
 compactness were evaluated at some stage although minimum description length
 was ultimately chosen (to be discussed in Chapter 
\begin_inset LatexCommand \vref{cha:MDL Models}

\end_inset 

).
\end_inset 


\layout Standard


\begin_inset Float figure
wide false
collapsed false

\layout Standard
\align center 

\begin_inset Graphics
	filename ./Graphics/mono2.eps
	display none
	scale 70.00

\end_inset 


\layout Caption


\begin_inset LatexCommand \label{cap:Reparameterisation-example}

\end_inset 


\size small 
Reparameterisation example in 1-D.
 A point moves along the curve a distance 
\begin_inset Formula $S'$
\end_inset 

 from the origin.
 All other points will do so as well to make this a continuous reparameterisatio
n, Each point is moved some distance away from the origin, but no point
 can override another which leads to a clash (and thus ambiguity in interpolatio
n).
\end_inset 


\layout Standard


\begin_inset Note
collapsed false

\layout Standard

\end_inset 


\layout Section

Similarity Measures
\layout Subsection

Introduction
\layout Standard

The rest of this chapter examines and connects concepts, techniques, and
 ideas which are being employed to 'glue' together warps and similarity
 measures.
 Warps and similarity are the two main components of any non-rigid registration
 algorithm.
 More broadly, there are 3 separate 'compartments' to consider, namely:
\layout Enumerate

Warps
\layout Enumerate

Similarity
\layout Enumerate

Objective function
\layout Standard

Having covered the first, the latter two points will be explained in greater
 detail with reference to practical considerations.
 The approach taken is that an image needs to be gradually warped until
 it matches another.
 The match is estimated using similarity measures.
 The process of warping and similarity falls under one generic objective
 function, which is an 'umbrella' in this context.
 In that sense, an objective function serves as a bridge for warps and similarit
y, making the selection of warps improve the similarity.
 Objective functions are then handled by an general optimiser -- that which
 selects warps that increase similarity.
 The remainder of this section deals with various methods of measuring image
 similarity.
\layout Subsection


\begin_inset LatexCommand \label{sub:Measuring-Similarity}

\end_inset 

Methods of Measuring Similarity
\layout Standard


\begin_inset Note
collapsed false

\layout Standard

(COMMENT: UPDATE THIS CROSS-REF -- DONE)
\end_inset 

.
\layout Comment

OLD Comment: Explain about rigid and affine registration..
 then about non-rigid
\layout Comment

NEWER: CHANGED DUE TO CJT: used to say 'general optimiser'
\layout Comment

OLD COMMENT: Show some shape with landmarks moving clockwise as in Chris'
 example
\layout Comment

OLD COMMENT: <FROM MANIFESTO> Existing non-rigid registration algorithms
 use an image-similarity criterion (eg mutual information [REFERENCE] or
 the correlation ratio [REFERENCE]), an image transformation model (eg affine,
 elastic [REFERENCE], fluid [REFERENCE]) <FROM MANIFESTO>
\layout Standard


\begin_inset Note
collapsed false

\layout Standard

Comment: Explain how representing warps -- doubtfully explained above.
 I am not too sure what CJT wants explained in detail.
\end_inset 


\layout Standard

There are various ways of measuring a perceived similarity between two images.
 Sum of pixel- or voxel-wise differences (as well as sum-of-
\emph on 
squared
\emph default 
-differences or even the 
\emph on 
mean
\emph default 
 rather than a summation) emerges as the most intuitive method, which merely
 accumulates pixel- or voxel-wise differences between the images.
 This measure, however, is rather poor at gauging a meaningful extent of
 similarity, particularly if positions where the images which lie in hyperspace
\begin_inset Foot
collapsed false

\layout Standard

One can think of images as though they have been reduced to a vector of
 pixel values, which map onto a position in a high-dimensional space.
\end_inset 

 \SpecialChar ~
are a just short distance apart.
 This can be thought of a case of slight miscorrespondence, wherein the
 images are almost fully aligned.
 This fairly intuitive measure is a good one to use when convergence in
 NRR is foreseen.
\layout Standard

Other image similarity measures are relatively immune to larger spatial
 displacements and mild variabilities in actual form.
 Histograms of intensity values in the images have seen a noticeable rise
 in practical use.
 Intensity values are accounted for globally, or even locally, e.g.
 inside regions whose impact on similarity estimation should be greater.
 These measures prove to be far better assessors of similarity under most
 circumstances.
 Mutual information and normalised mutual information, as described by Studholme
 
\begin_inset LatexCommand \cite{Studholme_nmi}

\end_inset 

, provide good histogram-based measures that see high usage in existing
 non-rigid registration algorithms.
 Each one will be dealt with in turn in the remainder of this section.
\layout Standard

Another method for measuring similarity makes use of the correlation ratio.
 Due to the nature and scope of this thesis, it is less relevant and, in
 principle, goes back over half a century ago 
\begin_inset LatexCommand \cite{Correlation Ratio}

\end_inset 

.
\layout Subsubsection

Mutual Information (MI)
\layout Standard

Viola 
\begin_inset LatexCommand \cite{Viola}

\end_inset 

 developed a method
\begin_inset Foot
collapsed false

\layout Standard

The discovery of mutual information is also attributed to Maes, yet the
 work was sparked by Viola in the mid-nineties.
\end_inset 

 \SpecialChar ~
of measuring similarity between two images by repeatedly comparing histograms
 of pairs of images 
\begin_inset LatexCommand \cite{Pluim_MI,Likar_MI}

\end_inset 

.
 When measuring mutual information, one computes 
\emph on 
informational overlap
\emph default 
 across images.
 If two images are properly aligned, their joint histogram is indicative
 of where 
\emph on 
sharp
\emph default 
 grey-value peaks are located, as well as the sharpness value of these peaks.
 Under the complementary case, which is mis-registration, the joint histogram
 occupancy is expected to include peaks with low magnitude and new steep
 peaks can emerge.
 By defining a joint information (or entropy) to be 
\begin_inset Formula $H(A,B)$
\end_inset 

 and a the information contained in a single histogram 
\begin_inset Formula $A$
\end_inset 

 to be 
\begin_inset Formula $H(A,B)$
\end_inset 

, it is reasonable to argue that MI calculates 
\begin_inset Formula $H(A)+H(B)-H(A,B)$
\end_inset 

.
 There are variants thereof 
\begin_inset LatexCommand \cite{Rueckert_non_rigid}

\end_inset 

, but the prime idea is that joint information is subtracted from the sum
 of information present in the two individual images.
\layout Standard


\begin_inset Note
collapsed false

\layout Standard

Chapter 
\begin_inset LatexCommand \ref{cha:Information Theory}

\end_inset 

 deals with the introduction of information theory and some of the basic
 measures which can explain the following in more detail.
 However, it is the principle that is worth understanding at this stage,
 rather than tedious technicality .
 
\end_inset 


\layout Comment

OLD: The method is....
 (see mi.m)
\layout Subsubsection

Normalised Mutual Information (NMI)
\layout Comment

OLD: Explain what the difference is....
 (w.r.t.
 the above)
\layout Standard

Studholme 
\begin_inset LatexCommand \cite{Studholme_nmi}

\end_inset 

 and Maes 
\begin_inset LatexCommand \cite{maes_nmi}

\end_inset 

 suggested that normalisation should be applied to mutual information.
 Several steps are involved in this normalisation process
\begin_inset Foot
collapsed false

\layout Standard

There is an additional distinction between symmetric and asymmetric normalised
 mutual information, but rationale for this requires the full technical
 recipe.
 The dissertation at 
\begin_inset LatexCommand \htmlurl{http://www.lans.ece.utexas.edu/~strehl/diss/node107.html}

\end_inset 

 summarises the way in which NMI is evaluated.
\end_inset 

.
 The main difference is that the expression used for MI is significantly
 extended and divided by a normalisation term.
 The method is predominantly used in non-rigid registration as it is generic,
 adaptable to new data, and yields better results.
\layout Comment

Old: MI, NMI (mutual info..
 see Rhodri function) etc.
\layout Comment

Old: SUB SUBSECTION?? Correlation Ratio
\layout Subsubsection

Sum-of-Squared-Differences
\layout Comment

COMMENT CJT (see below): Confirm with SSD
\layout Standard

One of the most intuitive and least resource-intensive approaches is the
 sum of differences and its variants.
 Pixels are being compared in two images, one pixel at a time, and their
 (potentially squared) grey-level difference are calculated.
 A sum over all pixel-wise differences is accumulated or averaged over,
 which obtains a measure that is based on the sum-of-squared-differences
 (SSD).
 Mean-of-squared-differences (MSD) is merely the case where the differences
 are averaged over, rather than summed up.
 Other variants include the case where differences are not raised to the
 power of two (squared).
\begin_inset Note
collapsed false

\layout Standard

(CJT: CONFIRM THE TWO PAST SENTENCES WITH SSD) -- DONE.
\end_inset 

This method is usually powerful if the two images compared are closely aligned
 and their intensity values are relatively continuous and low in contrast.
 In many cases, MSD/SSD will tolerate a low level of locally-situated difference
, while contrariwise, MI and NMI properly handle sparse dispersion of pixels
 in some localised region.
\layout Standard

Suggestions have been made over the years with regards to the issue of speeding
 up similarity measures.
 The above measures depend heavily, from an efficiency point-of-view, on
 the dimensions of an image.
 A multi-resolution approach, for example, can be used to speed up the entire
 process.
 Blurring or averaging, followed by re-sampling or sub-sampling, allows
 for images of smaller size to be manipulated and complexity to be quadratically
 lessened.
 As the similarity measures are proportional to the images size, far better
 performance can be achieved by a transition from coarse to finer resolution.
 Pluim 
\emph on 
et al.

\emph default 
 
\begin_inset LatexCommand \cite{Pluim_multi_res}

\end_inset 

 studied the effects that this approach will have on the measurement of
 similarity.
\layout Section

Groupwise versus Pairwise Registration
\layout Standard

A distinction is made between two approaches to tackling the NRR problem.
 Some take the approach wherein one image from a set is chosen as a reference
 (or template) and the remainder of the set is transformed to fit that reference.
 This means that, at the very end, all images will be assimilated to the
 particular reference, which was arbitrarily and possibly ill chosen.
 The other approach is based on the idea that images should be transformed
 to resemble the 
\emph on 
entire
\emph default 
 set, irrespective of an arbitrary choice of a reference image.
\layout Standard

Debates over the validity (or lack thereof) -- that which is inherent in
 the pairwise approach -- are of great relevance to the work presented hereafter.
 The subjective choice of a reference image implies that the results are
 highly dependent upon this choice.
 This leaves room for ambiguity and bias, which motivates the need to evaluate
 the results of NRR algorithms, as well as become independent of any selections
 that make the problem non-deterministic.
\layout Standard


\begin_inset Note
collapsed false

\layout Standard

RSS: Maybe a third section needs to be put here.
 -- DONE (SUMMARY)
\end_inset 


\layout Standard


\begin_inset Note
collapsed false

\layout Section

Summary
\layout Standard

The main concepts that image registration involves are transformation and
 similarity.
 Care must be taken, however, when choosing a proper methods for each.
 By identifying some valuable properties that ought to be preserved, one
 can put together a sensible registration scheme.
\layout Standard

There is yet little agreement on the power of each of the existing methods
 and comparisons are often biased.
 Pointers will be provided to additional methods and approaches in later
 sections.
 Also, several possible results and comparisons will be proposed.
\end_inset 


\layout Standard


\begin_inset Note
collapsed false

\layout Standard

'Spill' over to next page
\end_inset 


\layout Standard


\begin_inset Note
collapsed false

\layout Section

CPS for perturbation explanation later
\end_inset 


\layout Section

Assessment of NRR
\layout Standard

Two main approaches to assessing the accuracy of NRR algorithms have been
 described in the Introduction chapter -- one based on the recovery of known
 deformation fields, the other based on measuring the overlap of ground-truth
 annotations after registration.
 Both approaches are valid, but neither is easy to apply routinely, and
 both are better suited to off-line evaluation of algorithms, rather than
 
\emph on 
in-line
\emph default 
 evaluation of the results of NRR in practical applications.
\layout Subsection

Recovery of Deformation Fields
\layout Standard

One way to test the performance of a registration algorithm is to apply
 it to some 
\emph on 
artificial
\emph default 
 data where the correct correspondence is known.
 The correspondence is obtained by manual annotation, which can be refined
 by repeating the process, reducing or altogether annulling the effect of
 subjective errors.
 The STAPLE algorithm 
\begin_inset LatexCommand \cite{STPLE}

\end_inset 

 from Warfield 
\emph on 
et al
\emph default 
.
 addresses such problems.
 Estimation maximisation is used to account for a number of independent
 observations made by experts who annotate image labels (segmentation).
 No estimate can be considered to be an objective truth, so the distribution
 will be random.
 Making use of this observation was shown to lead to substantial improvement,
 as well as more pronounced and correct boundary edges.
 STAPLE exploits knowledge about uncertainty that is inherent in erroneous
 annotation where subjectivity prevails.
\layout Standard

There is another approach that thrives on ground-truth data and artificial
 warps that get applied to it.
 Having obtained ground truth, degradation of this correspondence can be
 applied.
 Such test data is typically constructed by applying sets of known deformations
 (either spatial or textural) to real images.
 This artificially-deformed data is then registered, and evaluation is based
 on comparing the deformation fields recovered by the registration algorithm
 with those that were applied originally 
\begin_inset LatexCommand \cite{Validation-NRR,schnabel}

\end_inset 

.
 This approach can be used to compare the performance of different NRR algorithm
s but, since it relies on the creation of artificial test data, cannot be
 applied in-line.
 Also, the validity of the approach depends on the ability to construct
 artificial deformations which mimic the variability found in real images
 of a given type, which is difficult to guarantee.
\layout Subsection

Overlap-Based NRR Assessment Methods
\layout Standard

An alternative approach is based on measuring the alignment 
\begin_inset LatexCommand \cite{Hellier}

\end_inset 

, or overlap 
\begin_inset LatexCommand \cite{Hellier,Validation-NRR}

\end_inset 

 of anatomical structures annotated by an expert, or obtained as a result
 of (semi-)automated segmentation.
 This has the disadvantage that manual annotation is expensive to obtain
 and prone to subjective error, whilst reliable automated or semi-automated
 segmentation is extremely difficult to achieve -- indeed if it was available
 it would often obviate the need for NRR.
\layout Standard

In later chapters, an overlap-based approach is used to provide a 'gold
 standard' method of assessment.
 The method requires manual annotation of each image -- providing an anatomical/
tissue label for each voxel -- and measures the overlap of corresponding
 labels following registration, using a generalisation of Tanimoto's overlap
 coefficient 
\begin_inset LatexCommand \cite{Beauchemin}

\end_inset 

.
 Each label for a given image is represented using a binary image but, after
 warping and interpolation into a common reference frame, based on the results
 of NRR, a set of fuzzy label images is we obtained.
 These are combined in a generalised overlap score 
\begin_inset LatexCommand \cite{Crum_MICCAI_2005}

\end_inset 

 which provides a single figure of merit aggregated over all labels and
 all images in the set:
\layout Standard


\begin_inset ERT
status Open

\layout Standard

\backslash 
begin{equation} 
\backslash 
mathcal{O} = 
\backslash 
frac{ 
\backslash 
sum
\backslash 
limits_{
\backslash 
mbox{
\backslash 
small pairs},k}
\backslash 
: 
\backslash 
sum
\backslash 
limits_{
\backslash 
mbox{
\backslash 
small labels},l}
\backslash 
alpha_{l} 
\backslash 
sum
\backslash 
limits_{
\backslash 
mbox{
\backslash 
small voxels},i} MIN(A_{kli},B_{kli})} {
\backslash 
sum
\backslash 
limits_{
\backslash 
mbox{
\backslash 
small pairs},k} 
\backslash 
sum
\backslash 
limits_{
\backslash 
mbox{
\backslash 
small labels},l}
\backslash 
alpha_{l} 
\backslash 
sum
\backslash 
limits_{
\backslash 
mbox{
\backslash 
small voxels},i} MAX(A_{kli},B_{kli})}
\backslash 
label{tanimoto} 
\backslash 
end{equation}
\layout Standard

\backslash 
noindent where $i$ indexes voxels in the registered images, $l$ indexes the labels and $k$ indexes image pairs (all permutations are considered). $A_{kli}$ and $B_{kli}$ represent voxel label values for a pair of registered images and are in the range $[0, 1]$. The $MIN()$ and $MAX()$ operators are standard results for the intersection and union of fuzzy sets. This generalised overlap measures the consistency with which each set of labels partitions the image volume. The standard error in $
\backslash 
mathcal{O}$ can be estimated in the normal way from the standard deviation of the pairwise overlaps.
\layout Standard
The parameter $
\backslash 
alpha_{l}$ affects the relative weighting of different labels. With $
\backslash 
alpha_{l}=1$, label contributions are implicitly volume-weighted with respect to one another. This means that large structures contribute more to the overall measure. Later chapter also consider the case where $
\backslash 
alpha_{l}$ weights labels by the inverse of their volume (which makes the relative weighting of different labels equal), where $
\backslash 
alpha_{l}$ weights labels by the inverse of their volume squared (which gives regions of smaller volume higher weighting), and where $
\backslash 
alpha_{l}$ weights labels by their complexity, which is defined as the mean absolute voxel intensity gradient over the labelled region.
\layout Standard
An overlap score based on a generalisation of the popular Dice Similarity Coefficient (DSC) would also be possible but, since DSC is related monotonically to the Tanimoto Coefficient (TC) by DSC = 2TC/(TC+1) ~
\backslash 
cite{Shattuck2001} it was not considered further.
\end_inset 


\layout Chapter
\pagebreak_top 

\noun on 

\begin_inset LatexCommand \label{cha:Active-Appearance-Models}

\end_inset 


\begin_inset LatexCommand \index{Models}

\end_inset 


\noun default 
Models
\layout Standard
\align right 

\size large 

\begin_inset Quotes eld
\end_inset 

I
\size small 
f you optimize everything, you will always be unhappy.
\begin_inset Quotes erd
\end_inset 


\newline 
-- 
\emph on 
Donald Knuth.
 
\layout Standard


\begin_inset Note
collapsed false

\layout Standard

TMI Text
\end_inset 


\layout Standard


\begin_inset ERT
status Open

\layout Standard

\backslash 
lettrine{T}{ his} chapter contains a gentle introduction to models of shape and appearance -- those which are being evaluated at the core of the work. The approach to ground-truth-free evaluation of NRR depends on the ability, given a set of registered images, to construct a generative statistical model of appearance.  The approach of Cootes et al~
\backslash 
cite{Cootes_ECCV_1998,Edwards}, who introduced models that capture variation in both shape and texture (in the graphics sense), was adopted. These models have been used extensively in medical image analysis. They assist interpretation tasks in, for example, brain morphometry and  cardiac time-series analysis 
\backslash 
cite{Frangi,Rueckert_2003,Stegmann}. 
\layout Standard
Other approaches to appearance modelling could also be considered as, in this application, one relies only on the generative property of such models. Nevertheless, the focus in this chapter remains appearance models of shape and intesity, which are dealt with almost exclusively.
\end_inset 


\layout Section

Statistical Models
\layout Subsection

The Top-down Approach
\layout Standard

This section explains the motivation and nature of active appearance models
 as an image analysis method.
 Image analysis is a broad and generic problem that can be tackled in various
 ways.
 This analysis is fundamental and essential to many routine tasks such as
 industrial inspection, motion analysis 
\begin_inset LatexCommand \cite{Yam}

\end_inset 

, face recognition 
\begin_inset LatexCommand \cite{coupled_view,Li_CVPR_01}

\end_inset 

, and medical image understanding 
\begin_inset LatexCommand \cite{Stegmann_cardiac}

\end_inset 

.
 What makes this problem intrinsically laborious is one's inability to take
 into account single pixels independently and study the structures that
 they form together, cohesively.
 The goal of analysis and interpretation is not only to tackle such problems
 properly, but also to do so efficiently.
 This needs to be done in a manner that is not excessively affected by the
 size of the image, i.e.
 it ought to be scalable.
\layout Standard

Analysis involves 
\emph on 
measurements
\emph default 
 of meaningful structures in an image, as well as explanations pertaining
 the 
\emph on 
form 
\emph default 
of these structures.
 In order to extract and study information from particular meaningful structures
, image 
\emph on 
segmentation
\emph default 
 needs to precede.
 Segmentation is concerned with the identification of several regions of
 interest, which may be characterised as belonging to the same object.
 By sub-dividing the image into such regions, understanding of the nature
 of its constituent components can more intuitively be gained.
\layout Standard

With models, one concentrates on abstraction and adopts a top-down approach
 to analysis of images.
 The approach relies on high-level knowledge about the visual attributes
 of one specific structure.
 Alternatively -- and often more usefully -- this abstraction can represent
 and embody a 
\emph on 
collection
\emph default 
 of structures that 
\emph on 
together
\emph default 
 form another aggregated structure.
 The reason why such an approach is referred to as a top-down approach is
 that it contains existing information which it attempts to 
\emph on 
fit
\emph default 
 to the problem posed
\begin_inset Foot
collapsed false

\layout Standard

A bottom-up approach considers low-level data and builds up towards knowledge
 of greater complexity which has a more substantial meaning.
 Top-down is the opposite approach where a model is aware of what it attempts
 to find, so it searches for a best match at lower levels.
 
\end_inset 

.
 It makes assumptions about the problem and is, in some sense, taking a
 preliminary, hypothesised overview on the structures in an image, as Figure
 
\begin_inset LatexCommand \ref{cap:A-target-image-2}

\end_inset 

 illustrates.
\layout Standard


\begin_inset Float figure
wide false
collapsed false

\layout Standard
\align center 

\begin_inset Graphics
	filename ./Graphics/model.eps
	display none
	scale 70.00

\end_inset 


\layout Caption


\begin_inset LatexCommand \label{cap:A-target-image-2}

\end_inset 


\size small 
A target image 
\begin_inset Formula $\mathbf{T}$
\end_inset 

 (greyscale bacground) is being overlaid with a high-level representation
 (the model 
\begin_inset Formula $\mathbf{M}$
\end_inset 

), which seeks a good fit in the target image by transforming itself.
\end_inset 


\layout Subsection

Rationale
\layout Standard

In many cases, image analysis tasks are better handled by a top-down approach.
 Not only is a top-down approach capable of gathering information about
 an image at hand, but in the case of model-based analysis, it is also capable
 of generating new images.
 The importance of this property lies in the fact that infinitely many unseen
 images can be derived from the model.
 These images can be used in various ways in a practical setting.
 One application, for example, involves the fitting to data, as explained
 at the end of this chapter.
 The model is deformed to resemble an image and, from this deformed model,
 images can be learned.
 Beyond this popular class of applications, worth mentioning is the fact
 that the thesis introduces a new application for models.
 On the one hand, models can be evaluated, whilst in practice, they can
 also be used to assess the quality of NRR.
\layout Section

Shape Models
\layout Standard

Given a collection of images depicting an object which possesses common
 properties, it is possible to model the visual form (or 
\emph on 
shape
\emph default 
) of that object.
 This model can be built in a way that makes it independent from subtle
 changes in view-point, object position, size etc.
 Such a model can be made robust to moderate levels of object deformation,
 too.
 The object which appears in the group of images need not be the exact same
 object; it can be an object belonging to one common 
\emph on 
class
\emph default 
.
 Variation that is typical for that class can be handled, and essentially
 be understood 
\begin_inset LatexCommand \cite{Beg}

\end_inset 

, as well.
 Learning of this variation can be done quite reliably with the help of
 elementary transformations.
 Such transformations were described in section 
\begin_inset LatexCommand \vref{sub:Transformations}

\end_inset 

, but their functionality is limited and constrained.
 They are merely the means by which segmented images (or shapes) are forced
 into a state of alignment.
 The process of alignment says something about the variation in shape.
\layout Standard

There are statistical methods that facilitate the encoding of the variability,
 which is 
\emph on 
learned
\emph default 
 during a so-called 
\emph on 
training process
\emph default 
.
 That training process does not require more than an exhaustive pass through
 the set of images where objects appear, then probing the distribution of
 points.
 However, in order to interpret a large set of objects, several simplification
 steps are required.
 This results from the fact that most images where objects lie are relatively
 large-scale in practice.
 These are large enough to result in an exponential blow-up
\begin_inset Foot
collapsed false

\layout Standard

Currently, model-based methods typically deal with only the order of tens
 of thousands of pixels.
 High-resolution medical images can contain millions of pixels/voxels.
 
\end_inset 

.
 Reduction of the dimensionality of the data is thus needed.
\layout Subsection

Deformable Models
\layout Standard

A method is sought which reduces the amount of information that is required
 to describe an object of interest.
 As well as describing that object, this method should consider the different
 forms this object may take -- particular those which deem both suitable
 and valid.
 In practice, this is essentially achieved by selecting points of interest
 which lie within the image, preferably ones which are a representative
 sub-set of the whole image.
 Points need to be picked so that they jointly encapsulate knowledge about
 the object of interest.
 In most cases, edge detection is sufficient for capturing and selecting
 regions or points of greater significance in the image.
 Edges and corners tend to hold more information of value for subsequent
 analysis (e.g.
 segmentation).
 These points lead to better identification of the different objects residing
 in the image.
 Such points become what is referred to as 
\emph on 
landmarks
\emph default 
.
\layout Standard

Landmarks are positions in the image which can effectively distinguish one
 object from another object in a similar image.
 They are represented and encoded as a set of points in a set of images
 (see Figure 
\begin_inset LatexCommand \vref{cap:Landmark-identification}

\end_inset 

).
 They possess interesting spatial traits and they can be used to render
 curves (or contours), which together make up complete 
\emph on 
shapes
\emph default 
.
 The concatenation of the coordinates of these landmarks describes an image
 (or rather the object being dealt with) using a more concise representation,
 which is lossy
\begin_inset Foot
collapsed false

\layout Standard

The loss is a necessary evil when the complexity of the data is reduced.
 The greater the number of landmark points, the higher the fidelity (as
 well as complexity).
\end_inset 

.
 As an example, in 2-D, for 
\begin_inset Formula $n$
\end_inset 

 landmarks, a vector of size 
\begin_inset Formula $2n$
\end_inset 

 can faithfully describe the shape of the object present in an image.
 This object can be encoded as follows.
\layout Standard


\begin_inset Formula \begin{equation}
(x_{1},y_{1},x_{2},y_{2},...,x_{n},y_{n})\Rightarrow\mathbf{S}\label{eq: landmarks}\end{equation}

\end_inset 


\layout Standard

where 
\begin_inset Formula $\mathbf{S}$
\end_inset 

 is simply a discrete reconstruction of the shape in the image.
 This does 
\emph on 
not
\emph default 
 embody the actual image, but only key characteristics of it.
 This proves to be sufficient for good approximations to be made.
\layout Standard


\begin_inset Note
collapsed false

\layout Standard

Comment: For the nave pixel-wise representation, not only will a space
 of width x height need to be allocated, but also the manipulation process
 on this data will slow down considerably.
\layout Standard

Comment: and their low proximity
\layout Standard

Comment: referred to as landmarks from here onwards
\end_inset 


\layout Standard
\align center 

\begin_inset Float figure
wide false
collapsed false

\layout Standard
\align center 

\begin_inset Graphics
	filename ./Graphics/asm.eps
	display none
	scale 70.00

\end_inset 


\layout Caption


\begin_inset LatexCommand \label{cap:Landmark-identification}

\end_inset 


\size small 
Landmark identification and mark-up in medical images
\end_inset 


\layout Subsection

Correspondence
\layout Standard

Chapter 2 alluded the the notion of image correspondence.
 The use of the term, in that context, referred to a dense, pixel-to-pixel
 correspondence.
 From here onward, when the notion of models and landmark points is discussed,
 the term 
\begin_inset Quotes eld
\end_inset 

correspondence
\begin_inset Quotes erd
\end_inset 

 deals with correspondence across landmark points, rather than that which
 involves all pixels contained in the images.
\layout Subsection

Principal Component Analysis (PCA)
\layout Comment

CJT: IT IS NOT ENTIRELY CLEAR FROM THE TEXT THAT Xi and Gi are produced
 in exactly the same way.
 -- DONE
\layout Standard

One can perceive and visualise the images dealt with as points in a high-dimensi
onal space, as was earlier suggested.
 By placing all images in that space, it is expected that some cloud of
 points will be present at a specific, albeit somewhat confined, region.
 The breadth of this region (or the size of that cloud) will depend on the
 variation amongst the images (or more generally -- data) which is being
 visualised.
\layout Standard

PCA is a method which relies on Eigen analysis.
 In essence, it obtains the Eigen-vectors and Eigen-values of a cloud of
 points, decomposing it into a set of vectors with their magnitude.
 
\begin_inset Note
collapsed false

\layout Standard

COMMENT: THE NEXT 3-4 SENTENCES ARE NOT CLEAR OR PRECISE - CJT ----Done
 loosely
\end_inset 

The highest Eigen-value corresponds to the most significant Eigen-vector
 (see the single-headed arrow in Figure 
\begin_inset LatexCommand \ref{cap:Principal-component-in}

\end_inset 

).
 It symbolises the direction which best distinguishes the image data.
 As as arrow, it is expected to be the longest one too -- that is -- the
 one whose magnitude is the greatest
\begin_inset Foot
collapsed false

\layout Standard

If one thinks of the cloud in 
\begin_inset Formula $n$
\end_inset 

 dimensional space as a placement of characteristics 
\begin_inset Formula $(c_{1},c_{2}...c_{n})$
\end_inset 

, the principal component is one characteristic which best separates instances
 of the data.
 It picks the largest range of variation and uses it in decomposition.
\end_inset 

.
 This vector is considered to be the principal component which describes
 that data.
 it serves as the most effective discriminant.
\layout Standard

In a recursive manner, and at each stage of the process, the current principal
 component is being studied (e.g.
 incorporated in a model's covariance matrix) and then set aside, by being
 reduced/annulled.
 The process is repeated until only negligible components (dimensions or
 vectors) remain present.
 As a whole, it is a progressive dimensionality reduction routine where
 data dimensionality us reduced at each stage, until only dimensions which
 contain noise are left.
 At each stage, this recursive function will therefore deal with simpler,
 denser, and more uniformly-distributed data.
 More and more principal components are set aside, leaving in tact data
 of lower dimensionality that occupies a relatively low volume in space.
\layout Standard

A smaller number of components can then be used to express the variation
 up to a comparatively high level of accuracy.
 The process is lossy, much like any of the other stages in model construction,
 including the choice of a finite number of landmarks.
 That loss is being controlled in the sense that one can choose the minimal
 amount of variation which must be accounted for
\begin_inset Foot
collapsed false

\layout Standard

A sensible choice might be, for example, 98% of the observed variation,
 which means that 2% of the variation is not accounted for.
 In practice, that 2% of the overall variation is usually the least informative
 and it is possibly made up from noise and error.
 Annulling this effect is, among other things, what PCA is intended to accomplis
h.
\end_inset 

.
 PCA is used to gain speed while retaining the best descriptors of variation
 or difference in shape and intensity.
 What this boils down to is the building of a model that is smaller in size
 and is easier to deal with.
 It is easier to deal with because: 
\series bold 
(1) 
\series default 
it is smaller; 
\series bold 
(2)
\series default 
 it is quicker, e.g.
 to reach convergence and 
\series bold 
(3)
\series default 
 some of its key attributes have been decomposed, which may be useful in
 learning.
\layout Standard
\align center 

\begin_inset Float figure
wide false
collapsed false

\layout Standard
\align center 

\begin_inset Graphics
	filename ./Graphics/pca.eps
	display none
	scale 70.00

\end_inset 


\layout Caption


\begin_inset LatexCommand \label{cap:Principal-component-in}

\end_inset 


\size small 
The principal component in a 2-D data scatter is indicated by the arrow
\end_inset 


\layout Standard


\begin_inset Note
collapsed false

\layout Standard

Instead, a short explanation will be given on Principal Component
\begin_inset Foot
collapsed false

\layout Standard

Plainly speaking, PCA only picks up 
\begin_inset Formula $n$
\end_inset 

 Eigen-values whose Eigen-values are the greatest.
\end_inset 

 \SpecialChar ~
Analysis 
\begin_inset LatexCommand \cite{PCA,twining_PCA}

\end_inset 

 which from here onwards be referred to as PCA.
 What is worth emphasising is that the only variant in the model described
 above is 
\begin_inset Formula $\mathbf{b}_{s}$
\end_inset 

 and as the values of 
\begin_inset Formula $\mathbf{b}_{1<i<s}$
\end_inset 

 are infinite (
\begin_inset Formula $\mathbf{b}_{1<i<s}$
\end_inset 


\begin_inset Formula $\in\mathbb{\mathbb{Z}}$
\end_inset 

), the same must hold for 
\begin_inset Formula $\mathbf{x}$
\end_inset 

.
 There is an infinite number of shapes, each of which can be generated from
 one choice of value for each model parameter.
 One interesting alternative to PCA was presented in 
\begin_inset LatexCommand \cite{Jebara}

\end_inset 

 By Jebara.
\end_inset 


\layout Comment

IMPORTANT FOR CR: CJT: What is the distinction you draw between PCA and
 Eigen analysis -- FIXED
\layout Comment

(LEFT OUT: Because there is a total of 
\begin_inset Formula $n$
\end_inset 

 modes of variation, 
\begin_inset Formula $1<s<n$
\end_inset 

, i.e.
 only 
\begin_inset Formula $n$
\end_inset 

 parameters exist.)
\layout Subsection


\begin_inset LatexCommand \label{sub:Appearance-Model-Construction}

\end_inset 

Model Construction
\layout Standard


\begin_inset Note
collapsed false

\layout Standard


\begin_inset LatexCommand \label{sub:Appearance-Model-Construction}

\end_inset 

Model Construction
\end_inset 


\layout Standard

An integral part of any appearance model is its construction.
 This initial formation step defines what the model encapsulates.
 Construction also affects the validity and quality of the model.
\layout Standard

The construction process can be broken down into various steps.
 The first step is concerned with the establishment of a model that is not
 only 'acquainted with' the 
\emph on 
mean
\emph default 
 form of some object (if not the image as a whole) in a set of images, but
 also the variation that can be applied to that mean in order to create
 new instances of that object.
 This model dictates which values several vectors can take.
 Each of these vectors can be translated into a visual form, i.e.
 image pixels which the vector affects.
\layout Standard

More desirable models should never be excessively bendable.
 They should be generic, flexible and permissive, but remain strict and
 confined at the same time.
 These models should accept as valid more reasonable variations of the object
 under investigation.
 One property is referred to as Specificity as it forces the model to remain
 specific.
 Conversely, and in a complementary manner, the model should properly represent
 a large set of images and be general.
 We refer to this property as Generalisation and elaborate on it in Chapter
 6.
\layout Standard

There is a convenient mathematical method for expressing variation.
 It also happens to be linear (non-linear equivalents exist as well 
\begin_inset LatexCommand \cite{Romdhani_BMVC_99}

\end_inset 

), which has its pros and cons.
 The method involves assigning a parameter to each mode of variation.
 When change to these parameters is applied, the mean image is deformed
 accordingly and there will be a direct effect on its appearance.
 Rather usefully, each valid image can be uniquely and fully described by
 the parameters which were used to generate it from the model.
 The synthetic appearance and its vector representations are equivalent
 and inter-changeable.
 What follows explains how models are being constructed, in technical terms.
\layout Subsection

Shape Models 
\layout Comment

(COMMENT: shape - FIXED) 
\layout Comment

(COMMENT: where that result is really just a simple vector - FIXED) 
\layout Standard

Shape models are a simplified version of full appearance models.
 Chronologically, shape models precede appearance models as appearance is
 dependent on shape.
 Models of appearance essentially extend shape by adding dense intensity
 information.
\layout Standard

To encode the shape of an object, landmarks need to be identified and statistica
l analysis applied to them.
 A vector of landmarks is formed which expresses spatial properties, namely
 a series of landmark coordinates.
 From a simple analysis, a mean shape is obtained and it can be denoted
 by 
\begin_inset Formula $\mathbf{x}_{mean}$
\end_inset 

 or 
\begin_inset Formula $\mathbf{\overline{x}}$
\end_inset 

.
 To arrive at this mean, the method most commonly used is Procrustes analysis.
 The generalised Procrustes procedure (or GPA for Generalised Procrustes
 Analysis) was developed by Gower in 1975 and has been adapted for shape
 analysis by Goodall in 1991.
 It studies each component of the vectors derived from the images and returns
 for each component a value that is said to be the mean.
 From here onwards, this vector which represents the mean of the data will
 be referred to as 
\begin_inset Formula $\mathbf{\overline{x}}$
\end_inset 

.
 Each shape 
\begin_inset Formula $\mathbf{x}$
\end_inset 

 can thus be formulated as indicated below
\layout Comment

IMPORTANT FOR CR: CJT: I am not clear about the meaning of parameters --
 EXPLAINED IN MORE DETAIL NOW.
\layout Quote


\begin_inset Formula \begin{equation}
\mathbf{x}=\mathbf{\overline{x}}+\mathbf{P}_{s}\mathbf{b}_{s}.\label{eq: Shape model}\end{equation}

\end_inset 


\layout Standard

The matrix 
\begin_inset Formula $\mathbf{P}$
\end_inset 

 represents the Eigen-vectors of the covariance matrix (set of orthogonal
 modes of variation) and the parameters 
\begin_inset Formula $\mathbf{b}_{s}$
\end_inset 

 control the variation of the shape by altering modes of variation.
 The parameters essentially describe the magnitude of the covariance of
 each element in the matrix.
 These parameters and the range within which they lie describe a level of
 freedom -- that is -- the freedom (or contrariwise -- constraints) of the
 model.
 Eigen-analysis is used in the derivation of the expression above, as was
 discussed in this chapter.
\layout Standard

It is important to note that landmark points could be chosen 
\emph on 
arbitrarily.
 
\emph default 
However, this results in poor models.
 It lead to serious issues as images need to be correspondent, i.e.
 points should aligned to exhibit on their spatial commonality.
 Identification of objects is in most cases done by drawing lines or selecting
 surfaces which surround these objects, to form segments.
 Given continuous elements such as a lines or surfaces, it is not obvious
 how to suitably sample from them in the form of points.
 The choice of points affects the quality of reconstruction, as measured
 by the assigned errors.
\layout Standard


\begin_inset Note
collapsed false

\layout Standard

CJT SAID BEFORE THE ABOVE PARAGRAPH ADDED: ULTIMATELY THERE IS NOT A VERY
 DEEP EXPLANATION OF LANDMARKS AND HOW THEY CAN BE ARBITRARILY CHOSEN
\end_inset 


\layout Standard

With the concise landmark-based representation (described in Equation 
\begin_inset LatexCommand \ref{eq: landmarks}

\end_inset 

) assumed to be the convention and a collection of decent-sized vectors
 rather than a large collection of images and pixels/voxels, it should be
 possible to express (in a feasible way) the legal range
\begin_inset Foot
collapsed false

\layout Standard

The legal range can be thought of as the values a parameters may take.
 In reality, a Gaussian distribution usually fits the observed range rather
 well.
\end_inset 

 \SpecialChar ~
of each one of the vector components.
 This, in essence, establishes the 
\emph on 
model
\emph default 
.
 It is an entity that can be manipulated to reconstruct all the shapes (or
 as later explained -- images) it originates from, and far beyond that.
 This model encapsulates the variation which was learned from the data and
 it usually improves its performance as more legal examples are interpreted
 and 'digested' to support further training.
 Varying the parameters of the model can generate new (yet unseen) examples
 as long as that value variation is restricted by the legal range, as learned
 from the training examples.
 The vector representation mentioned beforehand can be also perceived as
 a description of a fixed location in space that comprises 
\begin_inset Formula $d$
\end_inset 

 dimensions (see illustrative scatter in Figure 
\begin_inset LatexCommand \ref{cap:3-D-Scatter}

\end_inset 

).
 This turns out to be a useful demonstrative idea as will be seen later
 when dimensionality reduction is applied.
\layout Standard
\align center 

\begin_inset Float figure
wide false
collapsed false

\layout Standard
\align center 

\begin_inset Graphics
	filename ./Graphics/scatter.eps
	display none
	scale 70.00

\end_inset 


\layout Caption


\begin_inset LatexCommand \label{cap:3-D-Scatter}

\end_inset 


\size small 
3-D scatter of points, which illustrates data embedment in hyperspace
\end_inset 


\layout Standard

To discuss caveats, shape models merely contain statistical information.
 They can be built from the images with overlaid landmark points identified
 and assembled.
 In order to make such a modeling approach possible, it is vital to seek
 consistency amongst the coordinates of all landmarks.
 This means that all points need to be projected onto a common space --
 a process whose purpose is to ease collective analysis.
 That process can also be thought of as an alignment step which somehow
 links to the next chapter
\begin_inset Note
collapsed false

\layout Standard

(COMMENT: CJT did not like the previous sentence.
 Needs more detail) - Fixed in a questionable way
\end_inset 

.
 More issues that are concerned with normalisation, projection and the like
 are described in slightly more detail later in this thesis.
\layout Standard

A human expert usually performs annotation or landmarking of the images
 with the aid of some computerised special-purpose tools.
 In recent years, alternatives which are automatic showed great promise
 
\begin_inset LatexCommand \cite{Davies_MDL}

\end_inset 

 and they were also extended to 3-D 
\begin_inset LatexCommand \cite{Davies_Hippocampus}

\end_inset 

.
 The later chapter on MDL shape models is dedicated purely to that one strand
 of work which is so fundamental to the newly-proposed method.
\layout Standard


\begin_inset Note
collapsed false

\layout Standard

(COMMENT: CJT did not like this part about Stegmann:: OK - resolved)
\end_inset 


\layout Section

Appearance Models
\layout Standard

Appearance models were developed by Edwards 
\emph on 
et al.

\emph default 
 
\begin_inset LatexCommand \cite{Edwards_98_AAM,AAM_IEEE}

\end_inset 

.
 Their greatest contribution, advantage, and essence lie within the fact
 that they contain grey-level data, rather than just shape-specific data.
 Incorporation of full colour was made possible as well (e.g.
 Stegmann 
\emph on 
et al.

\emph default 
 
\begin_inset LatexCommand \cite{Stegmann}

\end_inset 

) since colour can be simply thought of as an extension of the single grey-scale
 band being divided up into the most common separability: red, green and
 blue components 
\begin_inset Foot
collapsed false

\layout Standard

There are different possible colour schemes 
\begin_inset LatexCommand \cite{petrou}

\end_inset 

, but they need not have any affect on principles of sampling intensities.
\end_inset 

.
\layout Standard

Appearance models contain intensity
\begin_inset Foot
collapsed false

\layout Standard

Patterns of intensities form texture.
\end_inset 

 information that is extracted from images by interpolating between landmark
 points.
 As a result, appearance models contain information about what an image
 
\emph on 
looks
\emph default 
 like rather than just its 
\emph on 
form,
\emph default 
 as visualised by contours (or surfaces in 3-D).
 Grey-level values (also referred to as 
\emph on 
intensity
\emph default 
 or 
\emph on 
texture
\emph default 
) could be systematically extracted from a normalised image and be stored
 in an intensity vector for subsequent steps of the algorithm.
 The normalisation process and representation of this intensity vector will
 be outlined later in this section.
\layout Standard

What enables synthesis from appearance models to possess great resemblance
 to reality is the fact that, at the later stages of the construction process,
 a 
\emph on 
combined
\emph default 
 model is made available and it produces dense pixels rather than meshes
 or contours.
 The linear model incorporates 
\emph on 
both 
\emph default 
shape and intensity and it expresses the way in which a change in intensity
 affects shape, and visa versa (e.g.
 how an expansion results in darkening of an image region).
 The model studies notion of the 
\emph on 
correlation
\emph default 
 between the two -- a notion that is dependent on the training data and
 principal component analysis algorithm chosen.
 Although appearance models are not as simple and fast to build as shape
 models, they contain all the information that is incorporated in shape
 models and, in that sense, are a superset of shape models
\begin_inset Note
collapsed false

\layout Standard

(COMMENT: CJT: In what sense? In principle they can be)
\end_inset 

.
\layout Standard

Some techniques have been developed and employed to speed up the matching
 of appearance models to image targets.
 Tasks such as the matching of an appearance model to some target image
 are described later in this chapter and are further illustrated in 
\begin_inset LatexCommand \cite{atlas_aam}

\end_inset 

.
\layout Subsection

Intensity Models
\layout Standard

The first stage in construction of an appearance model involves the sampling
 of texture.
 It assumed that a shape model was already obtained.
 Texture in this context is a patch of pixels intensities.
 In principle, having obtained a description of shape variation from a set
 of shapes, as well as their spatial correspondences, it is possible to
 identify homologous points in between these correspondences.
 This makes possible the approximations of the 
\emph on 
denser
\emph default 
 correspondence -- that which involves larger, continuous parts of the image,
 rather than points only.
 The description below illustrates one possible way of sampling intensities.
 Construction of an intensity model is carried out in the exact same way
 as was done for shapes (Equation 
\begin_inset LatexCommand \ref{eq: Shape model}

\end_inset 

).
\layout Standard

At this construction stage, each of the images, encoded as shape vectors,
 needs to be aligned to fit a bounding volume in space
\begin_inset Foot
collapsed false

\layout Standard

A normalisation step as such is similar to mapping onto a sphere, for instance.
\end_inset 

.
 In practice, the properties of that space are implicitly defined by the
 mean shape
\begin_inset Foot
collapsed false

\layout Standard

Oftentimes, the choice of the mean shape proves to be the least damaging
 choice, in terms of overall accuracy.
\end_inset 

.
 Rigid (or Euclidean similarity) transformations, namely translation, scale
 and rotation, are rarely sufficient in warping all images/points into that
 common space.
 For example, in the case of human face recognition, different head sizes
 and facial expressions introduce great difficulties.
 Nonetheless, it is crucial that good fitting is obtained before the sampling
 of grey-levels.
\layout Standard

Following these basic transformations which align all images, displaced
 control points on each image overlap and contain in between them shape-normalis
ed patches.
 These patches are made available for construction of texture vectors.
 Barycentric arithmetics, renowned for their frequent utility in computer
 graphics and stereo vision, are used to identify the location of all correspond
ing points within a patch
\begin_inset Foot
collapsed false

\layout Standard

It is helpful to think of two different triangles and the relationship between
 points within these triangles.
 Centre of gravity (CoG) is used here to assign approximate correspondence.
\end_inset 

.
 This location of point is directly affected by the warps applied to shift
 a given shape onto the space of the mean shape.
\layout Standard

Triangle meshes are subsequently created by stretching lines between neighbourin
g control points and intensity values are captured one by one (along a chosen
 grid of points to be sampled) and are used to form a vector representative
 of texture.
 Each component in such a vector captures the intensity (or colour) of one
 single pixel, as was learned from the examples.
 Statistical analysis, which is not different from the former cases, results
 in a linear expression for texture
\layout Comment

IMPORTANT FOR CR: CJT: The above is neither clear nor precise.
 This is a special case of how texture is constructed.
 --DONE - Explained in more detail and special case is declared at the start.
\layout Quote


\begin_inset Formula \begin{equation}
\mathbf{g}=\overline{\mathbf{g}}+\mathbf{P}_{g}\mathbf{b}_{g}.\label{eq: Intensity model}\end{equation}

\end_inset 


\layout Standard


\begin_inset Formula $\mathbf{g}$
\end_inset 

 is the intensity and the other parameters are the same as for the shape.
 The process is not different from dimensionality reduction in the case
 of shape.
\layout Standard

The use of the algorithm above implies that, for small vectors (i.e.
 a low number of pixels sampled), coarse appearances will be easier to spot
\begin_inset Foot
collapsed false

\layout Standard

Analogically, in the case of shape, sharp-bended descriptors result from
 the low number of sample points.
\end_inset 

.
 Objects will often appear to be nothing more than a collection of polygons
 that do not quite resemble realistic appearances
\begin_inset Foot
collapsed false

\layout Standard

One of the main aims and great power of appearance models is full synthesis.
\end_inset 

.
 To compensate for this, algorithms can be used for shading.
 In practical use, Geodesic interpolation is used and the results can be
 rather rich, considering the low dimensionality of the available data.
\layout Subsection

Combined Models
\layout Standard

The models in Equations 
\begin_inset LatexCommand \ref{eq: Shape model}

\end_inset 

 and 
\begin_inset LatexCommand \ref{eq: Intensity model}

\end_inset 

 take a linear form, so they are quite compact.
 This is a highly desirable property that makes the models flexible and
 manageable.
 The simplification is made possible owing to PCA, which reduces the size
 of vectors of shape and texture.
 As mentioned before, Eigen-analysis is involved in the process, but it
 has a few caveats.
 For example, in simpler cases, it assumes that none of the distributions
 is banana-shaped.
 This approach works more gracefully under the assumption that all distributions
 are normal.
 While this may be acceptable and plausible in practice, it adds a prerequisite
 to the method.
 There are other methods for decomposing data which resides in a high-dimensiona
l space, but they will not be further explored.
\layout Standard

The two model components, 
\begin_inset Formula $\mathbf{x}$
\end_inset 

 and 
\begin_inset Formula $\mathbf{g}$
\end_inset 

 (the vectors above, which are a function in generative models), need to
 be merged in order to establish a new model that blends both types of variation.
 This expressive model accounts for both types of variability (shape and
 intensity) and holds within it the correlation between the two.
 It means that any variation in shape will affect intensity too, and vice
 versa.
\layout Standard

The parameters 
\begin_inset Formula $\mathbf{b}_{s}$
\end_inset 

 and 
\begin_inset Formula $\mathbf{b}_{g}$
\end_inset 

 are aggregated to form a single column vector
\layout Comment

CJT: verbose and not very exact.-- DONE VERY ROUGHLY
\layout Comment

y, some weighing is ??strongly recommended?? (CHANGE THIS == CJT) -- DONE
 APPARENTLY
\layout Standard


\begin_inset Formula \begin{equation}
\left\{ \begin{array}{cc}
\mathbf{b}_{s}\\
\mathbf{b}_{g}\end{array}\right\} .\label{eq: parameters of model}\end{equation}

\end_inset 


\layout Standard

The new vector is a simple concatenation of the two.
 However, since the values of intensity and shape can be quite different
 in terms of their nature and granularity, some weighting is needed to attain
 a state of equilibrium, under which both shape and intensity accrue and
 attain a sufficiently-noticeable effect and impact.
 It is a normalisation step.
 
\begin_inset Note
collapsed false

\layout Standard

(THIS NEXT SENTENCE: is very vague - CJT) -- REWRITTEN AND EXPANDED
\end_inset 

 The danger is that if no weighing of any sort is applied, intensity values
 may supersede these of shape or vice versa.
 In less practical terms, if the extent of data values differs greatly,
 then spread of the points in space will be undesirably imbalanced.
 Thus, the components to be identified by PCA are not as beneficial as they
 otherwise would have been (very elongated distributions being one example).
 To use a 3-D analogy, if some values in the vectors are significantly greater
 than others, point vicinity takes a turn for the worse and the cloud might
 be flat instead of roughly spherical
\begin_inset Foot
collapsed false

\layout Standard

As an example, intensity frequently takes values in the range 
\begin_inset Formula $0..255$
\end_inset 

 whereas normalised shape coordinates lie between 0 and 1, so fractions
 such as 
\begin_inset Formula $\frac{1}{255}$
\end_inset 

 can be used as coefficients.
 The two should then scale almost indifferently.
\end_inset 

.
 For a relatively spherical spread of data points (or those of almost homogeneou
s variation), a greater number of large components will be available for
 selection by PCA.
 Consequently, the variation expressed by a fixed and constant number of
 principal components will be higher.
\layout Standard

A weighing matrix that resolves the problem introduced above is by convention
 named 
\begin_inset Formula $\mathbf{W}_{s}$
\end_inset 


\begin_inset Foot
collapsed false

\layout Standard

The symbol 
\begin_inset Formula $s$
\end_inset 

 stands to 
\emph on 
shape,
\emph default 
 as by default this matrix scales the shape parameters only.
 It gives logically equivalent results to these of applying the factor 
\begin_inset Formula $\mathbf{W}_{g}=\frac{1}{\mathbf{W}_{s}}$
\end_inset 

 to intensities.
\end_inset 

.
 The form in which coordinates get bound to 
\begin_inset Formula $\mathbf{x}$
\end_inset 

 depends on the level of accuracy required, the image size and the number
 of dimensions, whereas for grey-level values, this form is dependent on
 the number of bits allocated per pixel
\begin_inset Foot
collapsed false

\layout Standard

For colour it is common to use 24 bits and for grey-level just 8 bits.
 For more compact statistical appearance models, less than 8 bits (256 shades
 of grey) might suffice to achieve good results and, in medical imaging,
 12 bits are nearly a standard in acquisition.
 
\end_inset 

.
 With weighing in place, the aggregation takes the form
\layout Standard


\begin_inset Formula \begin{equation}
\left\{ \begin{array}{cc}
\mathbf{W_{\mathbf{s}}}\mathbf{b}_{s}\\
\mathbf{b}_{g}\end{array}\right\} \label{eq: combined model weighting}\end{equation}

\end_inset 


\layout Standard

where 
\begin_inset Formula $\mathbf{W}_{s}$
\end_inset 

 is chosen to minimise inconsistencies due to scale.
 Lastly, by applying another PCA stage to the aggregated data, the following
 combined model is obtained
\layout Standard


\begin_inset Formula \begin{equation}
\begin{array}{cc}
\mathbf{x}_{i}=\bar{\mathbf{x}}+\mathbf{Q}_{s}\mathbf{c}_{i}\\
\mathbf{g}_{i}=\mathbf{\bar{g}}+\mathbf{Q}_{g}\mathbf{c}_{i}\end{array}.\label{eq: combined model}\end{equation}

\end_inset 


\layout Standard

The appearance (shape and brightness levels) is now purely controlled by
 the parameters 
\begin_inset Formula $\mathbf{c}_{1},\mathbf{c}_{2},...,\mathbf{c}_{n}$
\end_inset 

 and there is no need to choose values for two 'families' of distinct parameters
, as argued before.
 This combined model has the benefits of the dimensionality reduction performed,
 which is based on shape as well appearance.
 This means that it finally encompasses all the variation learned and the
 correlation between these two distinct components.
 Since PCA was applied, the number 
\begin_inset Formula $n$
\end_inset 

 of parameters 
\begin_inset Formula $\mathbf{c}_{i}$
\end_inset 

 is expected to be smaller than (or in extremity -- equal to) the number
 of parameters in 
\begin_inset Formula $\mathbf{b}_{s}$
\end_inset 

 and 
\begin_inset Formula $\mathbf{b}_{g}$
\end_inset 

 put together.
\layout Section

Active Models and Fitting
\layout Standard

This section is concerned with search for model matches in images, for analysis
 purposes.
 This process is also known as model fitting.
 It is possible owing to the process characterised by active model 
\emph on 
training
\emph default 
, which involves extending an appearance model.
 This aspect of the work explains and exemplifies how to 
\emph on 
use 
\emph default 
appearance models.
 They could be used in a variety of ways, but models can also be discarded
 once built if no special functionality is necessary, e.g.
 in the case of model-based registration (Chapter 4).
 Training will be dealt with first and fitting, which is a closely-related
 aspect, will be explained in the subsequent subsections.
\layout Subsection


\begin_inset LatexCommand \label{sub:Active-Model-Training}

\end_inset 

Model Training
\layout Standard


\begin_inset Note
collapsed false

\layout Standard

Comment: Modify the name above and possibly deal with size of section by
 breaking it down to sub-subsections.
 DO BREAK IT DOWN (RSS, 10/7/04) -- DONE
\end_inset 


\layout Standard

A statistical model is available for exploration at this stage, having built
 it from a set of training images.
 That model is a flexible deformable entity 
\begin_inset LatexCommand \cite{shape_detection}

\end_inset 

 that can be used to describe the variation observed in the set of training
 images.
 It can also be used in a 'generative mode' to resemble instances of an
 object or a image
\begin_inset Foot
collapsed false

\layout Standard

The distinction between object or image is hard to make because the model
 can describe more than one valid independent object and usually represents
 only a partial region of the entire image.
 In a medical context, the term 
\emph on 
atlas
\emph default 
 fits well and it usually describes a single organ or anatomical structure.
\end_inset 

 \SpecialChar ~
that resides in the range of the training set
\begin_inset Foot
collapsed false

\layout Standard

The word 
\begin_inset Quotes eld
\end_inset 

range
\begin_inset Quotes erd
\end_inset 

 is a terminological equivalent to the area which stretches in between the
 space of training set instances.
 It can be perceived as the space defined by a potentially-Gaussian distribution
 that makes up the training set.
\end_inset 

.
\begin_inset Note
collapsed false

\layout Standard

(CJT: THE FOLLOWING FEW PARAGRAPHS ARE DIFFICULT TO MOTIVATE WITHOUT...
 MODEL MATCHING FIRST....)
\end_inset 


\layout Subsection


\begin_inset LatexCommand \label{sub:Fitting}

\end_inset 

Model Fitting
\layout Standard

The fitting of a model involves use of knowledge to analyse observations
 that have been made.
 To motivate model matching or fitting, one can argue that the previously-constr
ucted model involved a learning (or training) process which should somehow
 be exploited.
 For it is now known what objects of some type look like, it is possible
 to recognise and capture new objects of the same type.
\layout Standard


\begin_inset Note
collapsed false

\layout Standard

The paragraph above was added in July 2004 but it is not perfect at all.
\end_inset 


\layout Standard

Models can be varied by changing values of their parameters.
 It is not obvious how one should deform the model to reach an appearance
 that is reasonably similar to a given image.
 It is a completely opposite and complementary problem that one who explores
 this model will be faced with: how can a model generate new image instances
 after similar existing images instances generated that one model? In some
 sense, an inverse operation is needed, so that the model can be used in
 the opposite direction to the means by which it was created.
 In practise, the task is not simple.
 The alteration of model values needs to be guided by minimisation that
 obtains the matching which is being sought.
 In an expectedly high-dimensional problems, the process is laborious, unless
 extra knowledge about this minimisation problem is provided and in advance.
 Such knowledg can then be utilised, e.g.
 level of tolerance for the optimiser to aim for.
\layout Subsection

Learning the Correlations
\layout Standard

The way in which this problem can be solved involves learning how the parameters
 
\begin_inset Formula $\mathbf{c}_{i}$
\end_inset 

 affect the model
\begin_inset Foot
collapsed false

\layout Standard

There are some more complex considerations as the model needs to be aligned
 properly (rigid transformation), as well as change its form.
\end_inset 

 \SpecialChar ~
whilst compared to a standard target image -- the image to which the model
 must be fit.
 Each parameter in 
\begin_inset Formula $\mathbf{c}_{i}$
\end_inset 

 has an unequalled effect on different regions and aspects of the model,
 e.g.
 its size, intensities and so on.
 By changing the value of each such parameter and learning the change that
 is perceived in an image (using pixel-based comparison of some kind), a
 type of deformation index can be maintained.
 This index indicates which parameters should be changed and, if so, in
 what way and to what degree.
 The change is applied in order to approach good overlap between a model
 and some target image.
\layout Standard

More formally, the algorithm works as follows.
 For the model parameters 
\begin_inset Formula $\mathbf{c}_{i}$
\end_inset 

 where 
\begin_inset Formula $1<i<n$
\end_inset 

, a parameter change 
\begin_inset Formula $\delta\mathbf{c}$
\end_inset 

 (where one parameter or more can be changed simultaneously) is applied
 to generate new shape and texture.
 
\begin_inset Formula $\delta\mathbf{c}$
\end_inset 

 expresses, in a vector-based representation, the offsets that each of the
 original parameters 
\begin_inset Formula $\mathbf{c}_{i}$
\end_inset 

 is subjected to.
 The exhaustive pixel-wise difference in intensity
\begin_inset Foot
collapsed false

\layout Standard

A simple raster scan that account for all pixels should clearly be fast
 under most contemporary computer architectures.
\end_inset 

\SpecialChar ~
is calculated in accordance with
\layout Standard


\begin_inset Formula \begin{equation}
\delta\mathbf{I}=\mathbf{I}_{model}-\mathbf{I}_{image}\label{eq: delta start}\end{equation}

\end_inset 


\layout Standard

to produce a new vector of intensities (the differences).
 This vector can also be converted to be made visual and demonstrate differences
 in a way that is interpretable to human observers.
 A simple measure of difference is used although this need not necessarily
 be the case.
 Sum-of-squares of the pixel differences is then used because larger quadratic
 differences will have a greater effect on the final measure and summation
 then only consists of positive values.
 For example, consider the values derived in Equation 
\begin_inset LatexCommand \ref{eq: delta 2}

\end_inset 

 and in 
\begin_inset LatexCommand \ref{eq: delta3}

\end_inset 

.
 The former contains information about how the values of the vector in 
\begin_inset LatexCommand \ref{eq: delta 1}

\end_inset 

, and particularly their summed difference, get accentuated, whereas in
 the later case makes them almost negligible
\begin_inset Foot
collapsed false

\layout Standard

This is similar to the need for a median measure, where average is sensitive
 to erratic values or salt-and-pepper noise.
\end_inset 

.
 As an example to consider
\layout Comment

CJT: IN THE FOLLOWING 3: CONFUSING TWO FORMULATIONS AND AAM'S HERE -- EXPLAINED
 IN MORE DETAILS ABOVE NOW
\layout Standard


\begin_inset Formula \begin{equation}
\delta\mathbf{I}=sumofsquares(\{-1,3,5,2,6,-10,-1\})\label{eq: delta 1}\end{equation}

\end_inset 


\layout Standard

then becomes
\layout Standard


\begin_inset Formula \begin{equation}
\delta\mathbf{I}=sum(\{1,9,25,4,36,100,1\})=176\label{eq: delta 2}\end{equation}

\end_inset 


\layout Standard

as opposed to
\layout Standard


\begin_inset Formula \begin{equation}
\delta\mathbf{I}=sum(\{-1,3,5,2,6,-10,-1\})=4.\label{eq: delta3}\end{equation}

\end_inset 


\layout Standard

With this measure of intensity difference, relational information can be
 expressed between the parameter change and this difference as it appears
 in image space where a model is superimposed on some target.
 That information (merely a correlation) can be learned by using a pseudo-target
 image which is the model in its 
\begin_inset Note
collapsed false

\layout Standard

(CJT: THE REST OF THE SENTENCE IS MARKED ???) ALSO ??? ON THE REST OF THIS
 PARAGRAPH UNTIL THE EQUATION --> Explained better this time, but could
 use MORE change.
 It is vague at times.
\end_inset 

mean form.
 It can be used for basic comparison that says something about the model
 displacements and their corresponding effect
\begin_inset Foot
collapsed false

\layout Standard

It is possible to learn the properties of rotation, as an exemple, by applying
 a rotation and looking at the difference between the resulting image and
 the original image.
 That is the main concept that this step is based upon, namely studying
 the relationship 
\begin_inset Formula $Transformation\Longleftrightarrow Error$
\end_inset 

.
\end_inset 

.
\layout Standard

This quantitative measure of difference obtained will indicate the approximate
 
\begin_inset Quotes eld
\end_inset 

goodness
\begin_inset Quotes erd
\end_inset 

 of the parameter change (as perceived with the use of SSD or MSD) and not
 a more localised effect that the change has on the given image.
 This means that it will not necessarily be obvious what parts in the two
 entities (model and target) remain similar and which ones do not
\begin_inset Foot
collapsed false

\layout Standard

The vector's distribution of values, i.e.
 positions with high absolute values, can address this question.
\end_inset 

.
 A type of a sequential data such as a vector is hence more useful as it
 retains the location of each computed difference value.
 Unsurprisingly, this also consumes far greater memory resources (and many
 vectors of this kind will in fact be necessary).
\layout Standard

Under the premise that space is more expendable than time complexity, a
 vector of difference is calculated and the correlation can be formulated
 as follows.
\layout Standard


\begin_inset Formula \begin{equation}
\mathbf{c}_{i}\rightarrow\mathbf{c}_{i}+\delta\mathbf{c}\rightarrow\delta\mathbf{I}\label{eq: delta before end}\end{equation}

\end_inset 


\layout Standard

This type of offset 
\begin_inset Formula $\delta\mathbf{c}$
\end_inset 

, which was applied to the collection of parameters 
\begin_inset Formula $\mathbf{c}_{i}$
\end_inset 

, is accompanied by a global change in intensity values across the image
 frame.
 This correlation can now be set aside and become accessible from an index
 as its size is proportional to the image size.
 Storage is dictated by the following relation:
\layout Standard


\begin_inset Note
collapsed false

\layout Standard

Comment: CJT: YOU DON'T REALLY EXPLAIN HOW IN PRACTICE A IS OBTAINED --
 A guess is made below in footnote
\end_inset 


\layout Standard


\begin_inset Formula \begin{equation}
\delta\mathbf{c}=\mathbf{A}\delta\mathbf{I}\label{eq: deltas}\end{equation}

\end_inset 


\layout Standard

where 
\begin_inset Formula $\mathbf{A}$
\end_inset 

 is a matrix
\begin_inset Foot
collapsed false

\layout Standard


\begin_inset Note
collapsed false

\layout Standard

RSS: Doubtful!! More of a guess.
\end_inset 

The matrix 
\begin_inset Formula $\mathbf{A}$
\end_inset 

 can be obtained using linear regression.
\end_inset 

 \SpecialChar ~
that encapsulates the change in intensities due to the parameter/s change
 
\begin_inset Formula $\delta\mathbf{c}$
\end_inset 

.
 This is a matrix which is correspondent to an 
\emph on 
n
\emph default 
-dimensional vector that expresses the change which was discovered off-line.
 It linearly defines (in a possibly high-dimensional space) the linear relation
 between change to the parameters and change to the intensities, or more
 precisely the 
\emph on 
difference image
\emph default 
.
 It can be used to choose directions of change 
\begin_inset Note
collapsed false

\layout Standard

(CJT: NOT REALLY -- ON 'LOOK UP') - CHANGED
\end_inset 

 directly 
\begin_inset Note
collapsed false

\layout Standard

later on
\end_inset 

 when performing a search and thereby avoid re-computation in a virtually
 recurring and almost identical problem.
\layout Standard

The most fundamental (and perhaps even compact) algorithm will carry out
 the aforementioned steps for each of the modes of variation, as well as
 the linear geometrical transformations.
 This can be a very laborious and cumbersome process, but it depends on
 the prescribed level of robustness .
 As subsequent stages illustrate, models that are not rich enough will fail
 to converge in difficult scenarios, a classic example of which is inappropriate
 initialisation.
\layout Standard

The matrix 
\series bold 
A
\series default 
 contains many numbers and the matrix forms a 'path-finding map' that guides
 exploration for good parameter changes; this property will be of great
 use when fitting the model to a target.
 In practice, such matrices are visualised by showing negative values as
 dark and positive one as increasingly brighter ones.
\layout Standard


\begin_inset Note
collapsed false

\layout Standard

Old Comment: Should I reuse previous literature report? Ask Chris.
 Should I reuse figures?
\layout Standard

Old Comment: !!!!This is a new section!!!!!!!!!
\end_inset 


\layout Subsection

Target Matching
\layout Standard

The final stage involves the use of the model above, as well as the correlations
 learned for that model, to do the fitting.
 It is possible to carry out a search which is driven by the calculated
 difference between the model and a given target image.
 In pragmatic terms, this means that fitting of the existing model will
 be improved until the model approximately overlaps the target
\begin_inset Foot
collapsed false

\layout Standard

This process of fitting strives to converge to the global minimum (of difference
 measure).
 Realistically speaking, the model and the target never reach complete equivalen
ce, namely the difference value of absolute 0.
 Even if the target was used to train the model, PCA would obscure the connectio
n between the two, due to information loss.
\end_inset 

.
 The fitting is all done by changing the values of model parameters.
 The state of the model, having explored some space for a fit, holds in
 the form of parameter values some information about the target image.
 This information can be further analysed.
 One parameter in a model of faces, for example, could describe the vertical
 angle of given faces.
 This is where the power of a statistical model lies -- being able to describe
 something compound in a very compact form.
\layout Standard

The search for model match is reliant on error (or conversely -- similarity)
 measures which are repeatedly calculated after each attempted assignment
 in the model's parameter space.
 Having applied some change to the parameters, a new estimate of difference
 is obtained.
 Each such change in parameter values is primarily guided by the matrices
 described on page 
\begin_inset LatexCommand \pageref{eq: deltas}

\end_inset 

.
 These express the correlation between variation modes (the similarity transform
ations as well as modes of appearance change) and the intensity values which
 describe difference (or discrepancy in match).
\layout Standard


\begin_inset Note
collapsed false

\layout Standard

Comment: CJT: THE ABOVE IS VERY VAGUE - RSS: I added some sentences to clarify.
\end_inset 


\layout Standard

The model, as shown in Figure 
\begin_inset LatexCommand \ref{cap:Model-and-target}

\end_inset 

 (or in Figure 
\begin_inset LatexCommand \vref{cap:A-target-image-2}

\end_inset 

), is initially placed somewhere inside the image frame, with reasonable
 proximity to its target.
 If the model is placed too far from its to-be target, there is a danger
 that it will be unable to converge to the target correctly.
 It will most likely get stuck in a local minimum (the global minimum being
 out of reach, as Subsection 
\begin_inset LatexCommand \ref{sec:Optimisation}

\end_inset 

 explains).
 The reason why good initialisation is essential is that significantly large
 displacements are rarely learned off-line and the difference between the
 target and the model is quite meaningless unless there is at least some
 partial overlap or commonality.
\layout Standard

The algorithm which is used to perform the search 
\begin_inset Note
collapsed false

\layout Standard

(CJT DOES NOT LIKE 'SENSIBLY - ??) -- CHANGED
\end_inset 

 has the following general form:
\layout Itemize

Place the appearance model 
\series bold 
M
\series default 
 somewhere in the image, preferably at the centre where the target of interest
 (to be denoted by 
\series bold 
I
\series default 
) is likely to lie
\begin_inset Foot
collapsed false

\layout Standard

Advanced knowledge about the problem is highly conductive at this stage.
 Otherwise, a bottom-up image analysis is a must.
\end_inset 

.
\layout Itemize

With the appearance model in its current state and the static target, perform
 the following: 
\begin_inset Note
collapsed false

\layout Standard

(CJT: EQUATION HERE) -- I added a few more symbols, but for actual notation,
 it is better to look at a paper on AAM.
\end_inset 


\begin_deeper 
\layout Itemize

Calculate the differences between the model and the target.
 This can be done by synthesising 
\series bold 
M
\series default 
 and calculating 
\series bold 
M - I
\series default 
.
\layout Itemize

Using the correlations learned off-line
\begin_inset Foot
collapsed false

\layout Standard

If these correlations are not available, guessing would be an alternative.
 It is important, however, to learn from the experience gained during this
 independent run of the program or else the optimisation would behave senselessl
y and lead to improvements being identified very slowly.
 General optimisers are assumed to make a good judgment as such.
\end_inset 

, set new values for the parameters 
\begin_inset Formula $\mathbf{c}_{i}$
\end_inset 

 of 
\series bold 
M
\series default 
.
 
\layout Itemize

Compute the new difference measures between the model and the target (as
 previously).
\begin_deeper 
\layout Itemize

Save the new state of the appearance model if the difference has been lowered,
 i.e.
 similarity is being approached.
 
\layout Itemize

If unsuccessful, re-adjust the value of model parameters, potentially with
 inclusion of a scaling coefficient 
\begin_inset Formula $k=1.5,0.5,0.25$
\end_inset 

 and so forth.
 This often achieves good results, although it is a heuristics-driven technique.
\end_deeper 
\end_deeper 
\layout Itemize

Iterate while no stare of convergence has been reached and improvements
 are still observed at times.
\layout Standard

More advanced methodologies and algorithms are used at present, but better
 clarity is achieved here by adhering to simplicity.
\begin_inset Float figure
wide false
collapsed false

\layout Standard
\align center 

\begin_inset Graphics
	filename ./Graphics/aam.eps
	display none
	scale 70.00

\end_inset 


\layout Caption


\begin_inset LatexCommand \label{cap:Model-and-target}

\end_inset 


\size small 
Model and target fitting.
\end_inset 


\layout Standard

The technique of matching an appearance model to a target image can be depicted
 by a staged simulation or a large sequence of images resembling the one
 in Figure 
\begin_inset LatexCommand \ref{cap:Model-and-target}

\end_inset 

.
 Somewhat remarkably, only a few dozens of iterations are required in order
 to get good matching.
 This of course depends on the algorithm and the scale of the problem.
\layout Standard


\begin_inset Note
collapsed false

\layout Standard

As a superficial example, fitting of a perfectly-round ball versus a human
 hand is an interesting problem.
 Assuming that there is a good contrast between the ball and the background,
 there should be few false alarms for good fits.
 An inspection of the difference image is then almost trivial for human
 appraisal in this case, while fingers become deceiving in the case of hands.
 In accordance with these very same arguments, the process of correlation-learni
ng should often be custom-built.
 It should at least treat the problems with respect to its complexity because
 sensitivity to change and matching (much like recovery) abilities vary
 greatly in reality.
\end_inset 


\layout Standard


\begin_inset Note
collapsed false

\layout Standard

RSS: training of a matric A to be added? DONE
\end_inset 


\layout Standard


\begin_inset Note
collapsed false

\layout Standard

(CJT: WHICH DO YOU THINK WOULD BE EASIER? AND WHY?) -- Questions answered!
\end_inset 


\layout Standard


\begin_inset Note
collapsed true

\layout Section


\begin_inset LatexCommand \label{sec:Introduction}

\end_inset 

Introduction
\layout Standard


\begin_inset ERT
status Open

\layout Standard

\backslash 
lettrine{O}{ ne}
\end_inset 

 
\layout Comment

Write some stuff here and present subsections.
 Explain some of the important issues
\layout Comment

This paper will first explain....
 Section 1 deals with.....
 DO THIS AT END
\layout Section


\begin_inset LatexCommand \label{sub:The-Problem}

\end_inset 

The Approach
\layout Standard

The rest of this chapter will describe popular methods of top-down image
 analysis, but will focus on active appearance models at the expense of
 other, less relevant methods.
\layout Section


\begin_inset LatexCommand \label{sub:Statistical-Models}

\end_inset 

Statistical Models
\layout Standard

The next few sections explain in some depth the notion of 
\emph on 
statistical
\emph default 
 models and especially that of (statistical) appearance models.
 They move on to the description of active appearance models which are an
 extension to active shape models and a brief introduction to shape models
 may be worthwhile to begin with.
\layout Standard

.
\layout Standard


\begin_inset Note
collapsed false

\layout Section*

2.4 Shape Fitting
\layout Standard

got shape model
\layout Standard

Use it
\layout Standard

Get target
\layout Standard

Search along normals
\layout Standard

Fit to target
\layout Standard

In order to do this, we first construct.
\end_inset 


\layout Comment

(Old comment???) --introduce ASM's here
\layout Comment

(OLD COMMENT: I must define AAM first) above
\layout Comment

Done: The paragraph used to say 
\begin_inset Quotes eld
\end_inset 

the use of the TRIANGULATION algorithm
\layout Comment

IMPORTANT FOR CR: CJT: See comments on paper -- DONE
\layout Comment

SEE PAPER COMMENTS ON THIS SECTION -- DONE
\layout Section


\begin_inset LatexCommand \label{sub:Existing-Extensions}

\end_inset 

Existing Extensions
\layout Standard

The existing extensions to shape and appearance models are numerous and
 their purpose varies.
 Wavelet compression techniques are used to mitigate the troublesome space
 requirements (especially in 3-D, e.g.
 for analysis of brain volumes).
 These can also make active appearance models far more compact
\begin_inset Foot
collapsed false

\layout Standard

A sparse collection of pixels (or voxels) can be encoded using a lossy function
 
\begin_inset Note
collapsed false

\layout Standard

reconstruction 
\end_inset 

 with an even smaller number of parameters.
\end_inset 

.
\layout Standard

There are also some application-specific extensions such as the implementation
 of view-based models 
\begin_inset LatexCommand \cite{view_based_aam}

\end_inset 

 and coupled-view models 
\begin_inset LatexCommand \cite{coupled_view}

\end_inset 

 for face recognition purposes.
 The principal idea is that 5 different models can express full appearance
 irrespective of the wide range of viewing angles around the head.
 Due to the symmetry of a human head, only 3 models are used in practice
 (two side views can be mirrored; frontal remains as is).
 The most appropriate model can then be chosen in a real-time dynamic sequence.
 The choice of the model to be used depends on the estimated rotation of
 the head and by estimating that rotation successfully, models do not break
 down
\begin_inset Foot
collapsed false

\layout Standard

When models break down, fitting defaults to a local (and hence false) minimum.
 
\end_inset 

 \SpecialChar ~
when introduced with a high degree of freedom (e.g.
 angular freedom).
 This idea can undoubtedly be exploited in applications other than faces,
 but it appears to have a limited demand in industry and it has not been
 pursued much lately.
 It is the switching between different models in real-time and the selection
 of the 
\emph on 
most suitable
\emph default 
 model that makes this study challenging and for medical imaging, where
 the viewing degree of freedom is very limited, this extension is merely
 irrelevant.
\layout Standard

The effect that different facial expressions and aging factors have on statistic
al model was another intriguing aspect that was mainly pursued by Lanitis
 
\emph on 
et al.
 
\emph default 

\begin_inset LatexCommand \cite{Lanitis_face,Lanitis_aging}

\end_inset 


\emph on 
.

\emph default 
 Lanitis has recently worked on synthesis of faces and the analysis of facial
 attributes 
\begin_inset LatexCommand \cite{Lanitis_prosopo}

\end_inset 

.
 
\begin_inset Note
collapsed false

\layout Standard

CJT: DOES HE HAVE AN IMPLEMENTATION??? RSS: CHECK....
 another implementation of appearance
\emph on 
 
\emph default 
models
\end_inset 


\layout Standard

For a greater level of detail, as well as information on further extensions
 and applications, see Appendix 
\begin_inset LatexCommand \vref{cha:Appendix-AElaboration-on}

\end_inset 

.
\layout Comment

view-based and such...
\layout Section


\begin_inset LatexCommand \label{sub:Open-Questions}

\end_inset 

Open Questions
\layout Comment

used to be titled 'Flaws' in Lit.
 Rep.
\layout Standard


\begin_inset Note
collapsed false

\layout Standard

CJT: ABOUT THE FIRST TWO SENTENCES BELOW: NOT SO!!
\end_inset 


\layout Standard

Active appearance models are a powerful method of interpreting and synthesising
\begin_inset Foot
collapsed false

\layout Standard

This can be considered as being a reversal of interpretation, in fact.
 This binds with the notable computer vision/graphics differentiation.
\end_inset 

 \SpecialChar ~
images.
 Nevertheless, they are heavy, complex and they require a long time to train.
 Active appearance models sometimes serve a purpose which is different from
 that of active shape models and often they require more time to reach good
 convergence, mainly due to their additional complexity.
 In that sense, some implementation issues in appearance models need to
 be addressed; this can hopefully make them very powerful in more aspects.
 Furthermore, the accuracy of appearance models is sometimes lower
\begin_inset Foot
collapsed false

\layout Standard

Although some results support this claim, it is quite likely that better
 implementations and further improvements will prove otherwise.
 
\begin_inset Note
collapsed false

\layout Standard

CJT: DOES NOT LIKE THE WORD 'APPROVE'...
 REWRITE THIS WHOLE FOOTNOTE
\end_inset 


\end_inset 

 \SpecialChar ~
than that which is offered by other methods.
 If synthesis of photo-realistic images is a pre-requisite of the model
 to be used, then AAM's are indeed a unique and sensational technology that
 does the job adequately.
\layout Standard

An additional valid critique of AAM's speaks of its occasional failure to
 reach the global minimum when posed with the goal of fitting.
 It is still not immune to large initial displacements (and hence discrepancies)
 or target instances that deviate abnormally from the training set.
 Since AAM's still rely on a good initial placement in a given target, there
 are possibly pressing issues to be looked at.
\layout Standard

It is yet hard to ignore the fact that results of an AAM fitting are sometimes
 less accurate than those of an ASM
\begin_inset Foot
collapsed false

\layout Standard

This is 
\emph on 
not
\emph default 
 necessarily so in the like-for-like comparison.
\end_inset 

.
 This brings up the doubts as for whether the extra complexity associated
 with texture is worthy of being considered.
 The investment of time and intensive effort, including the need for human
 intervention, raises some important doubts and scepticism.
\layout Standard


\begin_inset Note
collapsed false

\layout Standard

CJT ON THE ABOVE: THIS IS NOT NECESSARILY SO IN THE LIKE-FOR-LIKE COMPARISON
\end_inset 


\layout Standard

A significant drawback that is associated with appearance models is that
 for automation of model construction, landmark selection 
\begin_inset LatexCommand \cite{Brett_et_al_auto_landmark_generation,Hill_non-rigid}

\end_inset 

, or more fundamentally image correspondence 
\begin_inset LatexCommand \cite{walker_corr}

\end_inset 

, is necessary and yet somewhat difficult to achieve.
 It is not obvious how to choose landmarks sensibly and how to judge the
 optimality of an automatic choice of significant points.
 Since the efficiency of an appearance model depends greatly on the textures
 embedded in that model, it is not sufficient to use existing techniques
 to select landmarks and pseudo-landmarks (additional points between the
 original anatomical or mathematical landmarks), as quite recently suggested
 by Davies 
\emph on 
et al.

\emph default 
 
\begin_inset LatexCommand \cite{Davies_MDL}

\end_inset 

.
 A further explanation of this work is spread throughout some of the following
 chapters, but primarily Chapter 
\begin_inset LatexCommand \ref{cha:MDL Models}

\end_inset 

 needs to be fully grasped for understanding of this undertaken project
 and its manifestation.
\layout Comment

Old comment: why this research seeks automation...
\end_inset 


\layout Chapter
\pagebreak_top 
MDL Shape Models
\layout Standard


\begin_inset Note
collapsed false

\layout Standard


\noun on 

\begin_inset LatexCommand \label{cha:Information Theory}

\end_inset 


\begin_inset LatexCommand \index{Information Theory}

\end_inset 


\noun default 
Information Theory
\end_inset 


\layout Standard
\align right 

\size large 

\begin_inset Quotes eld
\end_inset 

A
\size small 
ll generalizations, with the possible exception of this one, are false.
\begin_inset Quotes erd
\end_inset 


\newline 
-- 
\emph on 
Kurt Gdel.
\layout Standard


\begin_inset ERT
status Open

\layout Standard

\backslash 
lettrine{I}{n} 
\end_inset 

 the previous chapter, generative models of shape and intensity were described.
 Construction of such models is the factor that defines their quality as
 they are inherently based on statistics.
 Their dependence on landmark points -- points that define correspondence
 -- was also explained.
 This chapter explains how correspendences are exploited and improved in
 an iterative manner.
\layout Section

Shapes and Correspondence
\layout Comment


\series bold 
Description of the project:
\layout Comment

The main argument which supports the project and motivates is that model,
 being representative of data, tend to be less complex if the data possesses
 very little variation.
 This is primarily what registration seeks - similarity and low variation
 amongst a collection of data.
\layout Comment

It appears quite natural and almost imperative that we investigate the quality
 and the efficiency of algorithms based on the observation above.
\layout Standard

Correspondences describe of how images in the set are related to one another.
 As they contribute information that is not present in the raw images, they
 are essentially the 'glue' that assembles pertinent images and makes them
 an associative 
\emph on 
set
\emph default 
.
 Poor models are built from poor point-to-point correspondence and, conversely,
 a good model is one which is built from data that is well aligned.
 A key observation to make is that models, by definition, are based on the
 existence of correspondences in images, or shapes.
 Manipulation of these correspondences affects the quality of the resultant
 model.
\layout Standard

Different arguments can be made with regards to an arbitrary choice of landmark
 points in shape.
 These landmark points define a non-continuous, point-to-point correspondence.
 In the simpler case which is shapes, one needs to provide a precise and
 accurate set of landmarks that define a cross-shape relationship.
 Nevertheless, it is not sufficient only to determine how accurate the correspon
dence will be.
 It is also important to select a correspondence set that is representative
 of the shapes.
 The number of landmark points is, after all, finite.
 This means that sampling a set of corresponding point in one region while
 neglecting another leads to locally-optimised models which perform badly
 as a whole (globally).
 Herein we deal with two cases of discrepancy in correspondences.
 Firstly, the correspondence, if not dense, must be selected carefully.
 A selection of meaningless or arbitrary corresponding points, for example,
 leads to the construction of poor models.
 Secondly, there is the factor of accuracy in the identification of corresponden
ces.
 This might not be an entirely objective task, so it needs to be assessed
 in one form or another.
\layout Standard

This chapter concentrates on the case where increasingly-improved shape
 model are gradually being built.
 Correspondences across the set from which they are derived get refined
 iteratively.
 The refinement is attained as better correspondences are chosen automatically,
 under a process called reparameterisation.
 Essentially, optimal models are built using an optimisation framework wherein
 better correspondences are sought.
 Correspondences are embedded in a high-parametric space that is explored
 by a general optimiser.
\layout Standard


\begin_inset Note
collapsed false

\layout Standard

put text from previous section here inc.
 new material on automatic landmarks using MDL
\end_inset 


\layout Subsection

Landmark Selection
\layout Standard

Past work by Kotcheff and Taylor 
\begin_inset LatexCommand \cite{Kotcheff}

\end_inset 

 addressed the problem of building, progressively refining, and assessing
 shape models.
 The problem, which was tackled in part, involves the selection of good
 corresponding points on the curve of a shape.
 In practice, this is achieved by evaluating the choice of landmarks using
 a shape model -- that which resulted from a choice of landmark points.
 There is a case is circularity here and an optimiser is intended to identify
 the point of balance, i.e.
 a state of optimality.
\layout Standard

The determinant of the covariance matrix of the model is said to be a reasonable
 approximation of model quality.
 Poor models can be discerned from better ones since the product of mode
 variances should be small for assimilated shapes.
 That similarity is typically increased if the points on the curve of the
 shapes are correspondent.
 When PCA is applied to a poorly-correspondent shape data, incorrectness
 that prevails will increase the scale of the distribution.
 Consequently, the model built will be poorer or altogether invalid.
 It will contain more information than it needs to, due to errors in the
 correspondence.
\layout Subsection

Experimental Framework and Data
\layout Standard

In most of the experiments that follow, a particular data type is used to
 make up a set of similar shapes.
 The data type is referred to as 
\begin_inset Quotes eld
\end_inset 

brink and bump
\begin_inset Quotes erd
\end_inset 

, owing to the elements from which it is composed (see Figure 
\begin_inset LatexCommand \ref{cap:The-unregistered-bump}

\end_inset 

).
 A newly-constructed front end (shown in Figure 
\begin_inset LatexCommand \ref{cap:The-graphical-user}

\end_inset 

) handled the process of landmark identification.
 Like most other applications that are used to carry out this work, the
 front end was constructed using Sun Microsystems' Java and Mathwork's MATLAB,
 under GNU/Linux.
 The new graphical user interface carries out the majority of the experiments
 described in the remainder of this chapter, as well as in subsequent chapters.
 
\layout Standard


\begin_inset Float figure
wide false
collapsed false

\layout Standard
\align center 

\begin_inset Graphics
	filename ./Graphics/mdlgui_screenshot.eps
	scale 40.00

\end_inset 


\layout Caption


\size small 

\begin_inset LatexCommand \label{cap:The-graphical-user}

\end_inset 

The graphical user interface for semi-automatic landmark selection.
\end_inset 


\layout Standard


\begin_inset Float figure
wide false
collapsed false

\layout Standard
\align center 

\begin_inset Graphics
	filename ./Graphics/original_bump.eps
	scale 27.00

\end_inset 


\layout Caption


\begin_inset LatexCommand \label{cap:The-unregistered-bump}

\end_inset 


\size small 
Unregistered bump-shaped synthetic data and its three principal modes of
 variation (
\begin_inset Formula $\pm$
\end_inset 

2 standard deviations are shown).
 Each bump is composed of points, depicted as a plus sign, to make them
 distinguishable in the plots.
\end_inset 


\layout Standard


\begin_inset Note
collapsed false

\layout Standard

Kotcheff
\end_inset 


\layout Standard

Figure 
\begin_inset LatexCommand \ref{cap:The-unregistered-bump}

\end_inset 

 is intended to show not only the form of shape data which is being dealt
 with.
 It also depicts the results of using a given point-to-point correspondence
 to construct a model of shape.
 Each point that is used to sample the shape (the dots are being connected
 using standard straight lines) is unique.
 Any point corresponds to another particular point in another shape.
 Since the figure shows shapes that were synthesised by the shape models,
 the original data will look very similar.
 
\layout Section

Learning Shapes
\layout Subsection

Principled Approach
\layout Standard

A more recent approach, which is said to succeed the work of Kotcheff, made
 use of the minimum description length (MDL) principle 
\begin_inset LatexCommand \cite{Rissanen_MDL}

\end_inset 

 in shape modelling.
 An MDL-based criterion, rather than the determinant of model variances,
 was used to evaluate the quality of shape models.
 Concepts from information theory (and particularly Shannon's entropy) were
 applied to the selection of preferable descriptors of shape 
\begin_inset LatexCommand \cite{Davies_MDL_MI}

\end_inset 


\begin_inset Note
collapsed false

\layout Standard

(CJT: NOT REALLY ON 'GOOD..
 SHAPES')
\end_inset 

.
 Baker 
\emph on 
et al 
\begin_inset LatexCommand \cite{Baker}

\end_inset 

 
\emph default 
suggested using encoding of images to treat appearance models likewise.
\layout Standard

The process of searching for better correspondences in shapes remains similar.
 A selection of points that describe a given shape is perpetually altered
 and their effect evaluated in order to find better shape models.
 In this case, a better model is said to be one that requires a more compact
 set of shapes to be passed as an encoded message
\begin_inset Foot
collapsed false

\layout Standard

An alternative method involving B-fitting was proposed by Thacker 
\emph on 
et al.
 
\emph default 

\begin_inset LatexCommand \cite{Thacker B-Fitting}

\end_inset 


\emph on 
.
\end_inset 

.
 The rationale is simple.
 Many shapes that are similar, based on the position of sample points, are
 more compressible.
 Many of them convey similar information, which is a trait that is perceived
 positively by a model, which becomes less complex.
\layout Standard


\begin_inset Note
collapsed false

\layout Standard

Add reference to Thacker here -- DONE IN FOOTNOTE
\end_inset 


\layout Subsection

Searching for Improved Model
\layout Standard

Having defined a measure of model quality, there is an implicit measure
 of the quality of correspondences, too.
 The two are closely related, if not inherently the same.
 However, better correspondences ought to be found automatically.
\layout Standard

In this particular context, a set of points serve as markers or descriptors
 of the outline of a shape.
 Each time points on the curve are selected, a different model is ultimately
 constructed.
 A good and compact statistical model is one whose variations are relatively
 small.
 The same may apply to the number of its control points.
 Such a model is found using a general optimiser, under which positions
 of corresponding points are altered, or the set of points reparameterised.
 Returning to NRR algorithms, MDL can be used as a similarity measure under
 an objective function that is iteratively evaluated for each reparameterisation
 of the points on the curve.
 The minimisation process is described in a reasonable level of details
 in Subsection 
\begin_inset LatexCommand \ref{sec:Optimisation}

\end_inset 

 on optimisation.
 The more important part of this work is the use of an existing information-theo
retic measure, namely MDL.
 It guides an autonomous search for good models.
 It is also possible to gain insight into the process by looking at its
 objective function.
\layout Comment

TODO: ADD MORE TEXT AS CHRIS REQUESTED; CJT: WHAT ABOUT THE ECCV PAPER;
 RSS: ADD REFERENCE AND TEXT FROM ECCV 2002
\layout Comment

CJT: ABOVE - LAST PARAGRAPH NOT ADEQUATE
\layout Section


\begin_inset LatexCommand \label{sec:Objective-Function-Revisited}

\end_inset 

Objective Function and Optimisation 
\layout Subsection

Principles of Objective Functions
\layout Standard


\begin_inset Note
collapsed false

\layout Standard

DONE: See next section.
 Used to be called 'Objective Function Revisited'
\end_inset 


\layout Standard


\begin_inset Note
collapsed false

\layout Standard

IMPLICITLY DONE WHEN SHIFTING CONTENTS: Put some description here before
 explaining optimisation (CJT says so)
\end_inset 


\layout Standard


\begin_inset Note
collapsed false

\layout Standard

NOTE: MOVED TO THIS PREVIOUS SECTION, used to be in end of next section
\end_inset 


\layout Standard

An objective function is an integral part of optimisation.
 It is responsible for solving the problem that it defines by stating a
 goal rather than the way it is achieved (which is where an optimiser fits
 in).
 The objective function returns a figure of merit for certain states/observation
s that are being probed, e.g.
 a given choice of landmark points that are embedded in a set of shapes.
 In the case of shape models assessment, the objective function will compute,
 for any given a choice of correspondences, how good the resultant model
 is.
 It is a function whose output value needs to be minimised
\begin_inset Foot
collapsed false

\layout Standard

Minimisation and maximisation are complementary and, in this case, a concise
 model has a low description length.
 In later chapters as well, model quality is consistently defined in a way
 which favours a model whose value is low.
\end_inset 

, fundamentally by finding a set of values for its input parameters (e.g.
 sets of corresponding points).
 Such parameters are varied simultaneously in order for an optimal choice
 or an optimal solution to be picked from the many available choices.
 The greater the number of free (input) parameters, the more complex the
 function becomes and the longer it takes to solve it.
 This may be the general rule, albeit there are exceptions.
\layout Standard

In the context of image registration, the objective function is most heavily
 based on similarity measures, as was briefly explained in the earlier chapter
 on NRR.
 However, there are more factors which can be taken into consideration.
 It is wise to enable this measure to be extended in some way.
 For example, it can be helpful to include the 'cost' of the warps that
 are used, so that the objective function is negatively affected by large
 warps.
 The reason why the cost of the warp is sometimes an integral part of the
 function is that complex warps are not as desirable as uncomplicated ones
 that perform the task equally well or even better.
 This cost is often considered a
\emph on 
 regularisation
\emph default 
 
\emph on 
term
\emph default 
 
\begin_inset LatexCommand \cite{henn_regularise}

\end_inset 

 which penalises sequences of warps 
\begin_inset LatexCommand \cite{Cootes_reg}

\end_inset 

 that form large trajectories in space.
 An optimiser, being a generic problem solver, will seek a solution that
 is simple rather than finding an odd trajectory in space that gives a similar
 solution.
 This may be case since the solutions are often not unique.
\layout Standard

Objective functions are built to encapsulate in a concise and effective
 way everything that is repeatedly evaluated.
 They are therefore required to be a very efficient 'unit' (or black box)
 which will be invoked quite frequently.
 The 
\emph on 
speed
\emph default 
 of the registration will directly depend on the choice of an objective
 function that adds up results from warps, similarity calculations and possibly
 more components.
 The 
\emph on 
quality
\emph default 
 of the registration will of course depend on this function, too.
\layout Standard

To exemplify this with the use images, let two images 
\begin_inset Formula $\mathbf{I}_{m}$
\end_inset 

 and 
\begin_inset Formula $\mathbf{I}_{m}'$
\end_inset 

 be defined as the images before and after warping, respectively.
 Let a warping function 
\begin_inset Formula $f_{w}(\mathbf{x})$
\end_inset 

 be defined as 
\begin_inset Formula $f_{w}(\mathbf{I}_{m},<parameters>)=\mathbf{I}_{m}'$
\end_inset 

, i.e.
 for a given set of parameters, the function will map the input image onto
 a new frame.
 For a similarity
\begin_inset Foot
collapsed false

\layout Standard

It is assumed that for an objective function that needs to be minimised,
 the similarity measure will return small values for good similarity and
 vice versa.
\end_inset 

 \SpecialChar ~
function 
\begin_inset Formula $f_{sim}$
\end_inset 

, the objective function then takes the form
\layout Standard


\begin_inset Formula \begin{equation}
f_{objective}=f_{sim}(f_{w}(\mathbf{I}_{m},<params>),\mathbf{I}_{r})+<reg-terms>.\end{equation}

\end_inset 


\layout Comment

TODO: CJT COMMENT: More explanation is needed here...
 see CJT COMMENTS on paper..
 RSS: IT NEEDS BETTER EXPLANATION TO BE UNDERSTOOD CORRECTLY
\layout Standard

where 
\begin_inset Formula $f_{objective}$
\end_inset 

 is the objective function and 
\begin_inset Formula $<reg-terms>$
\end_inset 

 is a regularisation term that takes account of the magnitude or severity
 of applied warps.
 The function's solver (an optimiser) then attempts to find a series of
 parameter values that will lead it to a globally-preferred solution.
 It does so by applying warps in the case of images or reparameterising
 along the curve in the case of shapes.
 The optimiser is exploring the space of the problem, as defined by the
 objective function at hand.
 More precisely, it attempts to find 
\emph on 
assignments
\emph default 
 for all parameters that describe the warps so that similarity is maximised
 (or difference minimised
\begin_inset Foot
collapsed false

\layout Standard

This function is said to minimise the sum of the difference between two
 images and another less significant term.
 The two images compared are the transformed image 
\begin_inset Formula $\mathbf{I}_{m}'$
\end_inset 

 and the reference 
\begin_inset Formula $\mathbf{I}_{r}$
\end_inset 

 in this case.
\end_inset 

).
\layout Comment

((See below for current work and how it constructs the objective function,
 as in ECCV 2004 paper))
\layout Comment

explain about it and how it is constructed, used, etc.
\layout Comment

See the group-wise ECCV 2004 paper and copy formulation from there.
\layout Standard

This brief explanation about the objective function concludes and closes
 this section.
 It is intended to demonstrate the algorithmic approach that correspondence
 selection takes.
 Various algorithms (objective functions) can be assessed by methods such
 as the one described by Warfield 
\begin_inset LatexCommand \cite{Warfield_non-rigid_atlas}

\end_inset 

, or that which which is described in Chapter 7.
\layout Subsection


\begin_inset LatexCommand \label{sub:The-MDL-based-Objective}

\end_inset 

The MDL-based Objective Function
\layout Comment

FROM MICCAI: DONE: The long explanation of how the objective function has
 been constructed will go here.
 Maybe a screenshot of the application should be squeezed in too.
\layout Comment

o
\begin_inset Note
collapsed false

\layout Standard

Below is from MICCAI - section on opt.
 function.
\end_inset 


\layout Standard

To recapitulate, objective functions define the means by which a solution
 is to be found.
 Efficiency remains a concern, so a sophisticated function that avoids construct
ing the model more frequently than necessary must be employed.
 The function used in this context needs to drive a search for shape corresponde
nces using a suitable parameterisation (in the case of image registration
 -- transformations which increase similarity across 
\emph on 
all
\emph default 
 images).
\layout Standard

The nature of the problem and the methods of solving it convey the ulterior
 goal which is to minimise a description length of a model.
 The way this goal is achieved is different from the approach of most algorithms.
 Compared to the vast majority of methods to date, it takes a unique approach
 which is to use model encoding as a similarity measure.
 This relationship can be expressed using the formulation below.
\layout Standard

In the case of image registration, consider a transformation function 
\begin_inset Formula $W(\bullet,params)$
\end_inset 

.
 The construction of an appearance model can take the form 
\begin_inset Formula $Model(\mathbf{x}_{1},\mathbf{x}_{2},..,\mathbf{x}_{n})$
\end_inset 

 where 
\begin_inset Formula $\mathbf{x}_{i}$
\end_inset 

 are the images used to train that model.
 One seeks a model that is more compact using the (simplified) function
 
\begin_inset Formula $F_{obj}=MDL(Model(\mathbf{x}_{1}...,\mathbf{x}_{i}..,\mathbf{x}_{n}))-MDL(Model(\mathbf{x}_{1}...,W(\mathbf{x}_{i},params)..,\mathbf{x}_{n}))$
\end_inset 

 where 
\begin_inset Formula $params$
\end_inset 

 should be found to minimise this expression for each image vector 
\begin_inset Formula $\mathbf{x}_{i}$
\end_inset 

.
 A succinct description of this algorithm follows.
\layout Itemize

Repeat
\begin_deeper 
\layout Itemize

For each image vector 
\begin_inset Formula $\mathbf{x}_{i}$
\end_inset 

, 
\begin_deeper 
\layout Itemize

Optimise 
\begin_inset Formula $F_{obj}$
\end_inset 

 by altering the values of 
\begin_inset Formula $params$
\end_inset 

.
\end_deeper 
\end_deeper 
\layout Itemize

Until convergence.
\layout Standard

In practice, to indirectly and quickly evaluate MDL, one can use an evaluate
 that is approximately related to MDL.
 What will then be calculated is 
\begin_inset Formula ${\displaystyle \begin{array}{c}
n\\
\sum\\
i=1\end{array}}log(\lambda_{i})$
\end_inset 

 where 
\begin_inset Formula $\lambda_{1<i<n}$
\end_inset 

 are the 
\begin_inset Formula $n$
\end_inset 

 Eigen-values of the covariance matrix whose magnitudes are the greatest.
 This is similar to the formulation of Kotcheff 
\begin_inset LatexCommand \cite{Kotcheff}

\end_inset 

 where 
\begin_inset Formula ${\displaystyle \begin{array}{c}
n\\
\sum\\
i=1\end{array}}log(\lambda_{i}+\delta)$
\end_inset 

 is calculated to approximate
\layout Standard


\begin_inset Formula \begin{equation}
det(\mathbf{M+\delta)}\equiv\begin{array}{c}
n\\
\prod\\
i=1\end{array}\lambda_{i}\,\,\propto{\displaystyle \begin{array}{c}
n\\
\sum\\
i=1\end{array}}log(\lambda_{i}+\delta)\equiv log(det(\mathbf{M}))\label{eq: kotcheff}\end{equation}

\end_inset 


\layout Standard

where 
\begin_inset Formula $\mathbf{M}$
\end_inset 

 is the covariance matrix under consideration.
\layout Subsection


\begin_inset LatexCommand \label{sec:Optimisation}

\end_inset 

Optimisation
\layout Subsection


\begin_inset LatexCommand \label{sub:Opt-Background}

\end_inset 

Background
\layout Standard

General optimisation is often used in the process of matching to or finding
 solutions.
 Optimisation complexity can be relatively high
\begin_inset Foot
collapsed false

\layout Standard

The behaviour of such a problem is not linear and it may cross over to the
 realms of quadratic programming (QP) where various parameters simultaneously
 control a function and minimisation is therefore by no means trivial.
\end_inset 

, so a cunning algorithm needs be devised.
 
\begin_inset Note
collapsed false

\layout Standard

(COMMENT: CJT does not love this part) -- DONE -- moved to footnote
\end_inset 

 This process is, by convention, concerned with the minimisation
\begin_inset Foot
collapsed false

\layout Standard

The complement is used to generalise it to become a maximisation problem.
\end_inset 

 \SpecialChar ~
of the value of a function.
 That function most likely comprises more than a single variable, which
 makes it multi-dimensional.
\layout Standard

A multitude of software packages that act as general optimisers exist and
 the way they operate and perform varies.
 Some even use a mixture of different algorithms depending on the stage
 of the optimisation and the changing granularity of the problem.
 Approximations and changes in granularity can lead to significant speed
 gains, as well as better search strategies.
\layout Standard

Optimisation over a function that varies in many dimensions is a computationally
-expensive process.
 Often this optimisation requires some 
\emph on 
a priori 
\emph default 
knowledge of the problem domain.
 Only by using some knowledge to devise 
\emph on 
ad hoc
\emph default 
 solutions can performance end up being satisfactory.
 In the case of image matching, advantages can be gained if the effect of
 variable alteration can be predicted in some way.
 An example of this was described in Section 
\begin_inset LatexCommand \vref{sub:Fitting}

\end_inset 

 where pixel intensities have a dependency upon a group of parameters.
 Given the difference between two or more images, or even some generic data
 which described 
\emph on 
change
\emph default 
 caused by value alternations in the objective function, it is possible
 to determine paths that lead to quick convergence.
\layout Standard

For the problems at hand, common optimisation methods are gradient-descent
 and downhill simplex 
\begin_inset LatexCommand \cite{Press}

\end_inset 

.
 However, many other methods exist
\begin_inset Foot
collapsed false

\layout Standard

Among the popular methods: dynamic programming, genetic algorithms, Powell's,
 simulated annealing and steepest descent.
\end_inset 

.
 The advocated strategy would sometimes be a utilisation of mixtures of
 different methods with rational choice of the an algorithm at each stage.
 That may be needed because the different characteristics of the methods
 make them advantageous at different states throughout the optimisation
 process.
\layout Comment

OLD ((do not elaborate too much))
\layout Comment

OLD: give some silly stories and examples here
\layout Comment

DONE: Taylor says optimisation is not even worth a big amount of explanation
 so maybe leave this quite empty?
\layout Subsection


\begin_inset LatexCommand \label{sub:Problems}

\end_inset 

Problems
\layout Standard

One of the flaws of existing optimisation methods is their inability to
 find a global minimum (or minima) reliably enough.
 In problems of very high-complexity, as in the case of model fitting in
 two or three dimensions, this can lead to shallow searches whose result
 is unacceptable.
 It is even more difficult to drive an optimisation without additional knowledge
 about the objective function and the problem.
 Assumptions about the behaviour of the curve along each of the axes
\begin_inset Foot
collapsed false

\layout Standard

Optimisation is a multi-dimensional problem that searches along hyper-spaces,
 some of which are orthogonal to the many existing axes.
\end_inset 

 \SpecialChar ~
are otherwise made, based on observation.
 For example, one may assume that a face is located at the centre of the
 image and is upright.
\layout Standard

The speed of the optimisation process can be improved at the expense of
 overall accuracy and error likelihood.
 If no exhaustive search
\begin_inset Foot
collapsed false

\layout Standard

Exhaustive search is impossible for continuous functions, but digital images
 take discrete values.
\end_inset 

 \SpecialChar ~
is carried out, there is then a danger of convergence at local minima.
 In most applications, any convergence at a local minimum would be highly
 undesirable although this may be better than a complete failure at identifying
 regionally-low points in the function.
 Local minima are a necessary evil for large, complex, and continuous functions.
\layout Standard

In conclusion, there is a trade-off between speed and accuracy.
 However, accuracy can be achieved at a lower cost if more knowledge is
 acquired 'off-line', i.e.
 before the optimisation task actually begins.
 As expected, this also implies that many redundant computations will consume
 precious resources and time in order to train the optimiser.
 
\layout Comment


\emph on 
A priori
\emph default 
 knowledge of the problem can be rather beneficial though.
\layout Section

Summary
\layout Standard

This chapter has explained, but has not yet demonstrated, some of the advantages
 gained by using an MDL approach for choosing landmark points in a set of
 shapes.
 The notion of an objective function function was explained, as well the
 idea of using an information-theoretic objective function.
 Once this function is in place, there are various issues that are concerned
 with the optimisation regime.
 The way by which good solution are sought is rather crucial.
 Later chapters which review experiments elaborate further, using practical
 examples.
\layout Standard


\begin_inset Note
collapsed false

\layout Standard

Old unrelated COMMENT: Used to be called 'Information Theory and MDL Models'
\end_inset 


\layout Standard


\begin_inset Note
collapsed false

\layout Comment

Rework the name for the chapter above, merge with some of the previous section
 and reorganise all text including references
\layout Section

Background
\layout Comment

obsolete text: This section includes some assorted background to other strands
 which relate to MDL in the next chapter.
\end_inset 


\layout Standard


\begin_inset Note
collapsed false

\layout Standard

Comment: Rework the name for the chapter above -- DONE
\end_inset 


\layout Standard


\begin_inset Note
collapsed false

\layout Section


\begin_inset LatexCommand \label{sub:Importance}

\end_inset 

Importance
\layout Standard


\begin_inset ERT
status Open

\layout Standard

\backslash 
lettrine{O}{ ne}
\end_inset 

arguments regarding the importance of information theory with respect to
 this project vary.
 Information theory is indeed valuable due to its relevance to past projects
 in the field, on which future projects will rely.
 Image analysis is often involves the passage and handling of large sets
 of data and extraction of the meaning of the data is a necessity.
 Compression becomes ever more crucial when voluminous models and entities
 are maintained in memory and, again, reasoning about compression goes back
 to the theory of information.
 New ways to encode data, avoid redundancy and describe objects succinctly
 are being sought as they often reduce the 
\emph on 
complexity
\emph default 
 of any system as well as its
\emph on 
 size.

\emph default 
 Measures of information are necessary to introduce and support learning
 capabilities which in turn form intelligent systems.
 Such systems can evaluate and judge improvement as illustrated thus far
 and as will be illustrated later.
\layout Section


\begin_inset LatexCommand \label{sub:Shannon's-Entropy}

\end_inset 

Entropy
\layout Standard

The term entropy (commonly also referred to as Shannon's entropy [WWW-15])
 is used to denote a general measure of 
\emph on 
uncertainty
\emph default 
.
 It is not a very sophisticated idea, yet a very fundamental one which was
 first introduced in 1948.
 Uncertainty is associated with the required amount of data so it can also
 be thought of as an
\emph on 
 
\emph default 
information
\emph on 
 measure
\emph default 
 or quantifier.
 The value that quantifies uncertainty originally related to random variables
 which take different probabilities amongst a set of states (reminiscent
 of Markov chain models).
 Shannon's entropy has become a very useful way of evaluating structures
 and pattern in some data.
 The lower the entropy value, the more data is already inherent in that
 data.
 In a sense, the entropy indicates how much can be learned from the data
 and what is still unknown.
\layout Comment

Need much more work here
\layout Section


\begin_inset LatexCommand \label{sub:Minimum-Description-Length}

\end_inset 

MDL
\layout Standard

Minimum description length 
\begin_inset LatexCommand \cite{Rissanen_MDL}

\end_inset 

 provides a measure of the 
\emph on 
minimal
\emph default 
 amount of information necessary to encode some data.
 Any data can be transformed in a particular way so that it becomes a sequence
 of symbols (numbers or signals even, to be less general)
\begin_inset Foot
collapsed false

\layout Standard

Binary representation is quite complete in the sense that any data, e.g.
 programs and text, can be coded in a binary form.
 However, this representation might be very greedy of space and the issue
 of representation compactness then arises.
\end_inset 

.
 The transition between one symbol to another can be encoded by some transition
 table which holds the probabilities of all possible transitions.
 For 
\begin_inset Formula $n$
\end_inset 

 symbols, up to 
\begin_inset Formula $n^{2}$
\end_inset 

 transition need be defined.
 Markov chains are one such model type which is a convenient way of explaining
 the nature of MDL.
 Markov chains of a high order can accommodate for data of more awkward
 and unpredictable variance.
 MDL infrequently defaults to higher-order models (see examples at [WWW-14])
 which are superiorly expressive, although they require a far greater number
 of transitions to be specified.
\layout Standard

With proper use of models as in the case above, data can and should be represent
ed solely by all transitions and can then essentially replicated from these
 transitions.
 Unless the data is peculiar and shows no patterns, such a description would
 be compact for data large enough in bulk.
 MDL attempts to describe the extent to which some data is capable of diminishin
g in bulk (with or without loss being a separate issue) or rather the minimal
 amount of information that needs to be available to describe and reconstruct
 that data.
 In most cases, the more uncertainty present (i.e.
 higher entropy), the greater the minimal description length would be.
\layout Standard

As an example, here is a vector representation of some arbitrary data: 
\begin_inset Formula $v=\{3,4,3,1,1,3,4,2,2\}.$
\end_inset 

 There is an alternative way of representing this data.
 By using a first-order transition table, e.g.
 
\begin_inset Formula $3\rightarrow4:$
\end_inset 

1, 
\begin_inset Formula $3\rightarrow2:0$
\end_inset 

..., the likelihood or probability of transition from every element to its
 successor is revealed.
 Observable patterns are merely meaningless in this data example.
 Encoding of transitions will also be an inefficient approach as a result
 of the small vector size and the low sequential correlation
\begin_inset Foot
collapsed false

\layout Standard

To make this appear more practical, one can think of a large (
\begin_inset Formula $>100000$
\end_inset 

 pixels) image where patterns are present.
\end_inset 

.
 On the sharp contrary, vectors such as 
\begin_inset Formula $v=\{0\}$
\end_inset 

 or 
\begin_inset Formula $v=\{1,1,1,1,1,1,1,1,1,1,1\}$
\end_inset 

 bear a very small measure of uncertainty.
 In the second of these
\begin_inset Foot
collapsed false

\layout Standard

This can be portrayed as a uniform plain-white image.
\end_inset 

, only one transition exists so it can be represented by a tiny model and
 the entropy is 0.
\layout Standard

To summarise, MDL is a measure of the minimal amount of information that
 expresses a sequence
\begin_inset Foot
collapsed false

\layout Standard

General problem reducibility to a sequence is axiomatic as Turing Machines
 suggest.
\end_inset 

.
 By inspecting transitions it is possible to get an insight into the complexity
 of some model.
 A heart beat pattern, for instance, is rather predictable and repetitive
 in comparison with the positions of a person's fingers over time.
 This means that the description length of the heart state should be shorter
 than that of the hand.
 Less information is required to capture the behaviour of the heart in motion
 (heart beats are not sporadic).
\layout Standard

Issues of transitions and understanding of data patterns will later be explained
 in a different context.
 Rather than reconstructing vectors, images need to be reconstructed by
 the least number of bits.
 These bits are permitted to permute quantised natural numbers as the above
 arguments suggest.
\layout Comment

Old: MDL for shape model - get important issues.
 Explain from Rhodri's thesis
\layout Comment

Old: SECTION: Bags of Pixels
\layout Comment

Old: REMOVE THIS SECTION? PUT IT IN SOMEWHERE?
\end_inset 


\layout Chapter
\pagebreak_top 
Model-based Registration
\layout Standard


\begin_inset Note
collapsed false

\layout Standard


\noun on 

\begin_inset LatexCommand \label{cha:MDL Models}

\end_inset 


\begin_inset LatexCommand \index{MDL Models}

\end_inset 


\noun default 
Minimum Description Length and Models
\end_inset 


\layout Standard
\align right 

\size large 

\begin_inset Quotes eld
\end_inset 

A
\size small 
s order exponentially increases, time exponentially speeds up.
\begin_inset Quotes erd
\end_inset 


\newline 
-- 
\emph on 
Ray Kurzweil.
\layout Standard


\begin_inset ERT
status Open

\layout Standard

\backslash 
lettrine{R}{egitration} 
\end_inset 


\layout Standard

is the missing link which makes possible the construction of models without
 human intervention, i.e.
 without any interaction that involves annotation of data.
 This chapter outlines an approach for constructing appearance models using
 the images alone, without requiring any additional markup.
 The registration process is used to produce 
\emph on 
dense
\emph default 
 markup automatically and it serves the needed correspondences for the process
 of model building.
 This exemplifies the reciprocity and tight relationship between the task
 of registration -- that which establishes dense correspondence -- and models
 that utilise this correspondence.
\layout Standard


\begin_inset Note
collapsed false

\layout Standard


\begin_inset ERT
status Open

\layout Standard

\layout Standard

\backslash 
pdfbookmark{Text of bookmark}{Name of anchor}
\end_inset 


\end_inset 


\layout Section

Overview
\layout Standard

An important component of the proposed framework, as described in subsequent
 chapters, is the construction of appearance models from a given set of
 correspondence 
\emph on 
automatically
\emph default 
.
 The chapter begins by explaining a simplified registration framework that
 brings one dimensional data into a state of alignment.
 This is followed by more detailed explanation about the way alignment is
 used to construct models of appearance directly.
 Throughout this section, an approach is described for automatic construction
 of appearance models using a criterion of 
\emph on 
complexity
\emph default 
, but one could in principle replace this with other criteria, as indicated
 in benchmarks that appear later.
 Technical details described herein frequently refer back to earlier work
 
\begin_inset LatexCommand \cite{Davies_MDL,Davies_MDL_MI}

\end_inset 

 that backed the idea of building 
\emph on 
shape
\emph default 
 models, which are progressively refined, by assessing their complexity.
 Current work is distinct owing to the inclusion of intensity data in the
 model.
 Finally, a method for evaluating such models is described in greater depth.
\layout Section


\begin_inset LatexCommand \label{sub:Warps}

\end_inset 

Warps
\layout Standard

As discussed in Chapter 2, a fundamental part of any NRR algorithm are means
 of transformation.
 As Chapter 2 adhered to a broader perspective -- a perspective along the
 lines of general ideas -- there needs to be a more elaborate explanation
 of the types of warps used at this stage, as well as the remaining stages.
\layout Standard

Clamped-plated splines 
\begin_inset LatexCommand \cite{Marsland_MICCAI_2003}

\end_inset 

 are invertible, diffeomorphic warps 
\begin_inset LatexCommand \cite{diffeomorphism_paper}

\end_inset 

 that are used here almost exclusively.
 B-splines 
\begin_inset LatexCommand \cite{lee-b-spline,Rueckert_2003}

\end_inset 

 and thin-plate splines 
\begin_inset LatexCommand \cite{Bookstein_thin,jenkins_thin_plate}

\end_inset 

, for example, are considered somewhat deficient.
 The notion of diffeomorphism (see Subsection 
\begin_inset LatexCommand \ref{sub:Diffeomorphism}

\end_inset 

) was introduced to describe functions that map a group of pixels onto new
 positions without collision or ambiguity (notably the effect of tearing
 of folding).
 Diffeomorphism is by all means an important attribute for any type of warp
 to possess.
 Moreover, due to practical considerations, the warps used should also be
 computationally inexpensive.
\layout Standard

The warps currently in use affect a rounded confined region (this extends
 to elliptic-spherical region in 3-D) and they can be wholly characterised
 by their location, radius, and magnitude.
 These warps are parameterised by their horizontal and vertical location,
 while magnitude and radius are simple pertinent values.
 To transform images, many such warps are placed and applied at different
 locations and scales to one image at a time.
 Their position is chosen randomly, by drawing number from a Gaussian distributi
on.
\begin_inset Note
collapsed false

\layout Standard

(COMMENT CJT: How are they parameterised?) -- SENTENCE ADDED
\end_inset 

 Good results are carried on to subsequent iterations while bad ones get
 discarded.
 Towards the later stages of the algorithm, only small local warps, much
 as in the case of reparameterisation in shape, will entail constructive
 results, i.e.
 an increased inter-image similarity.
\layout Standard


\begin_inset Float figure
wide false
collapsed false

\layout Standard
\align center 

\begin_inset Graphics
	filename ./Graphics/warp.eps
	display none
	scale 70.00

\end_inset 


\layout Caption


\begin_inset LatexCommand \label{cap:Warp-applied-to}

\end_inset 


\size small 
An arbitrary warp applied to image.
 On the left: image before warp is applied; On the right: image after warping.
\end_inset 


\layout Comment

Model-based Registration
\layout Section

Using Models as a Similarity Measure
\layout Standard

An objective function describes the framework which is used to register
 images.
 The objective function described in this section comprises warps based
 on biharmonic clamped-plate splines, as well as an implicit similarity
 measure, which is an approximation of the quality of a model.
 Any collection of unregistered images can be used to establish such a model,
 but only a properly-registered set of images (that which results in high
 groupwise similarity) builds a good model.
 This observation can be exploited to create a similarity measure that not
 only deals with 
\emph on 
pairs
\emph default 
 of images, but can also deal with large 
\emph on 
sets
\emph default 
.
\layout Subsection


\begin_inset LatexCommand \label{sec:Current-Registration-Algorithm}

\end_inset 

The Registration Algorithm
\layout Standard

This section presents the model-based objective function in the form of
 pseudo-code.
 Initially, the algorithm is demonstrated using simplistic one-dimensional
 data.
 The algorithm can be conceptually divided into two parts as follows: 
\layout Standard


\begin_inset Note
collapsed false

\layout Standard

The explanations are intended to ease technical implementation being inter-commu
nicated.
 Emphasise style is used to symbolise less significant I/O (input/output)
 steps which can be ignored.
 Many other steps are left out because they have little correlation to data
 registration itself.
\end_inset 


\layout Standard


\series bold 
Initialisation
\layout Itemize

Generate images or retrieve them from a file.
\layout Itemize

Optionally, apply image smoothing.
\layout Itemize

Choose image reference.
 By default, the image closest
\begin_inset Foot
collapsed false

\layout Standard

Proximity is calculated based on the Euclidean distance, which identified
 the references that is, on average, nearest to all other images.
\end_inset 

 \SpecialChar ~
to the mean of all images gets selected.
\layout Standard


\series bold 
Main Loop
\layout Itemize

For a predefined number of iterations in the registration :
\begin_deeper 
\layout Itemize

Set the level of precision for the optimiser to reach.
 Ideally it should increased (or tolerance lowered) when advancements toward
 the goal made are small, i.e.
 when registration is approached.
\layout Itemize

Repeat for all images:
\begin_deeper 
\layout Itemize

If the current image is not a reference
\begin_inset Foot
collapsed false

\layout Standard

The reference remain static in this case.
\end_inset 

:
\begin_deeper 
\layout Itemize

Set up the positions of knot-points (random placements drawn from a Gaussian
 distribution are typically chosen).
\layout Itemize

Given the knot-points positions, apply warps to the current image and seek
 the warp parameters which minimise the cost 
\begin_inset Formula $f(x)$
\end_inset 

, where 
\begin_inset Formula $x$
\end_inset 

 is the complexity of the model built from the entire set of data.
\end_deeper 
\layout Itemize

end if
\end_deeper 
\layout Itemize

end repeat
\end_deeper 
\layout Itemize

end for
\layout Itemize

Statistics and registration logging take place
\emph on 
.
\layout Standard

At the core of this objective function lies an evaluator of the complexity
 of the model.
 How this value gets computed is the core idea which is discussed further
 in this section.
\layout Subsection

Algorithm Visualised
\layout Standard

Figure 
\begin_inset LatexCommand \ref{cap:Schematic-of-the}

\end_inset 

 shows the process that is outlined above.
 The framework is demonstrated in a simplified form in both cases (schematically
 and algorithmically).
 A reference image, as seen at the top of the figure, remains unaffected
 while all other images are manipulated in the way which is described in
 Figure 
\begin_inset LatexCommand \ref{cap:Current-algorithm-at}

\end_inset 

.
 These are used to construct a model from which a certain complexity measures
 can be derived, e.g.
 description length.
 Based on that measures of complexity, subsequent warps are applied to the
 group of images.
\layout Standard


\begin_inset Float figure
placement H
wide false
collapsed false

\layout Standard
\align center 

\begin_inset Graphics
	filename ./Graphics/current.eps
	scale 28.00

\end_inset 


\layout Caption


\begin_inset LatexCommand \label{cap:Schematic-of-the}

\end_inset 


\size small 
Schematic of the registration algorithm.
 A reference image (R) and the remainder of the warped set of images (I)
 form a combined model (circle) which is evaluated in an MDL-like manner
 to refine the subsequent warps.
\end_inset 


\layout Standard


\begin_inset Float figure
placement H
wide false
collapsed false

\layout Standard
\align center 

\begin_inset Graphics
	filename ./Graphics/current-focus.eps
	scale 20.00

\end_inset 


\layout Caption


\begin_inset LatexCommand \label{cap:Current-algorithm-at}

\end_inset 


\size small 
Current algorithm at a lower level.
 The idea of a reparameterisation is shown by emphasising that images are
 formed by aggregation of the previous image with some parameterisation.
\end_inset 


\layout Standard


\begin_inset Note
collapsed false

\layout Standard

EXPLAIN FIGURES
\layout Standard

---
\layout Standard

For a full corresponding notation and further explanation on the figures,
 see the short presentation file at:
\layout Itemize


\begin_inset LatexCommand \htmlurl{http://www.danielsorogon.com/Webmaster/Research/Explanatory_Notes/2004/Group-wise_NRR_Strategy_and_Notation.pdf}

\end_inset 


\layout Standard

It is certainly beyond the scope of this report and can be remitted.
 However, some of the figures should be thought-inspiring.
 A brief explanation of each has been included above for this reason.
\end_inset 


\layout Subsection

The Data
\layout Comment

Putting all the above together, the current approach of the system is as
 follows:
\layout Comment

It penalises more complex warps
\layout Comment

It uses the similarity measures
\layout Comment

It warps the images using diffeomorphic warps, usually simple ones (single
 point? Tim prefers single point, others want complex multi point warps
 that break continuity).
\layout Standard

The 1-D data which is dealt with hereafter is a simple elliptic bump.
 It varies in 3 distinct yet related ways, as shown in Figure 
\begin_inset LatexCommand \ref{cap:modes}

\end_inset 

.
 The data is being perturbed by varying the positions of the points that
 have it sampled (y-values), as shown in Figure 
\begin_inset LatexCommand \ref{cap:Reparameterisation-along-the}

\end_inset 

.
\layout Standard


\begin_inset Float figure
placement H
wide false
collapsed false

\layout Standard
\align center 

\begin_inset Graphics
	filename ./Graphics/bump.eps
	scale 70.00

\end_inset 


\layout Caption


\begin_inset LatexCommand \label{cap:modes}

\end_inset 


\size small 
Illustration of the three variation modes.
\end_inset 


\layout Standard


\begin_inset Float figure
wide false
collapsed false

\layout Standard
\align center 

\begin_inset Graphics
	filename ./Graphics/smith.eps
	scale 70.00

\end_inset 


\layout Caption


\begin_inset LatexCommand \label{cap:Reparameterisation-along-the}

\end_inset 

Movement of sample points and resampling of the curve that connects the
 points.
\end_inset 


\layout Standard

Figure 
\begin_inset LatexCommand \ref{cap:An-actual-set}

\end_inset 

 shows 6 different examples of what the data appears like in its most simplistic
 form, i.e.
 when only 2 points (the edges) are used to sample it.
 In practice, however, one can deal with the bump as though it is a vector
 of image intensities.
 Dealing with several such bumps (1-D images) in turn, we can visualise
 them as shown in Figures 
\begin_inset LatexCommand \ref{cap:Data-being-registered.}

\end_inset 

 and 
\begin_inset LatexCommand \ref{cap:A-larger-example}

\end_inset 

.
 
\begin_inset Float figure
wide false
collapsed false

\layout Standard
\align center 

\begin_inset Graphics
	filename ./Graphics/bump_width.eps

\end_inset 


\layout Caption


\size small 

\begin_inset LatexCommand \label{cap:An-actual-set}

\end_inset 

An simplified set of bump data.
 Different instances are indicated by distinct colours (or shades).
\end_inset 


\layout Standard


\begin_inset Float figure
wide false
collapsed false

\layout Standard
\align center 

\begin_inset Graphics
	filename ./Graphics/image_vectors.eps
	scale 70.00

\end_inset 


\layout Caption


\begin_inset LatexCommand \label{cap:Data-being-registered.}

\end_inset 


\size small 
Data being registered.
 The registration process is visualised by an image composed of data vectors.
 The columns are 1-D vectors interpreted as grey-scale pixels.
\end_inset 


\layout Standard


\begin_inset Float figure
wide false
collapsed false

\layout Standard
\align center 

\begin_inset Graphics
	filename ./Graphics/pixels.eps
	scale 60.00

\end_inset 


\layout Caption


\begin_inset LatexCommand \label{cap:A-larger-example}

\end_inset 


\size small 
A larger example of pixel representation for 1-D bump data.
\end_inset 


\layout Standard


\begin_inset Float figure
placement H
wide false
collapsed false

\layout Standard
\align center 

\begin_inset Graphics
	filename ./Graphics/test_on_target_7-4.eps
	scale 30.00

\end_inset 


\layout Caption


\begin_inset LatexCommand \label{cap:Original-data-set}

\end_inset 


\size small 
Original dataset depicted in 3-D.
 A set of size 5 is shown before application of any warps, which are intended
 to align the data.
\end_inset 


\layout Standard


\begin_inset Note
collapsed false

\layout Standard

Why not show the real thing? --DONE 
\layout Standard

HEIGHT was not supposed to be ignored
\end_inset 

The first step taken by the registration program is the generation of some
 random 'bumps'.
 These bumps varied in their height and width; the step size of the bump
 (the steep ends of the flat pinnacle) was fixed, i.e.
 the bump was initially flat at the top.
\layout Standard


\begin_inset Float figure
placement H
wide false
collapsed false

\layout Standard
\align center 

\begin_inset Graphics
	filename ./Graphics/AART0.5.22.eps
	scale 40.00

\end_inset 


\layout Caption


\begin_inset LatexCommand \label{cap:Autonomous-Appearance-based-Registration}

\end_inset 


\size small 
Autonomous Appearance-based Registration (AART): the program built to handle
 registration and model building.
\end_inset 


\layout Standard

Although the property of height was not intended to be ignored during registrati
on (its signal is the intensity, which cannot be discarded), it was expected
 that it would remain unchanged due to CPS-based warps being perfectly diffeomor
phic
\begin_inset Foot
collapsed false

\layout Standard

While the bump may have its form tweaked and manipulated, its highest peak
 should be preserved although it may move leftward or rightward.
 This assumes that boundaries for the warp intensity are honoured.
\end_inset 


\begin_inset LatexCommand \cite{diffeo-in-1d}

\end_inset 

.
 The bumps were all symmetric and the height took one value from the set
 {
\emph on 
hi, low
\emph default 
} where 
\begin_inset Formula $lo=0$
\end_inset 

 and 
\begin_inset Formula $0.7<hi<1$
\end_inset 

.
 The data was therefore far simpler than any 1-D data which is not constrained
 in any way.
 The height of the bump and the position at which the bump goes high could
 conjointly define that bump so two real numbers (a tuple) at the minimum
 would suffice to reconstruct each bump.
\begin_inset Note
collapsed false

\layout Subsection


\begin_inset LatexCommand \label{sec:Previous-work}

\end_inset 

Registration Based on Models
\layout Subsubsection

Summary
\layout Standard

Non-rigid registration (NRR) and model-based image analysis were previously
 believed to possess some commonality -- a premise on which current research
 is still based.
 There is a growing belief that the best of both can be exploited to construct
 a unified framework.
 This modified framework might be more robust and offer higher utility and
 functionality when compared with the other two approaches working solely.
\layout Standard

It is claimed that warping of the images, as is already done in medical
 imaging in particular, can be used to find correspondences that are optimal
 in some respects.
 Pair-wise (and sometimes group-wise) 
\begin_inset Note
collapsed false

\layout Standard

Not really about Group-wise 
\end_inset 

image registration using non-rigid transformations was the way in which
 previous (local) research by Smith had planned to build good models of
 appearance.
 Furthermore, non-rigid registration made it possible to achieve better
 correspondence in images and maybe supersede other methods.
 By constructing models from the transformation parameters, one could also
 highlight and describe successful registration trajectories, i.e.
 ideal warping sequences or a legal range of warps.
 As a result of the process in its entirety, active appearance models could
 be constructed automatically (for identification of correspondence no longer
 requires any human intervention) and non-rigid registration could guided
 by appearance models rather than similarity measures which are pair-wise.
 
\begin_inset Note
collapsed false

\layout Standard

CJT: I am not sure you know what you mean.
 This is not a clear explanation -- I tried to explain it better.
 Hopefully it is not too rough.
\end_inset 


\layout Comment

Old Comment: Like Rhodri's optimisation for asm's..
 explain about recent submission to ECCV 2004
\layout Subsubsection

Results
\layout Standard

There was never evidence to indicate that the results of previous work were
 as successful as had been hoped.
 It was anticipated that since it dealt with group-wise registration (and
 globally optimal models), its results should clearly be better 
\begin_inset Note
collapsed false

\layout Standard

CJT: In what sense? Where is the evidence? RSS: I was wrong saying it was
 successful so I fixed it.
\end_inset 

than those obtained from pair-wise registration under similar conditions.
 This approach came with an extra cost to make things even tougher.
 The process which offered little improvement was far slower and the results
 were not superior by any noticeable measure.
 In fact, it is possible that the results were partially biased -- not positivel
y, but rather negatively, due to few of the conditions set for the experiments.
\layout Standard

Back at the start, circa October 2004, impending experiments aimed to disprove
 the claim that the conditions and choices made were the cause for any apparent
 advantage.
 They just as well aspired to increase apparent gains of group-wise registration
 -- something which was not yet evident at the time.
 Answers as to why this was so will be given in Chapter 
\begin_inset LatexCommand \ref{cha:Experiments}

\end_inset 

.
\layout Standard


\begin_inset Note
collapsed false

\layout Standard

Left out: 
\begin_inset Quotes eld
\end_inset 

Various improvements and lines of research had already been suggested and
 similar work continued even back then....
\begin_inset Quotes erd
\end_inset 


\end_inset 


\layout Section


\begin_inset LatexCommand \label{sec:On-going-work}

\end_inset 

On-going Work
\layout Subsection

A Critique
\layout Standard

Work in the field seems to move in differentiable yet almost identical direction
s.
 On the one hand, speed is an issue that might not have a definite solution
 and parts of this document elaborate on imaginable hindrances and conceivable
 impediments of this kind.
 Algorithmic trade-offs and different choices of programming language or
 paradigm, operating system and platform is a matter worth pursuing.
 Since the process relies on wide global scope, i.e.
 investigation of various images simultaneously where change in one affects
 all, heuristics can perhaps be applied to decrease the number of iterations
 involved
\begin_inset Foot
collapsed false

\layout Standard

Although knowledge of the problem is an integral part of most program optimisati
on steps, the more formal methods can be used to identify dependencies.
 A dependency graph can reliably indicate where re-evaluation is indeed
 necessary (e.g.
 Figure 
\begin_inset LatexCommand \vref{cap:AART-dependencies_struct}

\end_inset 

).
\end_inset 

.
\layout Standard

Claims of a similar nature can be made on the more intrinsic part of work
 being reviewed.
 For a start, values were often tweaked manually and no strong evidence
 was used to support such arbitrary selections which purportedly followed
 common sense.
 Another problem that has been realised is that much of the process comprised
 the simplistic joining of remotely-germane components whose nature is unique
 and autonomous.
 This means that components in the system often suffered from the undependable
 fusion which was in place -- something which is a direct consequence of
 the knowledge that is still lacking in the field.
 There is much to be learned about how the numerous existing techniques,
 measurements and component should be merged effectively and, by all means,
 conveniently.
\layout Comment

Maybe Smith's work here
\layout Standard


\begin_inset Note
collapsed false

\layout Standard

<sec:On-going-Research>On-going Research -- ignore
\end_inset 


\layout Standard


\begin_inset Note
collapsed false

\layout Standard

RSS: Merge with the previous part
\end_inset 


\layout Subsection

Parallel and Related Work
\layout Standard

Rueckert 
\emph on 
et al.

\emph default 
 
\begin_inset LatexCommand \cite{Rueckert_2003}

\end_inset 

 describe statistical deformation models (SDM's) which are in essence surprising
ly similar to appearance model.
 As it turns out, they are explicitly set to construct an appearance model
 using statistical analysis as described in Chapter 
\begin_inset LatexCommand \ref{sub:Statistical-Models}

\end_inset 


\begin_inset Note
collapsed false

\layout Standard

(USED TO SAY 'ACTIVE -- fixed '; CJT: THEY EXPLICITLY SET TO CONSTRUCT AN
 APPEARANCE MODEL - added)
\end_inset 

.
 They do this analysis in a strategically different and indirect way though.
 To transform images, B-Splines are used which are quite powerful, well-understo
od and commonly used, e.g.
 in computer graphics rendering and curve fitting.
 However, they suffer from one main drawback which is deficiency of diffeomorphi
sm.
 What this practically means is that parts of the data can be torn or folded,
 i.e.
 structures can disappear.
 This cannot happen if the CPS-based warps are used, but a valid comparison
 is needed to discover if this attribute really is all about gains.
\layout Standard

Similar concepts have been applied to segmentation in 
\begin_inset LatexCommand \cite{Collins}

\end_inset 

.
 Much work has concentrated on using the knowledge and techniques from each
 one of these two to establish a more powerful framework of full appearance
 statistical models.
 The work is described in Chapter 
\begin_inset LatexCommand \vref{cha:Project-Goals}

\end_inset 

 with reference to research that is associated with the GC (some of the
 cross-over papers are relevant in this context).
 An exclusive introduction to Rueckert's work will attempt to elucidate
 the current registration concepts which future research relies upon.
\layout Standard


\begin_inset Note
collapsed false

\layout Standard

(CJT: i DON'T REALLY EXPLAIN WHAT THEY DO...
 E.G.
 B-SPLINES ETC..
 THIS IS ONE OF THE CROSS-OVER PAPERS) - Added
\end_inset 


\layout Standard

Non-rigid registration methods have been applied in several medical domains
 of expertise.
 Amongst these is the renowned brain analysis task, contrast-enhanced MR
 mammography and segmentation and tracking of the heart.
 The procedures currently employed are inclined to follow higher-order entropy
 measures that will not be delved any further.
 Rueckert's homepage [WWW-2] which is listed at the end gives the full details
 and references.
 Chapter 
\begin_inset LatexCommand \ref{cha:Information Theory}

\end_inset 

 on information theory explained in brevity some of the basic ideas behind
 these so-called entropy measures.
\layout Standard

The success of temporal non-rigid image registration method is dependent
 upon two factors:
\layout Enumerate


\series bold 
Search algorithm:
\series default 
 As earlier illustrated in the context of active appearance mode, good warps
 need to be searched to achieve good similarity.
\layout Enumerate


\series bold 
Similarity:
\series default 
 The performance relies on a suitable choice of similarity measures which
 guide the search until a sufficiently good fit is declared.
\layout Standard

Learning the properties of similarity measures, the way they affects the
 search duration and the effect warps have on similarity are all important
 aspects of registration method development.
 This is reminiscent of the process in which correlation between parameter
 changes and intensity changes are learned in appearance models.
\layout Standard

Statistical parametric mapping (SPM) are being used in University College
 London [WWW-16] in order to register bio-medical data.
 The term SPM refers to construction and assessment of spatially extended
 statistical process that can be used to test hypotheses about given medical
 data, especially in the domain of neurology.
 SPM spatially normalises images into a standard regular space and then
 applies some smoothing.
 Statistics which are then extracted from the registration of the data are
 addressed by theory of continuous random fields.
 None of this is arcane, though the concepts are rather unique to UCL.
\layout Standard

Also in UCL, registration is performed which is based on fluid models.
 The rigid movement of objects does not usually impose problems as those
 introduced by soft tissue.
 Fluid registration is a matching technique which models these awkward morpholog
ical changes as compressible viscous fluid.
 The idea is presently applied in brain imaging where greater interest has
 existed for some time.
\layout Standard

Change in organs due to resection (craniotomy being a banally-encountered
 scenario), expansion, movement etc.
 is often modelled using thin-plate splines 
\begin_inset LatexCommand \cite{Bookstein_thin}

\end_inset 

 and the motion of organs can be handled using free-form deformation (FFD)
 which are based on B-splines.
 Prior to this embedment of high-order functions, the effects of rigid-body
 motion is annulled by Euclidean transformation.
 Similarity measures guide this process of rigid registration just as well.
 It is the technical description of the algorithms used that proves why
 these methods, which are used in Guy's Hospital, are extremely effective.
 As earlier mention, current work is done using the bi-harmonic 
\begin_inset LatexCommand \cite{Abkar}

\end_inset 

 clamped-plate splines and possible investigation is considered for a model-base
d objective function that uses other morphometrical methods.
 
\layout Standard


\begin_inset Note
collapsed false

\layout Standard

CJT: WE DID NOT HEAR ABOUT FLUID REGISTRATION OR B-SPLINE FUNCTION REGISTRATION
 (E.G.
 SPM) WHICH ARE WELL-KNOWN APPROACHES - ADD THESE TO REFERENCES TOO.
 -- DONE apart from references -- see Web references though.
\end_inset 


\layout Section


\begin_inset LatexCommand \label{sec:Goals}

\end_inset 

Goals
\layout Standard

A main goal, which appertains to the big picture that is the GC, is the
 merger which involves (non-rigid) registration and statistical models.
 In both cases, some 
\emph on 
dense correspondence
\emph default 
 across some or all of the images is involved and must eventually be determined.
 Re-use of the information that is incorporated in each of this two techniques
 (which are believed to be inherently the same) would make the overall analysis
 task more powerful, flexible and well-integrated
\begin_inset Foot
collapsed false

\layout Standard

The parallel development in both fields, especially the need to identify
 homologous structures, is what makes this GC suitably arranged and increases
 its potential of resulting in success.
\end_inset 

.
 If even a moderate combination of the two is obtained, then new ways of
 building and using models will be open for investigation.
\layout Standard

In NRR, lower-level inspection of image pixels identifies similarity using
 mutual information (or any other similarity measure for this argument's
 sake), whereas in statistical modelling, the correspondences are often
 marked by hand (as explained in previous chapters, this is no longer quite
 the case necessarily) or gathered in an ill-chosen fashion.
 It is imperative that effort is made to reuse the segmentation from NRR
 so that models can be constructed more quickly and fitted to targets before
 feature extraction takes over and does its part of the analysis job.
\layout Comment

Old: What can I work on?
\layout Comment

Old: What direction will my research take?
\layout Comment

Old: What is currently required from the AAM, non-rigid registration, warps,
 etc.
\end_inset 


\layout Subsection

Early Experiments
\layout Standard

Early work on the model-based objective function was fruitful.
 Images of the bump were registered using a variety of registration methods,
 including the model-based one.
 The existing algorithm was well-behaved.
 The problem, however, was not thoroughly understood as warps were permitted
 to degrade parts of the data.
 What follows are some exemplary experiments which, together with correspondent
 videos (see accompanying CD-ROM) demonstrate the process of registration
 visually, with progression.
 Below are perils and solutions to problems encountered on the path a working
 algorithm.
\layout Standard


\begin_inset Float figure
placement H
wide false
collapsed false

\layout Standard
\align center 

\begin_inset Graphics
	filename ./Graphics/mean_msd_graph-1.eps
	scale 27.00

\end_inset 


\layout Caption


\begin_inset LatexCommand \label{cap:Mean-MSD-measures}

\end_inset 


\size small 
Mean MSD measures at each point during the model-based registration of 10
 data instances.
\end_inset 


\layout Standard


\begin_inset Float figure
placement H
wide false
collapsed false

\layout Standard
\align center 

\begin_inset Graphics
	filename ./Graphics/overlaid.ps
	scale 70.00

\end_inset 


\layout Caption


\begin_inset LatexCommand \label{cap:A-comparative-analysis}

\end_inset 


\size small 
A comparative analysis of different objective functions.
 It illustrates that the model complexity decreases only for the newly-proposed
 objective functions.
 The Y-Axis value is an indicator of model compactness.
\end_inset 


\layout Standard
\align center 

\begin_inset Float figure
placement H
wide false
collapsed false

\layout Standard
\align center 

\begin_inset Graphics
	filename ./Graphics/full_set.eps
	display none
	scale 25.00

\end_inset 


\layout Caption


\begin_inset LatexCommand \label{cap: full set images}

\end_inset 


\size small 
Images being registered according to the description length of the entire
 set of size 10.
 The X-axis indicates run-time time in seconds.
\end_inset 


\layout Subsubsection

MDL and Models
\layout Standard

It is realised that model residuals must to be included in some form or
 another (e.g.
 description length) in the objective function.
 As one example of the need for this issue to be resolved, see Figure 
\begin_inset LatexCommand \vref{cap:A-long-optimisation}

\end_inset 

.
 When not accounted for properly, the quality of the model can be perceived
 as though it surpasses the point of optimality.
 The incomplete term for description length is described in 
\begin_inset LatexCommand \cite{Davies_MDL}

\end_inset 

.
\layout Standard


\begin_inset Float figure
placement H
wide false
collapsed false

\layout Standard
\align center 

\begin_inset Graphics
	filename ./Graphics/10000_-_second_attempt-1.eps
	scale 30.00

\end_inset 


\layout Caption


\begin_inset LatexCommand \label{cap:A-long-optimisation}

\end_inset 


\size small 
A long optimisation with the successful model-based algorithm shows that
 it surpasses what is questionably the correct solution (indicated by the
 red dotted line).
\end_inset 


\layout Standard


\begin_inset Note
collapsed false

\layout Standard

This is needed for image similarity to have a good starting point is the
 simpler case which is, in fact, landmark selection.
 When landmarks can be identified correctly 
\emph on 
and
\emph default 
 the objective function reaches stable convergence, application of the proven
 principles to images can resume.
\end_inset 


\layout Comment

See form 2!!
\layout Comment

show some figure here...
\layout Subsubsection

Automatic Landmark Selection
\layout Standard

More considerable work was focused on shapes and the selection of landmarks
 which define point distribution models (PDM's).
 These are somewhat analogous to shape models.
 Work on shapes can be sub-categorised as follows.
\layout Subsubsection

Subsets
\layout Standard

The idea of this approach is to speed up the algorithm by essentially pyramiding
 the whole set (see Figure 
\begin_inset LatexCommand \ref{cap:Illustration-of-the}

\end_inset 

) and building up towards a much quicker convergence.
\layout Comment

SHOW PYRAMID of HIERARCHICAL approach
\layout Standard
\align center 

\begin_inset Float figure
placement H
wide false
collapsed false

\layout Standard
\align center 

\begin_inset Graphics
	filename ./Graphics/aam-pyramid.eps
	display none
	scale 45.00

\end_inset 


\layout Caption


\begin_inset LatexCommand \label{cap:Illustration-of-the}

\end_inset 


\size small 
Illustration of the approach taken in registration using subsets.
\end_inset 


\layout Standard

This hierarchy permits larger sets to be dealt with, going as high as hundreds
 -- something which has thus far been impractical.
 The figure shows how subsets are chosen in the context of image registration
 to create smaller AAM's.
 In practice the choice is stochastic.
 By registering subsets, a near globally optimal AAM can be constructed.
 Similar principles can be shown for shapes.
\layout Standard

Instead of treating large sets and optimising over these, smaller sets can
 be handled, thereby lightening the burdens of large Eigen analyses.
 Figures 
\begin_inset LatexCommand \ref{cap:shapes-subsets}

\end_inset 

 and 
\begin_inset LatexCommand \ref{cap: full set images}

\end_inset 

 illustrate that subsets appear to result in better and quicker descent
\begin_inset Foot
collapsed false

\layout Standard

This excludes the start when subsets require time to stabilise by preliminary
 warps.
\end_inset 

.
 The time required to optimise over subsets is significantly reduced.
\layout Standard
\align center 

\begin_inset Float figure
placement H
wide false
collapsed false

\layout Standard
\align center 

\begin_inset Graphics
	filename ./Graphics/subset.eps
	display none
	scale 25.00

\end_inset 


\layout Caption


\size small 

\begin_inset LatexCommand \label{cap:shapes-subsets}

\end_inset 

Images being registered according to the description length of random subsets
 comprising 4 images each.
 A choice of subset changes every 10 iterations.
 It is evident that the score goes lower, but the time required is then
 greater.
\end_inset 


\layout Standard

Figure 
\begin_inset LatexCommand \ref{cap:shapes-subsets}

\end_inset 

 shows that a subset-driven approach is slower though it is able to bring
 about some great improvements after an initial instability at the start.
 That slow start can be explained by pointing out that an insufficient number
 of different subset choices was cycled through.
 As a result, a rather localised optimisation is performed while the overall
 set benefits very little.
\layout Standard


\begin_inset Note
collapsed false

\layout Standard

10.3.3.2 Speed-up through Modification
\layout Standard

Various optimisations and fixing code
\end_inset 


\layout Subsubsection

Varying Optimiser Tolerance
\layout Standard

As part of speed-up through modification, an adaptive precision approach
 was taken.
 The rate of convergence is changed as the process goes on and so is the
 speed of the algorithm.
 There is more to be investigated to ensure the approach invariantly results
 in gains.
 It is also worthwhile to see if the choice of tolerance can be made more
 preferable, based on empirical evidence.
 Experiments with varying values for tolerance showed that there was promise
 in an approach that seeks coarse solutions at the start and refines them
 further as it went along.
\layout Comment

include figure here.
 One where the derivate shows how convergence rate changes.
\layout Subsubsection

Taboo Search (TS)
\layout Standard

To improve the performance of the search for good reparameterisations, a
 better optimisation method was sought.
 Among the methods explored was taboo search.
 Taboo search is a technique that attracted some interest in the 1990's
 
\begin_inset LatexCommand \cite{glover}

\end_inset 

.
 It makes use of knowledge about the search space while optimising.
 Thus, it can look up previous decisions and reach good solutions rather
 rapidly.
 It is similar to Simulated Annealing from a theoretic point-of-view.
 
\layout Subsubsection

Inference for Images
\layout Standard

Further improvements to the registration algorithms were inspired by experience
 acquired in past work.
 Previously, 
\emph on 
ad hoc 
\emph default 
improvements were made to the landmark selection algorithm.
 One such example is detection and rollback of any parameterisations which
 cause the assessor to report degradation in value.
 The optimiser, by its very nature, may return declining values once bad
 warps/parameterisations have been picked.
 Conventionally, this needs to be fixed manually, by intervening with decisions
 outside the optimisation routine.
 A mild adjustment, on the other hand, can automate this.
\layout Subsubsection

Comparison of Optimisation Regimes
\layout Standard

Different optimisation regimes were investigated, e.g.
 by changing optimiser parameters for the standard optimisation function,
 as well as investigating approaches that are altogether different.
 Example of this is presented in the next section on automatic model-building
 in 2-D.
\layout Standard


\begin_inset Note
collapsed true

\layout Subsection

Extension to 2-D
\layout Standard


\begin_inset Note
collapsed false

\layout Standard

Revised from MICCAI and changed.
 Reword the text below.
\end_inset 


\layout Standard

Since some of the gathered statistics indicate that the program achieved
 what it had been set to achieve, there are intentions of applying the same
 concepts to 2-D and data in the foreseeable future.
 The principles remain unchanged and the only required extension is that
 of CPS to a higher-dimensional space -- something which has been developed
 already.
\layout Standard

This extension step is expected to be trivial as CPS warps in 2-D have already
 been dealt with by Marsland and necessary 2-D data is available in the
 Division.
 Synthetic 2-D data can be generated as well if necessary and code exists
 for doing so (see Figure 
\begin_inset LatexCommand \vref{cap:2-D-Synthetic-data}

\end_inset 

).
 Once generation of data becomes possible and shapes for which the estimated
 solution is known can be created, e.g.
 triangles in 2-D space, then well-controlled 2-D tests can be performed
 under AART.
\layout Standard

The only envisioned hindrances will then be the speed of execution and the
 diligent selection of knot-points for transformation.
 Since there is yet some lacking understand of the problem in 1-D, time
 is needed to improve the algorithm.
 Its requirements need to have a more responsive time-span.
\begin_inset Note
collapsed false

\layout Standard

and the extension to 2-D has not yet been applied.
\end_inset 


\layout Subsection

Benchmarks using Flexible Platforms
\layout Standard

When a sensible registration algorithm is available to be used with brain
 data, it can then be compared to other methods developed within the IRC.
 Comparative tests are performed using a regular, annotated and standardised
 data.
 Software of Crum 
\emph on 
et al.
 
\emph default 
(confer the paper to appear in MICCAI 2004) is able to carry out such comparison
s.
 It relies on the database from Boston which comprises 8 brain volumes with
 ground-truth landmarks (annotated by professional radiologists).
 Validation 
\begin_inset LatexCommand \cite{schnabel}

\end_inset 

 of results with respect to other existing and to-be-established inter-operable
 software can be considered as well.
\layout Subsection

Application to 3-D Data
\layout Standard

The possibility of 3-D registration is still on hold, awaiting the point
 where it becomes practical.
 If the algorithm is successful and fast enough, 3-D extensions remain a
 valid possibility.
 This will not, however, take place in the near future.
\layout Subsection

Creating Atlases of Deformation for Different Groups
\layout Standard

Having got some methodology which derives average data with description
 of valid deformations, one can study the deformation of brains within a
 schizophrenic group, for example.
 It is then possible to perform some classification tasks using model fitting.
\layout Subsection

Refining Appearance Models Construction
\layout Standard

For reasons which were openly explained in earlier parts of this report,
 automating the selection of image correspondences is essential.
 This endemic problem in modelling can hopefully be solved at last.
 Hopefully, this refinement means 
\emph on 
automation
\emph default 
.
\end_inset 


\layout Standard


\begin_inset Note
collapsed true

\layout Standard

As images were being warped, the form of the bump quickly changed to give
 a smoother curve with more continuous derivatives.
 This of course depended on the type of warp which had been applied to the
 bump.
 At each iteration, new similarity with respect to some reference image
 or similarity with reference to the whole set of images was obtained using
 warps and measured using the methods outlined in Section 
\begin_inset LatexCommand \vref{sub:Minimum-Description-Length in modelling}

\end_inset 

.
\layout Standard

The similarity measures used in these experiments to evaluate similarity
 were mean-squared-difference (MSD) and mutual information (MI).
 The latter was more computationally expensive so although it gave better
 results, it needed to be used with caution.
 Likewise, the type of warp applied was often, but not alway,s a simple
 one which is controlled by a single allocated control point.
 In some cases, many control points were assembled to form an expensive
 warp of increased complexity.
 The choice of these points was often decided to be random as a successful
 rational choice would have required much more speed, consequently slowing
 down the whole process.
\layout Standard

As explained to some extent beforehand in 
\begin_inset LatexCommand \vref{sub:Reparameterisation}

\end_inset 

, reparameterisation was used to perform points placements in the image
 of the bump.
 These points did not directly express the form of the bump, but rather
 controlled the 
\emph on 
warps
\emph default 
 that affected the bump point coordinates.
 Initially, the curve to be reparameterised was an ordinary linear function
 stretching from the origin to a point 
\begin_inset Formula $(n,n)$
\end_inset 

 where 
\begin_inset Formula $n$
\end_inset 

 is the number that is chosen to be the image width (the only dimension
 of the single-dimensional data).
 Points were later chosen according to the change imposed on the curve due
 to warping.
\layout Standard

The experimentation Smith carried out allowed for many combinations of different
 options to be set, applied and appraised comparatively.
 The estimates of the 
\begin_inset Quotes eld
\end_inset 

goodness
\begin_inset Quotes erd
\end_inset 

 of warps were calculated using the creation of an appearance model from
 the group of images at present state, making this a group-wise optimisation
 methodology.
\end_inset 


\layout Standard


\begin_inset Note
collapsed true

\layout Standard


\begin_inset Float figure
placement H
wide false
collapsed false

\layout Standard
\align center 

\begin_inset Graphics
	filename ./Graphics/msd_gen_5_5-2.eps
	scale 27.00

\end_inset 


\layout Caption


\begin_inset LatexCommand \label{cap:Data-being-visualised}

\end_inset 


\size small 
Data being visualised by AART.
 In this case, 5 bumps are shown at some arbitrary state during registration.
\end_inset 


\layout Standard


\begin_inset Float figure
placement H
wide false
collapsed false

\layout Standard
\align center 

\begin_inset Graphics
	filename ./Graphics/multi_warp_20_zero_constant-2.eps
	scale 30.00

\end_inset 


\layout Caption


\begin_inset LatexCommand \label{cap:Multiple-knot-point-warps}

\end_inset 


\size small 
Multiple knot-point warps show that the curve is exponential when a model-based
 objective function is employed.
\end_inset 


\end_inset 


\layout Standard


\begin_inset Note
collapsed true

\layout Subsection


\begin_inset LatexCommand \label{sec:Proposal-of-new}

\end_inset 

New Algorithms
\layout Standard

At the stage when results described in Chapter 
\begin_inset LatexCommand \ref{cha:Experiments}

\end_inset 

 resembled these which are described in Chapter 
\begin_inset LatexCommand \ref{cha:MDL Models}

\end_inset 

 on MDL for shape models construction, it was decided to come up with new
 and more advanced ideas.
 In fact, parallel work by Twining on group-wise registration promoted collabora
tion and suggested that ideas should be exchanged in order to form a new,
 more powerful registration algorithm.
 As part of the discussions on issues of commonality and possibly duplicated
 effort, new schematics were drawn.
 This section is intended to explain them in some level of detail since
 they 
\emph on 
might 
\emph default 
at some point be implemented.
\layout Standard

Two possible views on how the problem can be tackled are shown below.
 What is common to both is that they attempt to encapsulate the model discrepanc
y in one cunning way or another.
 They need to express a way in which discrepancies relate to the data and
 to the warps which are applied to that data.
\layout Standard


\begin_inset Note
collapsed false

\layout Standard

INTRODUCTION HERE
\end_inset 


\layout Comment

Proposal of new algorithm is a previous name
\layout Standard


\begin_inset Float figure
placement H
wide false
collapsed false

\layout Standard
\align center 

\begin_inset Graphics
	filename ./Graphics/proposal1.eps
	display none
	scale 40.00

\end_inset 


\layout Caption


\begin_inset LatexCommand \label{cap:A-proposal-for}

\end_inset 


\size small 
One possible proposal for the further development of the registration algorithm.
 The main idea to take is that residuals should drive warps that in turn
 affect the model.
\end_inset 


\layout Standard


\begin_inset Float figure
placement H
wide false
collapsed false

\layout Standard
\align center 

\begin_inset Graphics
	filename ./Graphics/proposal2.eps
	display none
	scale 40.00

\end_inset 


\layout Caption


\begin_inset LatexCommand \label{cap:A-second-possible}

\end_inset 


\size small 
A second reasonable proposal for algorithm extension.
 MDL is the main driver of warps here.
 
\end_inset 


\layout Standard

For explanation of these, the aforementioned document needs to be looked
 at.
 These are rather long-winded to explain and the notation needs to be understood
 in advance.
 These notation is not final either and it is soon going to be changed as
 most recently agreed.
\layout Standard


\begin_inset Note
collapsed false

\layout Standard

EXPLANATION OF FIGURES
\end_inset 


\layout Subsection


\begin_inset LatexCommand \label{sec:Extensions_algorithms}

\end_inset 

Extensions
\layout Standard

Extensions were applied to the code which deals with MDL-based shape model
 construction (Chapter 
\begin_inset LatexCommand \vref{cha:MDL Models}

\end_inset 

).
\layout Standard

As an example
\begin_inset Note
collapsed false

\layout Standard

(DO NOT SAY IT IS THE ONLY EXTENSION)
\end_inset 

, below lies pseudo-code of what is referred to as adaptive precision.
 It simply selects a suitable tolerance for the optimiser.
 It does so in order to avoid excessive computations at early stages of
 the landmark selection procedure.
\layout LyX-Code

OUTPUT: precision_required
\layout LyX-Code

INPUTS: iterations_ratio, precision_automation_type
\layout LyX-Code

    % iterations_ratio is the ratio between the
\layout LyX-Code

    % current iteration and the total number
\layout LyX-Code

    % of iterations
\layout LyX-Code

switch precision_automation_type,
\layout LyX-Code

       case 'default'     
\layout LyX-Code

            if (iterations_ratio < 0.1),
\layout LyX-Code

               return precision_required = 1e-1;
\layout LyX-Code

            elseif (iterations_ratio < 0.2),
\layout LyX-Code

               return precision_required = 1e-2;
\layout LyX-Code

            elseif (iterations_ratio < 0.3),
\layout LyX-Code

               return precision_required = 1e-3;
\layout LyX-Code

\layout LyX-Code

            ...
\layout LyX-Code

\layout LyX-Code

            else      
\layout LyX-Code

               return precision_required = 1e-12;
\layout LyX-Code

            end
\layout LyX-Code

       case 'smart'
\layout LyX-Code

            % Look at the evaluation curve derivatives to
\layout LyX-Code

            % infer precision
\layout LyX-Code

end
\end_inset 


\layout Standard


\begin_inset Note
collapsed true

\layout Standard

and improving Models Module in some way....
\end_inset 


\layout Section

Model Building
\layout Subsection

Automatically Building Appearance Models
\layout Standard

The previous section covered a variety of methods for registration of data.
 The output of such registration are warp fields that define one-to-one
 correspondences of points in the data.
 Having got these correspondences, models can be built directly as described
 in 
\begin_inset ERT
status Open

\layout Standard

\backslash 
S
\end_inset 


\begin_inset LatexCommand \vref{cha:Active-Appearance-Models}

\end_inset 

.
 As the correspondence is a dense one, there is no limit in principle on
 the number of sample points from which the appearance model is constructed.
\layout Standard

This section explores the extension of the image registration method to
 2-D, as well as derivation of models from the registered data.
 What a registration algorithms establishes, regardless of the objective
 function used, is a dense correspondence in the images.
 Given this correspondence, however obtained, it is possible to learn the
 variation in shape and intensity.
 By applying the same algorithm to a set of one- or two-dimensional data,
 an appearance models can be built.
 The videos labeled 
\family typewriter 
8.avi
\family default 
 and 
\family typewriter 
14.avi
\family default 
 (see the accompanying CD-ROM) show the result of 1-D registration of the
 bump data using a model-based objective function.
 Combined models are shown, as well as shape and intensity models.
 Taking a similar approach to 2-D datasets, the same type of models can
 be built from brain data.
\layout Subsection

The Objective Function
\layout Standard

In order to obtain a set of corresponding points, transformation of data
 need be involved.
 Two separate families of registration algorithms have been repeatedly used.
 The first method uses sum-of-squared-differences to measure similarity,
 whereas the second uses the minimum description length (MDL) framework.
 In both cases, transformation was handled solely using bi-harmonic clamped-plat
e splines.
 Although mutual information is a ubiquitous similarity measure, it did
 not prove to be as valuable in the experiments described in the remainder
 of this thesis.
\layout Standard

Figures 
\begin_inset LatexCommand \ref{cap:mutual_information_image}

\end_inset 

 and 
\begin_inset LatexCommand \ref{cap:ssd_vxl_image}

\end_inset 

 show the registration process, by overlaying images and get a blocky blend
 that is the discrepancy image.
\begin_inset Float figure
wide false
collapsed false

\layout Standard
\align center 

\begin_inset Graphics
	filename Graphics/ssd_vxl.png
	scale 70.00

\end_inset 


\layout Caption


\begin_inset LatexCommand \label{cap:ssd_vxl_image}

\end_inset 

Discrepancy image showing the difference between two registered images.
 the objective function used was sum-of-squared-differences.
\end_inset 


\layout Standard


\begin_inset Float figure
wide false
collapsed false

\layout Standard
\align center 

\begin_inset Graphics
	filename Graphics/info_vxl.png
	scale 70.00

\end_inset 


\layout Caption


\begin_inset LatexCommand \label{cap:mutual_information_image}

\end_inset 

Discrepancy image showing the difference between two registered images (differen
t from the image set shown in the previous figure).
 the objective function used was mutual information.
\end_inset 


\layout Standard

Lastly, as part of the experiments that investigate optimisation through
 minimisation of the objective function, a survey is shown which compared
 3 methods.
 Figure 
\begin_inset LatexCommand \ref{cap:Optimisation_comparison}

\end_inset 

 visually, as opposed to quantitatively, compares the level of refinement
 obtained through the different optimisation methods.
\layout Standard
\align center 

\begin_inset Float figure
wide false
collapsed false

\layout Standard
\align center 

\begin_inset Graphics
	filename Graphics/combined_view_5.png
	scale 70.00

\end_inset 


\layout Caption


\begin_inset LatexCommand \label{cap:Optimisation_comparison}

\end_inset 

A survey of different registration optimisation methods.
 The figure shows the results in the form of discrepancy images, each for
 the results of a different optimisation method.
\end_inset 


\layout Standard


\begin_inset Note
collapsed true

\layout Subsection

3-D Registration Framework
\layout Subsection

Minimisation
\layout Standard

Discrepancy image
\end_inset 


\layout Standard


\begin_inset Note
collapsed true

\layout Section


\begin_inset LatexCommand \label{sec:Starting-Point}

\end_inset 

Determinant
\layout Section


\begin_inset LatexCommand \label{sec:Starting-Point}

\end_inset 

Previous work (Kotcheff, Davies)
\layout Section


\begin_inset LatexCommand \label{sec:Starting-Point}

\end_inset 

Bumps in 1-D
\layout Section


\begin_inset LatexCommand \label{sec:Starting-Point}

\end_inset 

Proof of concept
\layout Section


\begin_inset LatexCommand \label{sec:Starting-Point}

\end_inset 

Speed - pitfall
\layout Section


\begin_inset LatexCommand \label{sec:Starting-Point}

\end_inset 

Starting Point
\layout Standard


\begin_inset ERT
status Open

\layout Standard

\backslash 
lettrine{I}{ t}
\end_inset 

is worth starting off with a description of the some recent and relevant
 developments which were made before September 2003.
 The following few paragraphs summarise and shed light at some of the main
 principles.
 These principles consequently describe some methods which are still used
 in the existing system -- systems that surely needed to be extended and
 their understanding was the most crucial.
\layout Standard

Smith's work follows the work of Davies in a more-or-less obvious sense,
 but it explores a different domain with slightly different aims.
 Each of these two research efforts will be dealt with in turn.
\layout Subsection


\begin_inset LatexCommand \label{sub:Returning-to-Shape}

\end_inset 

Returning to Shape Models
\layout Standard

Davies repeatedly performed a reparameterisation over a given series of
 shapes, or rather their defining points (although in principle he dealt
 with continuous curves where points are just implicitly defined)
\begin_inset Note
collapsed false

\layout Standard

In principle he dealt with continuous curves -- Done
\end_inset 

.
 All these points were shifted in accordance with some displacements, as
 orchestrated by a monotonically increasing curve.
 This reparameterisation was applied to all examples, one reparameterisation
 for each example
\begin_inset Foot
collapsed false

\layout Standard

There was also a further investigation into the optimisation scheme.
 All shapes can be optimised over simultaneously (also known as joint optimisati
on) or one can be optimised at any single iteration (known as sequential
 optimisation).
\end_inset 

 
\begin_inset Note
collapsed false

\layout Standard

This is ambiguous.
 Getting it right is the key to the method -- added a footnote to clarify.
\end_inset 

 \SpecialChar ~
in the training set to evaluate an optimal choice of point spreads, or
 more precisely, the favourable reparameterisations that act upon these
 points (in principle, that is defined with respect to a curve which will
 be represented by a finite number of sample points.
\layout Standard

In current group-wise registration work, the elements that such reparameterisati
on affects are the points which control the
\emph on 
 warps
\emph default 
 applied to the data
\begin_inset Foot
collapsed false

\layout Standard

The data type is irrelevant.
 It makes no difference whether it is an image of full appearance or just
 a 'brick-and-bump' as was repeatedly the case.
\end_inset 

.
 These chosen warps are then applied to all the examples (or data instances)
 and measures are used to describe the vague notion of model-ability.
 One could argue that the model provides a good indicator of how 
\begin_inset Quotes eld
\end_inset 

similar
\begin_inset Quotes erd
\end_inset 

 the data is collectively
\emph on 
, en mass
\emph default 
e
\begin_inset Note
collapsed false

\layout Standard

I don't think I agree with the statement - let's discuss - it's not strictly
 about similarity, it is about model-ability.
 -- Corrected
\end_inset 

.
 
\begin_inset Note
collapsed false

\layout Standard

LEFT OUT: Different measures of similarity are used as well as different
 types of warps.
\end_inset 

 Another way of explaining this process is to say that warps are being found
 that reveal data correspondences.
 Correspondences are found when points (or imaginary sample points of the
 curve) lie in analogous regions -- that is -- regions that are describing
 the same part of the logically equivalent class of objects.
 
\begin_inset Note
collapsed false

\layout Standard

No! incorrect: 'data lie in similar positions in the imaginary image grid'
 left out now...
\end_inset 

A warp implicitly defines an uneven plane for images to be embedded in and
 when all images get embedded in that plane, they should then be collectively
 similar.
 Interestingly, that similarity can be checked with the use of AAM's (reminiscen
t work can be found in 
\begin_inset LatexCommand \cite{Rueckert_non_rigid,lebriquer,wang_stats}

\end_inset 

).
 Ways of evaluating an appearance model and ways of drawing conclusions
 about the data that was used to build it already exist.
 The algorithms developed for this work use a similarity measure such as
 MSD or MI to see how similar images become during search
\begin_inset Foot
collapsed false

\layout Standard

This similarity computation is incorporated in the objective function and
 it usually comprises a collection of pair-wise similarity measures.
\end_inset 

, before a model is created.
 The model created from 
\emph on 
all
\emph default 
 the examples is the entity that defines the 'goodness' of the warps.
 A model can in some sense describe and measure of similarity across the
 entire set, as opposed to the pair-wise measures used previously.
 This construction of a model can in that unprecedented way guide the search
 for good warps
\begin_inset Note
collapsed false

\layout Standard

No.
 Why? How? RSS: Taken out: 
\begin_inset Quotes eld
\end_inset 

MI and MSD are utilised to check local, small-scale changes only 
\begin_inset Quotes eld
\end_inset 


\end_inset 

.
 The system seeks control points that define good warps and it seeks such
 points using the idea of reparameterisation.
 The resulting warps must then produce good models for the 
\emph on 
whole
\emph default 
 data.
 For example, in the case of these specific experiments, all the data instances
 are warped to become quite similar so the model created from them has a
 low determinant.
\layout Standard


\begin_inset Note
collapsed false

\layout Standard

CJT: This last paragraph is better -- RSS: *SMILE*
\end_inset 


\end_inset 


\layout Chapter
\pagebreak_top 

\noun on 

\begin_inset LatexCommand \label{cha:Project-Goals}

\end_inset 


\begin_inset LatexCommand \index{Project Plan}

\end_inset 


\noun default 
Assessment of Models and Non-Rigid Registration
\layout Standard


\begin_inset Note
collapsed false

\layout Standard

Called: A Model-based Registration Framework 
\layout Standard

Model Building
\end_inset 


\layout Standard
\align right 

\size large 

\begin_inset Quotes eld
\end_inset 

N
\size small 
othing in life is to be feared.
 It is only to be understood.
\begin_inset Quotes erd
\end_inset 


\newline 
-- 
\emph on 
Marie Currie.
 
\layout Standard


\begin_inset ERT
status Open

\layout Standard

\backslash 
lettrine{T}{he} 
\end_inset 

 most valuable contribution of the thesis is the introduction of a framework
 wherein NRR can be assessed without any use of ground truth.
 The framework is valuable not only because NRR applications are routinely
 used.
 This framework is considered useful because it offers a solution to a problem
 where cumbersome annotation is otherwise needed 
\begin_inset LatexCommand \cite{Crum_MICCAI_2005}

\end_inset 

.
 Novelty, on the one hand, should be attributed to seminal work by Davies
 
\emph on 
et al.

\emph default 
 
\begin_inset LatexCommand \cite{Davies_MDL}

\end_inset 

 while, on the other hand, the use of models in registration is unprecedented.
 Models were derived from a registration in the past 
\begin_inset LatexCommand \cite{Rueckert_2003}

\end_inset 

, but they were not actively used to assist or drive registration and its
 assessment.
\layout Standard

This chapter returns to discussing how models are built and proceeds to
 explaining an 
\emph on 
ad hoc
\emph default 
 method that is used to evaluate these models.
 Lastly, this evaluation method is applied to the problem of assessing the
 quality of NRR, merely by reversing a problem that is double-edged.
\layout Section

Building Appearance Models from Correspondences
\layout Standard


\begin_inset ERT
status Open

\layout Standard
As explained in Chapter 3, the key requirement in building an appearance model from a set of images, is the existence of a dense correspondence across the set. This is often defined by interpolating between the correspondences of a limited number of user-defined landmarks. Shape variation is then represented in terms of the motions of these sets of landmark points. Using the notation of Cootes et al~
\backslash 
cite{Cootes_ECCV_1998}, the shape (configuration of landmark points) of a single example can be represented as a vector $
\backslash 
mathbf{x}$ formed by concatenating the coordinates of the positions of all the landmark points for that example. The texture is represented by a vector $
\backslash 
mathbf{g}$, formed by concatenating image values (texture) sampled over a regular grid on the {
\backslash 
em registered} image.  This means that the a given element in $
\backslash 
mathbf{g}$ is sampled from an equivalent point in each image, assuming the registration is correct.
\layout Standard
In the simplest case, the variation of shape and texture is modeled in terms of multivariate gaussian distributions, using Principal Component Analysis (PCA)~
\backslash 
cite{PCA} to obtain linear statistical models of the form: 
\backslash 
begin{eqnarray} 
\backslash 
mathbf{x}&=&
\backslash 
mathbf{
\backslash 
overline{x}}+
\backslash 
mathbf{P}_{s}
\backslash 
mathbf{b}_{s} 
\backslash 
nonumber 
\backslash 

\backslash 
 
\backslash 
mathbf{g}&=&
\backslash 
overline{
\backslash 
mathbf{g}}+
\backslash 
mathbf{P}_{g}
\backslash 
mathbf{b}_{g} 
\backslash 
end{eqnarray} where $
\backslash 
mathbf{b}_{s}$ are shape parameters, $
\backslash 
mathbf{b}_{g}$ are texture parameters, $
\backslash 
mathbf{
\backslash 
overline{x}}$ and $
\backslash 
overline{
\backslash 
mathbf{g}}$ are the mean shape and texture, and $
\backslash 
mathbf{P}_{s}$ and $
\backslash 
mathbf{P}_{g}$ are the principal modes of shape and texture variation respectively.
\layout Standard
In generative mode, the input shape ($
\backslash 
mathbf{b}_{s}$) and texture ($
\backslash 
mathbf{b}_{g}$) parameters can be varied continuously, allowing the generation of sets of images whose statistical distribution matches that of the training set.
\end_inset 


\layout Standard


\begin_inset Float figure
wide false
collapsed false

\layout Standard
\align center 

\begin_inset Graphics
	filename Graphics/From_TMI_2006_Revision_2/aam_brain_set_modes_1-3.png
	scale 45.00

\end_inset 


\layout Caption


\begin_inset LatexCommand \label{apm_brain}

\end_inset 


\size small 
The effect of varying the first (top row), second, and third parameter of
 a brain appearance model by 
\begin_inset ERT
status Open

\layout Standard
$
\backslash 
pm2.5$
\end_inset 

 standard deviations
\end_inset 


\layout Standard


\begin_inset ERT
status Open

\layout Standard

\layout Standard
In many cases, the variations of shape and texture are correlated. If this correlation is taken into account, a combined statistical model is obtained. It has the more general form: 
\backslash 
begin{eqnarray} 
\backslash 
mathbf{x}&=&
\backslash 
bar{
\backslash 
mathbf{x}}+
\backslash 
mathbf{Q}_{s}
\backslash 
mathbf{c} 
\backslash 
nonumber 
\backslash 

\backslash 
 
\backslash 
mathbf{g}&=&
\backslash 
mathbf{
\backslash 
bar{g}}+
\backslash 
mathbf{Q}_{g}
\backslash 
mathbf{c} 
\backslash 
end{eqnarray} where the model parameters $
\backslash 
mathbf{c}$ control both shape and texture, and $
\backslash 
mathbf{Q}_{s}$, $
\backslash 
mathbf{Q}_{g}$ are matrices describing the general modes of variation derived from the training set. The effect of varying different elements of 
\backslash 
textbf{$
\backslash 
mathbf{c}$} for a model built from a set of 2-D MR brain images is shown in Figure 
\backslash 
ref{apm_brain}.  The number of modes (columns) in $
\backslash 
mathbf{Q}_{s}$ and $
\backslash 
mathbf{Q}_{g}$ is one less than the number of images.  In practice, it is often possible to approximate images well, using fewer modes $m$.
\layout Standard
Generally, we wish to distinguish  between the meaningful shape variation of the objects under consideration, and the apparent variation in shape that is due to the positioning of the object within the image (the pose of the imaged object). In this case, the appearance model is generated from an (affinely) aligned set of images. Point positions $
\backslash 
mathbf{x}_{im}$ in the original image frame are then obtained by applying the relevant pose transformation $T_{
\backslash 
mathbf{t}}(
\backslash 
cdot)$: 
\backslash 
begin{equation} 
\backslash 
mathbf{x}_{im}=T_{
\backslash 
mathbf{t}}(
\backslash 
mathbf{x}_{model}) 
\backslash 
end{equation} where $
\backslash 
mathbf{x}_{model}$ are the points in the model frame, and $
\backslash 
mathbf{t}$ are the pose parameters. For example, in 2-D, $T_{
\backslash 
mathbf{t}}$ could be a similarity transform with four parameters describing the translation, rotation and scale of the object.
\layout Standard

\layout Standard

\end_inset 


\layout Standard

In an analogous manner, the image can also be normalised with respect to
 the mean image intensities and image variance, 
\begin_inset Formula \begin{equation}
\mathbf{g}_{im}=T_{\mathbf{u}}(\mathbf{g}_{model}),\end{equation}

\end_inset 

 where 
\begin_inset Formula $T_{\mathbf{u}}$
\end_inset 

 consists of a shift and scaling of the image intensities.
 For further implementation details see\SpecialChar ~

\begin_inset LatexCommand \cite{Cootes_ECCV_1998,Edwards}

\end_inset 

.
\layout Standard


\begin_inset ERT
status Open

\layout Standard
As noted above, a meaningful, dense, groupwise correspondence is required before an appearance model can be built. NRR provides a natural method of obtaining such a correspondence, as noted by Frangi and Rueckert ~
\backslash 
cite{Frangi,Rueckert_2003}.  It is this link that forms the basis of our new approach to NRR evaluation.
\layout Standard
The link between registration and modelling is further exploited in the Minimum Description Length~(MDL)~
\backslash 
cite{IPMI_2005_ISBE} approach to groupwise NRR, where modelling becomes an integral part of the registration process. This is one of the registration strategies evaluated here.
\layout Standard

\end_inset 


\layout Section

Generalisation and Specificity
\layout Standard

A previous chapter, as well as Section 5.3, described how the results of
 NRR can be used to build a generative statistical model of image appearance.
 In this section, the method for quantitatively assessing the quality of
 the model is presented.
 The model is built from the registered data and, hence, the quality of
 the NRR from which the model was derived.
 Several variants of the approach are introduced, with the aim of finding
 one which is both robust and sensitive to small misregistrations.
\layout Standard


\begin_inset ERT
status Open

\layout Standard

\layout Standard
 
\backslash 
label{sec:Evaluation}
\layout Standard

\layout Standard

\backslash 
label{Model_Measures} 
\layout Standard
A good model of a set of training data should possess several properties. Firstly, the model should be able to extrapolate and interpolate effectively from the training data, to produce a range of images from the same general class as those seen in the training set. This property will be called {
\backslash 
em generalisation ability} from this point onwards. Conversely, the model should not produce images which cannot be considered as valid examples of the class of image modelled. That is, a model built from brain images should only generate images which could be considered as valid images of possible brains. This will be called the {
\backslash 
em specificity} of the model. In previous work, quantitative measures of {
\backslash 
em specificity} and {
\backslash 
em generalisation} were used to evaluate shape models~
\backslash 
cite{Davies_MDL_MI}. The extension of these ideas to images (as opposed to shapes) is presented here. Figure~
\backslash 
ref{hyperspace} provides an overview of the approach.
\layout Standard
Consider first the training data for the model, that is, the set of images which were the input to NRR. Without loss of generality, each training image can be considered as a single point in an $n$-dimensional image space. A statistical model is then a probability density function (pdf) $p(
\backslash 
mathbf{z})$ defined on this space.
\layout Standard
To be specific, let $
\backslash 
{
\backslash 
mathbf{I}_{i}:i=1,
\backslash 
ldots 
\backslash 
mathcal{N}
\backslash 
}$ denote the $
\backslash 
mathcal{N}$ images of the training set when considered as points in image space. Let $p(
\backslash 
mathbf{z})$ be the probability density function of the model. A quantitative measure of the {
\backslash 
em specificity} $S$ of the model is defined, with respect to the training set $
\backslash 
mathcal{I} = 
\backslash 
{
\backslash 
mathbf{I}_{i}
\backslash 
}$ as follows: 
\backslash 
begin{equation} S_{
\backslash 
lambda}(
\backslash 
mathcal{I};p) 
\backslash 
doteq 
\backslash 
int p(
\backslash 
mathbf{z}) 
\backslash 
mathbf{min}_{i}
\backslash 
left(|
\backslash 
mathbf{z}-
\backslash 
mathbf{I}_{i}|
\backslash 
right)^{
\backslash 
lambda} 
\backslash 
: d
\backslash 
mathbf{z},
\backslash 
label{eq:Sdef} 
\backslash 
end{equation} where $|
\backslash 
cdot|$ is a distance on image space, raised to some positive power $
\backslash 
lambda$ (for the remainder of this chapter only the case $
\backslash 
lambda$ = 1 will be considered). That is, for each point $
\backslash 
mathbf{z}$ on image space, the nearest-neighbour to this point in the training set is found. Then, the powers of the nearest-neighbour distances it is summed up, weighted by the pdf $p(
\backslash 
mathbf{z})$. Greater specificity is indicated by {
\backslash 
em smaller} values of $S$, and vice versa. In Figure~
\backslash 
ref{S&G}, diagrammatic examples of models with differing specificity is given.
\layout Standard
The integral in equation 
\backslash 
ref{eq:Sdef} can be approximated using a Monte-Carlo method. A large random set of images $
\backslash 
{ 
\backslash 
mathbf{I}_{
\backslash 
mu}:
\backslash 
, 
\backslash 
mu=1,
\backslash 
ldots 
\backslash 
mathcal{M}
\backslash 
}$ is generated, having the same distribution as the model pdf $p(
\backslash 
mathbf{z})$. The estimate of the specificity (
\backslash 
ref{eq:Sdef}) is: 
\backslash 
begin{equation}
\backslash 
label{Seq} S_{
\backslash 
lambda}(
\backslash 
mathcal{I};p)
\backslash 
approx 
\backslash 
frac{1}{
\backslash 
mathcal{M}}
\backslash 
sum
\backslash 
limits_{
\backslash 
mu=1}^{
\backslash 
mathcal{M}}
\backslash 
mathbf{min}_{i}
\backslash 
left(|
\backslash 
mathbf{I}_{i}-
\backslash 
mathbf{I}_{
\backslash 
mu}|
\backslash 
right)^{
\backslash 
lambda}, 
\backslash 
end{equation} with standard error: 
\backslash 
begin{equation} 
\backslash 
sigma_{S}=
\backslash 
frac{SD_{
\backslash 
mu} 
\backslash 
left
\backslash 
{
\backslash 
mathbf{min}_{i}
\backslash 
{|
\backslash 
mathbf{I}_{i}-
\backslash 
mathbf{I}_{
\backslash 
mu}|^
\backslash 
lambda
\backslash 
}
\backslash 
right
\backslash 
}}{
\backslash 
sqrt{
\backslash 
mathcal{M}-1}}, 
\backslash 
label{S_SE} 
\backslash 
end{equation} where $SD_{
\backslash 
mu}$ is the standard deviation of the set of $
\backslash 
mu$ measurements.  Note that this definition of $S$ does not require that the space of images  is constructed. Instead, one simply needs to be able to define distances between images.  This is discussed in Section~
\backslash 
ref{Shuffle} below. 
\end_inset 


\layout Standard


\begin_inset ERT
status Open

\layout Standard

\layout Standard
 A measure of generalisation similarly is defined, simply reversing the direction of the nearest-neighbour distance measure: 
\backslash 
begin{equation}
\backslash 
label{Geq} G_{
\backslash 
lambda}(
\backslash 
mathcal{I};p)
\backslash 
doteq 
\backslash 
frac{1}{
\backslash 
mathcal{N}}
\backslash 
sum
\backslash 
limits_{i=1}^{
\backslash 
mathcal{N}}
\backslash 
mathbf{min}_{
\backslash 
mu}
\backslash 
left(|
\backslash 
mathbf{I}_{i}-
\backslash 
mathbf{I}_{
\backslash 
mu}|
\backslash 
right)^{
\backslash 
lambda}, 
\backslash 
end{equation} with standard error: 
\backslash 
begin{equation} 
\backslash 
sigma_{G}=
\backslash 
frac{SD_{i} 
\backslash 
left
\backslash 
{
\backslash 
mathbf{min}_{
\backslash 
mu}
\backslash 
{|
\backslash 
mathbf{I}_{i}-
\backslash 
mathbf{I}_{
\backslash 
mu}|^
\backslash 
lambda
\backslash 
}
\backslash 
right
\backslash 
}}{
\backslash 
sqrt{
\backslash 
mathcal{N}-1}}. 
\backslash 
label{G_SE} 
\backslash 
end{equation} That is, for each member of the training set $
\backslash 
mathbf{I}_{i}$, the distance to the nearest-neighbour in the sample set $
\backslash 
{
\backslash 
mathbf{I}_{
\backslash 
mu}
\backslash 
}$ is computed. Large values of $G$ correspond to model distributions which do not cover the training set and have poor generalisation ability, whereas small values of $G$ indicate models with better generalisation ability.
\layout Standard
Note here that both measures can be further extended, by considering the sum of distances to $k$-nearest-neighbours, rather than just to the single nearest-neighbour. However, the choice of $k$ would require careful consideration and in what follows, expeiments shown are restricted to the single nearest-neighbour case.
\end_inset 


\layout Section

Image distance measures
\layout Standard


\begin_inset Float figure
wide false
collapsed false

\layout Standard
\align center 

\begin_inset Graphics
	filename Graphics/From_TMI_2006_Revision_2/evaluation_framework-revised.png
	display none
	scale 45.00

\end_inset 


\layout Caption


\begin_inset LatexCommand \label{hyperspace}

\end_inset 

The model evaluation framework: A model is constructed from the training
 set and used to generate synthetic images.
 The training set and the set generated by the model can be viewed as clouds
 of points in image space (
\begin_inset Formula $\mathbf{I}_{i}$
\end_inset 

 represented by stars, and 
\begin_inset Formula $\mathbf{I}_{\mu}$
\end_inset 

 represented by dots).
\end_inset 


\layout Standard
\align center 

\begin_inset Float figure
wide false
collapsed false

\layout Standard
\align center 

\begin_inset Graphics
	filename Graphics/From_TMI_2006_Revision_2/sg-revised.png
	display none
	scale 45.00

\end_inset 


\layout Caption


\begin_inset LatexCommand \label{S&G}

\end_inset 

Training set (points) and model pdf (shading) in image space.
 
\series bold 
Left:
\series default 
 A model which is specific, but not general.
 
\series bold 
Right:
\series default 
 A model which is general, but not specific.
\end_inset 


\layout Standard
\align center 

\begin_inset Float figure
wide false
collapsed false

\layout Standard
\align center 

\begin_inset Graphics
	filename Graphics/From_TMI_2006_Revision_2/shuffle_comparison-revised.png
	display none
	scale 50.00

\end_inset 


\layout Caption


\begin_inset LatexCommand \label{shuffle_images}

\end_inset 

A comparison between shuffle difference images evaluated using various size
 neighbourhoods (radius 
\begin_inset Formula $r$
\end_inset 

).
 
\series bold 
Left:
\series default 
 original image, 
\series bold 
right:
\series default 
 warped image, 
\series bold 
centre, from the left:
\series default 
 shuffle distance with 
\begin_inset Formula $r=1$
\end_inset 

(Euclidean), 
\begin_inset Formula $1.5,2.9$
\end_inset 

 and 
\begin_inset Formula $3.7$
\end_inset 

 pixels.
\end_inset 


\layout Standard


\begin_inset ERT
status Open

\layout Standard

\backslash 
label{Shuffle}  The definitions provided for specificity and generalisation require a measure of separation in image space. The most straightforward way to measure the distance between images is to treat each image as a vector formed by concatenating the pixel/voxel intensity values, then take the Euclidean distance. This means that each pixel/voxel in one image is compared against its spatially corresponding pixel/voxel in another image. Although this has the merit of simplicity, it does not provide a very well-behaved distance measure since it increases rapidly for quite small image misalignments~
\backslash 
cite{wang}. Another possibility is the use of Image Euclideadn Distance (IMED), as proposed in a recent paper. While this approach was implemented and tested, it was not considered further due to efficiency and constraints.
\layout Standard
This observation led to consideration of an alternative distance measure, based on the 'shuffle difference', inspired by the 'shuffle transform' 
\backslash 
cite{Shuffle}. Given two images $
\backslash 
mathbf{I}_1(
\backslash 
mathbf{x})$ and $
\backslash 
mathbf{I}_2(
\backslash 
mathbf{
\backslash 
mathbf{x}})$, the shuffle distance between them is defined as 
\backslash 
begin{equation} D_s(
\backslash 
mathbf{I}_1,
\backslash 
mathbf{I}_2)=
\backslash 
frac{1}{n} 
\backslash 
sum_{
\backslash 
mathbf{x}} 
\backslash 
mathbf{min}_{i}
\backslash 
|
\backslash 
mathbf{I}_1(
\backslash 
mathbf{x})-
\backslash 
mathbf{I}_2(
\backslash 
mathbf{N}_i(
\backslash 
mathbf{x}))
\backslash 
| 
\backslash 
end{equation} where $
\backslash 
|
\backslash 
cdot
\backslash 
|$ is the absolute difference, there are $n$ pixels (or voxels) indexed by $
\backslash 
mathbf{x}$, and $
\backslash 
{
\backslash 
mathbf{N}_i(
\backslash 
mathbf{x})
\backslash 
}$ is the set of pixels in a neighbourhood of radius $r$ around $
\backslash 
mathbf{x}$.
\layout Standard
The idea is illustrated in Figure~
\backslash 
ref{shuffle_diagram}. Instead of taking the sum-of-squared-differences between corresponding pixels, the minimum absolute difference between each pixel in one image and the values in a neighbourhood around the corresponding pixel is used. This is less sensitive to small misalignments, and provides a better-behaved distance measure. The tolerance for misalignment is dependent on the size of the neighbourhood ($r$), as is illustrated in Figure~
\backslash 
ref{shuffle_images}.
\end_inset 


\layout Standard
\align center 

\begin_inset Float figure
wide false
collapsed false

\layout Standard
\align center 

\begin_inset Graphics
	filename Graphics/From_TMI_2006_Revision_2/brains_shuffle_symmetric-revised.png
	display none
	scale 45.00

\end_inset 


\layout Caption


\begin_inset LatexCommand \label{shuffle_diagram}

\end_inset 


\size small 
The calculation of a shuffle difference image
\end_inset 


\layout Standard


\begin_inset ERT
status Open

\layout Standard
It should be noted that the shuffle distance as defined above depends on the direction in which it is measured (see Figure~
\backslash 
ref{shuffle_examples}), hence is not a true distance. It is trivial to construct a symmetric shuffle distance, by averaging the distance calculated in both directions between a pair of images.  It was found, however, that the improvement obtained was not significant, and did not justify the increased computation time. In what follows, the asymmetric shuffle distance is used exclusively.
\end_inset 


\layout Standard


\begin_inset Note
collapsed true

\layout Subsection
\pagebreak_top 

\noun on 

\begin_inset LatexCommand \label{cha:Reg_Algorithm}

\end_inset 


\begin_inset LatexCommand \index{Algorithms}

\end_inset 


\noun default 
Evaluating Models of Appearance
\layout Standard
\align right 

\size large 

\begin_inset Quotes eld
\end_inset 

S
\size small 
cience is the systematic classification of experience.
\begin_inset Quotes erd
\end_inset 


\newline 
-- 
\emph on 
George Henry Lewes.
\layout Standard


\begin_inset ERT
status Open

\layout Standard

\backslash 
lettrine{S}{ ome}
\end_inset 

 methods and results have been discussed in the section about experiments.
 That section dealt with two distinct families of problems, but the main
 one was image registration and the relations it has to models of appearance.
 From this point onwards in this chapter, discussions will concentrate on
 that one later portion of the work.
 For the realisation of one successful approach and for completeness, this
 section will also explain the way in which registration is performed at
 present.
\layout Standard

A later part of this chapter outlines the structure of the successful approach
 graphically.
 It is followed by the proposal of a two new approaches to be attempted
 in the near future if time permits.
 These more illustrative parts may be hard to follow, but references should
 clear up the way to full understanding.
 They should also serve as a starting point for greater exploration of this
 approach and fore-coming plans as they currently stand.
\layout Subsection
\pagebreak_top 

\noun on 

\begin_inset LatexCommand \label{cha:Progress}

\end_inset 


\begin_inset LatexCommand \index{Progress}

\end_inset 


\noun default 
Assessment of Registration using Models
\layout Standard
\align right 

\size large 

\begin_inset Quotes eld
\end_inset 

W
\size small 
e see only what we know.
\begin_inset Quotes erd
\end_inset 


\newline 
-- 
\emph on 
Wolfgang von Goethe.
\layout Standard


\begin_inset Note
collapsed false

\layout Standard


\noun on 
General Progress and Contributions
\noun default 
 used to be the chapter name
\end_inset 


\end_inset 


\layout Chapter
\pagebreak_top 
Validation Methodology and Experiments
\layout Standard


\begin_inset Note
collapsed false

\layout Standard


\noun on 

\begin_inset LatexCommand \label{cha:Experiments}

\end_inset 


\begin_inset LatexCommand \index{Experimentation}

\end_inset 


\noun default 
MDL Appearance Models and Registration
\end_inset 


\layout Standard
\align right 

\size large 

\begin_inset Quotes eld
\end_inset 

W
\size small 
e know nothing in reality; for truth lies in an abyss.
\begin_inset Quotes erd
\end_inset 


\newline 
-- 
\emph on 
Democritus.
\layout Standard


\begin_inset ERT
status Open

\layout Standard

\backslash 
lettrine{I}{n} 
\end_inset 

order for the assessment method to deem credible, one need to test it against
 data where the correct solution is known.
 Then, in attempts to arrive at a particular true answer, one can confirm
 correctness and validity of the method.
 In the next couple of chapters, the most comprehensive set of experiments
 is described in detail.
 The experiments represent a culmination of the work since they address
 and solve a problem which is commonly explored.
 They embody just one aspect of the work, which successfully unifies a broader
 whole.
 While building of models using NRR and evaluation of any type of model
 is possible, the chapter only concentrates on in-depth experiments where
 the quality of NRR of two brain sets is studied.
\layout Standard

Two sets of experiments were performed, one designed to validate the model-based
 approach for evaluating NRR, the other to demonstrate its use in a practical
 application.
 The latter experiment is described in the next Chapter.
\layout Standard


\begin_inset ERT
status Open

\layout Standard

\layout Standard

\backslash 
label{sec:Validation}
\layout Standard

\layout Standard

\layout Standard
In the first set of experiments the aim was to show that Specificity and Generalisation are valid measures of the degree of misregistration of a group of images. It is expected that, as registration is degraded, Specificity and Generalisation should respond accordingly. If the measures are indicative of the quality of NRR, then they can be employed in benchmark-type NRR studies.
\layout Standard
A set of registered images, for which ground-truth labels were available, was used and a series of deformations was then applied. The labels were binary images, each of which corresponds to an anatomical compartment of the brain. As deformations were applied to the images and their accompanying labels, any binary image was interoplated to become fuzzy. Images and their ground-truth labels were deformed in tandem so, for every pixel in the image, its corresponding anatomical classification (derived from the corresponding label) moved along with it. The deformation was repeated with varying degress of magnitude, which were carefully controlled and studied from the warp fields. This introduced progressively-increasing misregistration. This made it possible to investigate how measures of Specificity and Generalisation varied, as a function of the known misregistration. The newly-created test set was composed of progressively-degraded pseudo-registrations that substitute real NRR results where the correct solution is unknown, or subjected to bias. Generalised overlap was also measured for each of the deformed image sets, using the ground-truth labels, to provide a comparison with the existing method that is based on models.
\layout Standard

\layout Standard
In the second set of experiments the aim was to demonstrate that one could usefully discriminate between different NRR algorithms, by comparing results for the same dataset. Several algorithms were to perform a full registration on the same datasets and their results evaluated using the same three measures (metric) that have been validated.
\layout Standard

\backslash 
subsection{Image Data}
\layout Standard
To conduct the experiments two different sets of MR images of the brain were used. The first, which will be referred to as the 'MGH Dataset' (see Acknowledgements), was a set of 2-D transaxial mid-brain slices, extracted at an equivalent level from each of a set of affinely aligned T1-weighted 3-D MR scans of $
\backslash 
mathcal{N}=36$ normal subjects. As well as the images themselves, there is access to ground-truth data, in the form of dense (pixel by pixel) anatomical label maps for the gray and white matter, the caudate nucleus, and the lateral ventricles. These labels were further divided into left and right hemispheres. The anatomical labels were obtained by manual annotation under conditions of rigorous quality control.  An example image and the corresponding label maps are shown in Figure~
\backslash 
ref{image_and_labels}. 
\end_inset 


\layout Standard
\align center 

\begin_inset Float figure
wide false
collapsed false

\layout Standard
\align center 

\begin_inset Graphics
	filename Graphics/From_TMI_2006_Revision_2/shuffle_images-revised.png
	display none
	scale 45.00

\end_inset 


\layout Caption


\begin_inset LatexCommand \label{shuffle_examples}

\end_inset 


\size small 
Examples of the shuffle difference image: from first to second (left), from
 second to first (centre), and the symmetrical shuffle difference image
 (right)
\end_inset 


\layout Standard


\begin_inset ERT
status Open

\layout Standard
 The set of images was non-rigidly registered using a Minimum Description Length~(MDL) NRR algorithm~
\backslash 
cite{IPMI_2005_ISBE}, and this registration was used as the starting point for a systematic evaluation of the effects of misregistration. Although the initial registration is subjected and inclined to the MDL objective function, this provides a sufficiently-good starting point, assuming that each deformation degrades the registartion rather than improve it.
\layout Standard
The second set of images, which will be referred to as the 'Dementia Dataset', consisted of a set of 2-D transaxial mid-brain slices, extracted at an equivalent level from each of a set of affinely-aligned T1-weighted 3-D MR scans of $
\backslash 
mathcal{N}=104$ subjects entered into a clinical study of dementia. These images varies in terms of intensity, size, and shape from the former set, which means that the method cannot be fit and customised to work with just a particular set of data. This makes the arguments as regards validation ever more compelling. While other datasets such as face images were used in validation experiments where models are shown to degrade, in terms of Generalisation and Specificity, as a function of deformation, their scope and contribution is assumed to be unnecessary for the method's validity to be defended.
\layout Standard

\backslash 
subsection{Perturbing the Initial Registration}
\layout Standard

\layout Standard
In order to perform a systematic evaluation of the effects of misregistration, multiple image sets were created, based on the MGH Dataset, but with controlled degrees of misregistration.  To create a misregistered set, the original image set was taken and had applied to it a set of smooth pseudo-random spatial warps, based on biharmonic Clamped Plate Splines~
\backslash 
cite{CPS}. The warp for each image was controlled by 25 randomly placed knot-points, each displaced in a random direction by a distance drawn from a Gaussian distribution whose mean controlled the degree of misregistration introduced. This provided a very general family of warps. The direction and magnitude of these warps were carefully studied to ensure that all parts of the image were subjected to homogenous deformations. The degree of misregistration was analysed by measuring $d$, the average magnitude of pixel displacement over the whole image. This was done by tracing the per-pixel shift in the warp fields. The standard deviation of these warp was verify the validity of this Gaussian distribution. A total of 70 misregistered image sets were generated-- 10 warp-set instantiations for each of 7 different values of $d$ (0.0643, 0.249, 0.685, 1.36, 2.21, 2.76, and 4.15 pixels). Examples of warped images are shown in Figure~
\backslash 
ref{warps_16}.
\layout Standard

\end_inset 


\layout Standard
\align center 

\begin_inset Float figure
wide false
collapsed false

\layout Standard
\align center 

\begin_inset Graphics
	filename Graphics/From_TMI_2006_Revision_2/brain_and_labels_CAROLE.png
	display none
	scale 35.00

\end_inset 


\layout Caption


\begin_inset LatexCommand \label{image_and_labels}

\end_inset 


\size small 

\begin_inset ERT
status Open

\layout Standard
An example affinely-aligned brain image and its accompanying anatomical labels, both overlaid and expanded, for gray matter, white matter, the lateral ventricles, and the caudate nucleus. The labels are also divided into left and right.
\end_inset 


\end_inset 


\layout Standard
\align center 

\begin_inset Float figure
wide false
collapsed false

\layout Standard
\align center 

\begin_inset Graphics
	filename Graphics/From_TMI_2006_Revision_2/example_warp_mangnitude_brains_16.png
	display none
	scale 23.00

\end_inset 


\layout Caption


\begin_inset LatexCommand \label{warps_16}

\end_inset 


\size small 

\begin_inset ERT
status Open

\layout Standard
An original image from the MGH Dataset (top left) and examples of warped versions of the same image obtained using different values of $d$, the mean pixel displacement (shown on each image).
\end_inset 


\end_inset 


\layout Standard


\begin_inset ERT
status Open

\layout Standard
 
\backslash 
subsection{Validation using Warped Images} 
\backslash 
label{validation}
\layout Standard
Given the 70 image sets described above, each with known average misregistration, $d$,  the relationship between $d$ and Specificity, Generalisation, and Generalised Overlap was investigated, by calculating the mean and standard error for each measure over the 10 warp instances for each value of $d$. In total, there were 71 image sets to study. One is the original registered set and the other 70 image sets comprise 10 instantiatuion for each value of $d$.
\layout Standard
For each misregistered image set, Specificity and Generalisation were calculated, as described in Section ~
\backslash 
ref{Model_Measures}, using $m$~=~15 modes of variation for the model and $
\backslash 
mathcal{M}$~=~1000 synthetic images drawn from a Gaussian distribution, as described in Section ~
\backslash 
ref{Appearance}. This was repeated for values of shuffle radius, $r$, of 1 (Euclidean distance), 1.5, 2.1 and 3.7, as defined in Section ~
\backslash 
ref{Shuffle}, corresponding to circular neighbourhoods contained within 1x1, 3x3, 5x5 and 7x7 pixel patches respectively. These experiments were repeated with 2.5
\backslash 
%, 5.0
\backslash 
% and 10
\backslash 
% Gaussian intensity noise added to the misregistered images, in order to investigate the sensitivity of the model-based measures to image noise. This makes possible to argue in favour of the robuestness of these measures to noise, as well as knowing its caveats.
\layout Standard
Similarly, Generalised Overlap with volume, equal, inverse volume and complexity weightings were calculated, as defined in Chapter 2. The mean and standard error for each measure over the 10 warp instances for each value of $d$ was also calculated.
\layout Standard

\backslash 
subsection{Sensitivity} 
\backslash 
label{sec:sensitivity}
\layout Standard
The size of perturbation that can be detected in the validation experiments will depend both on the change in the values of the measures as a function of misregistration and the standard error of those values. To quantify this, the sensitivity of a measure was defined as follows.
\layout Standard

\backslash 
begin{equation}
\backslash 
label{sensitivity} D(m;d) = 
\backslash 
frac{1}{{
\backslash 
sigma}_m}
\backslash 
left(
\backslash 
frac{m(d)-m(0)}{d}
\backslash 
right), 
\backslash 
end{equation}
\layout Standard

\backslash 
noindent where $m(d)$ is the value of the measure for some degree of deformation $d$, ${
\backslash 
sigma}_m$ is the standare error of the estimate of $m(d)$. $D(m;d)=1$ is the change in $d$ required for $m(d)$ to change by one noise standard error, which indicates the lower limit of change in misregistration $d$ which can be detected by the measure. $D$ is a function of $d$; to simplify comparison between different methods of evaluation, we also use the mean sensitivity over a range of values of $d$.
\layout Standard
In order to compare the sensitivities of different methods of evaluation, the expected error in $D$ also needed to be estimated. Since the validation experiments provided repeated estimates of $m(d)$, one can obtain empirical estimates of the errors in $m(d)$, $m(0)$, and ${
\backslash 
sigma}_m$.  These can be combined, using error propagation, to estimate the uncertainty in the estimate of sensitivity.
\layout Standard

\end_inset 


\layout Standard
\align center 

\begin_inset Float figure
wide false
collapsed false

\layout Standard
\align center 

\begin_inset Graphics
	filename Graphics/From_TMI_2006_Revision_2/overlap-based-evaluation-no-shadow-colour.png
	display none
	scale 35.00

\end_inset 


\layout Caption


\begin_inset LatexCommand \label{overlap_results}

\end_inset 


\size small 

\begin_inset ERT
status Open

\layout Standard
Overlap measures (with corresponding  $
\backslash 
pm$ one standard error errorbars) for the MGH dataset as a function of the degree of degradation of registration correspondence, $d$. The various graphs correspond to the various tissue weightings as defined in Chapter 2.
\end_inset 


\end_inset 


\layout Standard
\align center 

\begin_inset Float figure
wide false
collapsed false

\layout Standard
\align center 

\begin_inset Graphics
	filename Graphics/From_TMI_2006_Revision_2/generalisation_curves_corrected.png
	display none
	scale 30.00

\end_inset 

\SpecialChar ~

\begin_inset Graphics
	filename Graphics/From_TMI_2006_Revision_2/specificity_curves_corrected.png
	display none
	scale 30.00

\end_inset 


\layout Caption


\begin_inset LatexCommand \label{brain_spec}

\end_inset 


\size small 

\begin_inset ERT
status Open

\layout Standard
Generalisation 
\backslash 
& Specificity for various definitions of image distance (varying shuffle radius) with corresponding $
\backslash 
pm$ one standard error errorbars as a function of the degree of degradation of the registration correspondence $d$ for the MGH dataset
\end_inset 


\end_inset 


\layout Standard


\begin_inset ERT
status Open

\layout Standard
 
\backslash 
section{Results} 
\backslash 
label{sec:Results}
\layout Standard

\backslash 
label{sec:validation-results}
\layout Standard
Figure~
\backslash 
ref{overlap_results} plots each of the four variants of the generalised overlap measure, as a function of $d$, the degree of misregistration. As expected, the value decreases monotonically with increasing misregistration, in each case. This shows that the two gold-standard measures of misregistration (mean pixel displacement and ground-truth overlap) are in agreement, which validates the experimental framework.
\layout Standard
Similarly, Figure~
\backslash 
ref{brain_spec} plots Generalisation and Specificity as functions of $d$, for different values of shuffle radius $r$. The results are qualitatively similar to those obtained for generalised overlap, except that both measures {
\backslash 
em increase} monotonically with increasing misregistration, as expected (see Section~
\backslash 
ref{sec:Evaluation}. These results show that, over the range of misregistrations investigated, the model-based measures are good surrogates for $d$, the mean pixel misregistration. Since the warps used to introduce controlled misregistration were of very general form, there is no reason to suppose that this result is dependent on the pattern of misregistration. 
\layout Standard

\backslash 
subsection{Sensitivity}
\layout Standard
Figure ~
\backslash 
ref{fig:sensitivity} shows the results of applying sensitivity analysis to the validation study. These demonstrate that Specificity is more sensitive (is able to detect smaller misregistrations) than the overlap-based approach, which is in turn more sensitive than Generalisation. Note from the error bars that these differences are statistically significant. Maximum sensitivity is achieved with a shuffle radius of $1.5$ or $2.1$. The most sensitive generalised overlap measure is obtained using label-complexity weighting.
\layout Standard
 
\backslash 
subsection{Effect of Noise}
\layout Standard
The validation experiments were repeated and sensitivity analysis reported above with added image noise.  Although the absolute values of the model-based measures were shifted upwards, as would be expected, there were no changes in the relative values, nor any systematic or statistically significant changes in sensitivity, even for 10
\backslash 
% added noise.
\end_inset 


\layout Standard
\align center 

\begin_inset Float figure
wide false
collapsed false

\layout Standard
\align center 

\begin_inset Graphics
	filename Graphics/From_TMI_2006_Revision_2/sensitivity_graph.png
	display none
	scale 70.00

\end_inset 


\layout Caption


\begin_inset LatexCommand \label{fig:sensitivity}

\end_inset 

Mean sensitivity of different NRR assessment methods over the full range
 of deformations 
\begin_inset Formula $d$
\end_inset 

, shown with 
\begin_inset Formula $\pm$
\end_inset 

one standard error errorbars
\end_inset 


\layout Standard
\align center 

\begin_inset Float figure
wide false
collapsed false

\layout Standard
\align center 

\begin_inset Graphics
	filename Graphics/From_TMI_2006_Revision_2/groupwise_model.png
	display none
	scale 70.00
	keepAspectRatio

\end_inset 


\layout Caption


\begin_inset LatexCommand \label{mdl_model}

\end_inset 

The first mode (
\begin_inset Formula $\pm2.5$
\end_inset 

 standard deviations) of an appearance model built automatically by group-wise
 registration.
\end_inset 


\layout Standard
\align center 

\begin_inset Note
collapsed false

\layout Standard


\begin_inset Float figure
wide false
collapsed false

\layout Standard
\align center 

\begin_inset Graphics
	filename Graphics/From_TMI_2006_Revision_2/registration_results_HORIZ.png
	scale 70.00

\end_inset 


\layout Caption


\begin_inset LatexCommand \label{cap:Landmark-identification}

\end_inset 


\end_inset 


\end_inset 


\layout Comment

Previously called: Potential Developments and Goals
\layout Chapter
\pagebreak_top 
Application to Non-Rigid Registration Evaluation
\layout Standard
\align right 

\size large 

\begin_inset Quotes eld
\end_inset 

C
\size small 
ivilisations can only be understood by those who are civilised.
\begin_inset Quotes erd
\end_inset 


\newline 
-- 
\emph on 
Alfred North Whitehead.
\layout Standard


\begin_inset ERT
status Open

\layout Standard

\backslash 
lettrine{T}{ this}
\end_inset 

 chapter presents one among the practical applications of the word presented
 thus far.
 Apart from assessment of appearance model of the brain and human face,
 one is able to assess the quality of registration algorithm.
 The following benchmark is the most extensive set of experiments performed
 and it demonstrates that an important routine task such as NRR can be indeed
 simplified, by obviating the need for ground truth data.
\layout Standard


\begin_inset ERT
status Open

\layout Standard

\layout Standard

\backslash 
section{Comparing Registration Algorithms} 
\backslash 
label{sec:comparing-reg}
\layout Standard
To illustrate the application of model-based evaluation in practice, the NRR results obtained using three different methods for registering a group of images were compared, as described in more detail below. The intent was to establish whether it was possible, in a practical setting, to detect significant differences in performance between different NRR algorithms.  All three registration methods used the same piecewise affine representation of image warps~
\backslash 
cite{Cootes_Piecewise_Affine_BMVC} and the same multi-resolution optimisation framework.  The same number of iterations (function evaluations) were used in each case.
\layout Standard
The three registration algorithms were applied to two datasets.  The MGH Dataset was used because it allowed the evaluation results obtained using Specificity and Generalisation to be compared with an evaluation based on the Generalised Overlap measure (using ground truth). For these experiments $
\backslash 
mathcal{M}$~=~500 synthetic images were used to estimate Specificity and Generalisation. The Dementia Dataset was used because it was more representative of a typical clinical study, and it is important to demonstrate that the results were not dataset-specific. For these experiments  $
\backslash 
mathcal{M}$~=~1000 synthetic images were used.
\layout Standard
The three registration methods used were as follows.
\layout Standard

\backslash 
subsection{Pairwise Registration to a Reference} A commonly used approach to registering a group of images is to register each image in the group in turn to a reference image chosen from the group, using a pairwise objective function (e.g.,~
\backslash 
cite{Rueckert_2003}).  We used this approach as a baseline, with a sum of absolute intensity differences objective function (which gave slightly better results than sum of squared differences or mutual information).
\layout Standard
Pairwise approaches to registration can produce reasonable correspondences, but suffer from the problem that the results obtained depend on the choice of reference. Refinements of the basic approach are possible, where the reference is initialised and updated so as to be representative of the group of images as a whole.  It is important to note, however, that even in this case the correspondence for a given image is determined solely by the information in the image and the reference.  More recently, there has been considerable interest in {
\backslash 
em groupwise} methods which aim to make more systematic use of the information in the complete set of images when establishing correspondence.  The remaining two methods we tested fall into this category.
\layout Standard

\backslash 
subsection{Groupwise Congealing Algorithm} Learned-Miller et. al.~
\backslash 
cite{Miller_CVPR2000} originally introduced their 'congealing' algorithm for registering a set of hand-written digits. The aim was to avoid the arbitrary selection of a co-ordinate frame, by repeatedly registering each image with an evolving "average" model. Given the current set of transformed images (initially the original images), for each pixel position, $i$, the probability density function of intensities, $v$, at that position across the set of images, $p_i(v)$ is estimated.  The objective function is then the sum of entropies of these distributions across the whole image, $F=
\backslash 
sum_i 
\backslash 
int p_i(v) {
\backslash 
bf log} p_i(v) dv$.  A set of image deformations were optimised to minimise this. In later work on registering sets of 3-D medical images~
\backslash 
cite{Zollei_2005}, the objective function was approximated by $
\backslash 
sum_j 
\backslash 
sum_i {
\backslash 
bf log}p_i(v_{ij})$, where $v_{ij}$ is the value of pixel $i$ in deformed image $j$. During optimisation, each image was warped so as to bring pixels with similar intensities into correspondence across the set.  We implemented this later approach.
\layout Standard

\backslash 
subsection{Groupwise MDL Algorithm}  A groupwise method which uses a Minimum Description Length~(MDL) formulation~
\backslash 
cite{IPMI_2005_ISBE} has previously been described. The main idea is that the complete set of images can be encrypted as a coded message, and the description length ~
\backslash 
cite{Rissanen_MDL} in bits used as an objective function. Rather than encoding the raw images, the encoding uses an appearance model, built using the estimated correspondences, to approximate the data; the encoding needs also to include details of the model itself and of the discrepancy between each image and its model approximation. As the registration proceeds, the correspondences, and hence the appearance model, are continually updated so as to minimise the description length.
\end_inset 


\layout Standard


\begin_inset Float figure
wide false
collapsed false

\layout Standard
\align center 

\begin_inset Graphics
	filename Graphics/From_TMI_2006_Revision_2/combined-view-nrr-assessment-tmi.png
	scale 25.00

\end_inset 


\layout Caption


\begin_inset LatexCommand \label{fig_sim}

\end_inset 


\series bold 
Left and right:
\series default 
 Generalisation and Specificity of the three registration methods as a function
 of the number of modes included in the appearance
\end_inset 


\layout Standard


\begin_inset ERT
status Open

\layout Standard

\layout Standard

\backslash 
section{Results of Comparison}
\layout Standard
Figure~
\backslash 
ref{fig_sim} compares the performance of the three registration algorithms outlined in Section~
\backslash 
ref{sec:comparing-reg}. All the measures tested in the previous section were computed, but we show results for only the most sensitive model-based method. Figures~
\backslash 
ref{fig_sim}(a) and (c) show Specificity calculated using a shuffle radius of 2.1, for different values of $m$, the number of modes used to build the generative model. Figure~
\backslash 
ref{fig_sim}(b) shows generalised overlap using different weightings. The results shown in Figure~
\backslash 
ref{fig_sim}(a) suggest that the MDL groupwise approach gives the best registration result for the MGH Dataset, followed by Pairwise and Congealing in order of decreasing performance -- irrespective of the value of $m$.  Inspection of the error bars shows that these differences are statistically significant.  The results for Generalised Overlap, shown in Figure~
\backslash 
ref{fig_sim}(b), are more complicated, with the performance of the different NRR algorithms ordered differently for different weightings, though inspection of the error bars shows that many of the differences are not significant.  Overall, the same general pattern emerges as for Specificity, with the Groupwise method generally best (statistically significantly in two cases), but with no significant difference between Pairwise and Congealing in most cases.  The results for inverse volume weighting generally lack significance, but are inconsistent with those obtained using the other weighting schemes.  Volume weighting gives the best separation between the different variants, and places the three methods in the same order as Specificity. Overall, this supports the interpretation that Specificity give results that are generally equivalent to those obtained using Generalised Overlap, but with higher sensitivity. Finally, the Specificity results shown in Figure~
\backslash 
ref{fig_sim}(c) for the Dementia Dataset, place the three methods in the same order.
\layout Standard

\end_inset 


\layout Standard


\begin_inset Note
collapsed false

\layout Standard


\noun on 

\begin_inset LatexCommand \label{cha:Future-Work}

\end_inset 


\begin_inset LatexCommand \index{Future Work}

\end_inset 


\noun default 
Results of Model-based Objective Functions
\layout Section

Results of registration
\layout Section

Resulting models
\layout Section

Segmentation propagation (attempts)
\layout Section

Comparison with other OF's
\end_inset 


\layout Chapter
\pagebreak_top 
Extensions to 3-D
\layout Standard
\align right 

\size large 

\begin_inset Quotes eld
\end_inset 

I
\size small 
f you're not part of the solution, you're part of the precipitate.
\begin_inset Quotes erd
\end_inset 


\newline 
-- 
\emph on 
Henry J.
 Tillman.
\layout Standard


\begin_inset ERT
status Open

\layout Standard

\backslash 
lettrine{T}{ he}
\end_inset 

 model and NRR assessment methods were extended to operate on three-dimensional
 data.
 Rather than handling images, the methods then deal with volumes and, in
 accordance, shuffle distance neighbourhoods become a box or sphere of voxels,
 rather than a square or a disk.
\layout Standard

The chapter alludes to work which is performed at present.
 Thus, in this particular chapter, along with the subsequent chapter on
 future paths, planning and strategies are described rather than complete
 work.
\layout Section

Speed Limitations
\layout Standard

There are several tricks-of-the-trade, which can be used to speed up the
 process of registration assessment and model evaluation in 3-D.
 One strategy, for example, involves rescaling the data, then dealing with
 smaller versions of the whole, as shown in Figure 
\begin_inset LatexCommand \ref{cap:Multi-res}

\end_inset 

.
\layout Standard


\begin_inset Float figure
wide false
collapsed false

\layout Standard
\align center 

\begin_inset Graphics
	filename ./Graphics/pyramid.eps
	scale 70.00

\end_inset 


\layout Caption


\begin_inset LatexCommand \label{cap:Multi-res}

\end_inset 


\size small 
A multi-resolution approach illustrated in 2-D.
 Coarser representations are shown at the top levels and the original image
 lies at the bottom.
\end_inset 


\layout Standard

The basic concept is that, if the scale of the problem is reduced, it can
 be handled at a coarse level and then iteratively handled at finer level,
 until the original unscaled data is reached.
\layout Standard

Progressive refinement of the numerical results is a strategy which can
 also be used in 2-D.
 However, only when the scale of the problem rises to include a third dimension,
 
\emph on 
ad hoc 
\emph default 
solutions become a necessity.
 Clearly, results of an assessment experiment that operates on a reduced-size
 set will miss information that exists at the finer levels of granularity.
 Thus, only an approximation can ever be obtained.
\layout Section

Progressively-improved Estimates
\layout Standard

A strategy worth employing is one which offers a figure of merit that is
 gradually made more accurate.
 In cases where a benchmark is performed, conclusions can be reached early
 on.
 In the case where synthetic images are considered, this strategy is a possibili
ty even without scaling.
 The size of the synthetic set can be simply limited.
 However, an assessment method that is quicker to deliver an estimate is
 one which makes use of the entire set (whether coarse or not) rather than
 use just a subset that is subjected to bias.
\layout Standard

There different ways of reducing the complexity of the problem at hand.
 In practice, this means that a box of voxel may be sliced into 8 (
\begin_inset Formula $2^{3}$
\end_inset 

) equal-sized boxes which are then used in the analysis, or even more usefully,
 the box should be rescaled to become 8 times smaller, in terms of volume.
\layout Section

Selective Assessment of Slices
\layout Standard

In general, there is not much which distinguishes the method's use in 2-D
 and in 3-D, other than efficiency factors.
 However, several possibilities emerge owing to the fact that 3-D data can
 be interpreted differently once its dimensionality is reduced.
 For example, one can choose one representative slice from a larger volume
 and refine the evaluation by considering more slices, one at a time.
 This suffers from the fact that voxels whose position varies in the third
 dimension, i.e.
 it moves between the slices due to warping, will not be treated appropriately.
 All these issues, along with other pitfall, will be addressed in the future.
 
\layout Comment


\begin_inset Note
collapsed false

\layout Standard


\begin_inset Note
collapsed false

\layout Standard


\noun on 

\begin_inset LatexCommand \label{cha:Experiments}

\end_inset 


\begin_inset LatexCommand \index{Experimentation}

\end_inset 


\noun default 
Improving the Efficiency of Model-based Objective Functions
\end_inset 


\layout Standard

Subsets, work on shape, etc.
\layout Section


\begin_inset LatexCommand \label{sec:Overview}

\end_inset 

Identifying Shape Edges
\layout Section


\begin_inset LatexCommand \label{sec:Overview}

\end_inset 

Taboo search?
\layout Section


\begin_inset LatexCommand \label{sec:Overview}

\end_inset 

Improving MDL-based Shape Optimisation
\layout Subsection

Subsets
\layout Comment

Use the previous structure and check the initial number of pages.
 Reconsider the need to have table of figures ad table of whatever else.
 Also, acknowledgements might only be suitable for a thesis.
\layout Comment

Verify with Chris what an acceptable length is for this report and do not
 waste excess time on a report whose results are not likely to appear in
 the thesis.
 Some of the better experiments and the introduction, however, can be re-used
 when writing the thesis.
\layout Comment

The sections that need the most changing are to do with the scheduling of
 next year's activities
\layout Comment

This chapter used to be called
\noun on 
 Experiments and Results
\layout Comment

---
\layout Comment

---
\layout Standard


\begin_inset ERT
status Open

\layout Standard

\backslash 
lettrine{T}{ roughout}
\end_inset 

 the past year, many results have been obtained and better understanding
 established.
 Some of these are more relevant to the preliminary research aims (see Form
 2) than others.
 Although experiments were applied to 1-D data, principles that extend to
 a higher-dimensional data were learned and should form the theoretical
 grounds for future work concerning the model-based objective function.
 It has been agreed that shortly into the second year of this research,
 once sufficient understanding of the problem and confidence are gained,
 2-D (and possibly later on, 3-D) application of the method will be investigated
\begin_inset Foot
collapsed false

\layout Standard

Issues which yet cannot be ignored are related to efficiency.
 By scaling down the problem though, proof of method appropriateness is
 both possible and traceable.
\end_inset 

.
\layout Standard

Indication of prescribed tasks and some intermediate submissions of progress
 up-to-date can be found in the forms.
 They are available online
\begin_inset Foot
collapsed false

\layout Standard

The author is aware that Web references and expansions through remote text
 are frowned upon.
 However, these are collectively an 'open door' to the large majority of
 work (some 2,000+ files); much of it is completely omitted from this report.
\end_inset 

 \SpecialChar ~
as Portable Document Format (PDF) and Word files at:
\layout Itemize


\begin_inset LatexCommand \htmlurl{http://www.danielsorogon.com/Webmaster/Research/Progress/forms.htm}

\end_inset 


\layout Standard

All weekly progress reports can be found under:
\layout Itemize


\begin_inset LatexCommand \htmlurl{http://www.danielsorogon.com/Webmaster/Research/Progress/}

\end_inset 


\layout Standard

There are clear advantages to the retaining of the records above.
 These will later allow chronological dissection of progress made, as well
 as the problems encountered on a day-to-day or week-to-week basis.
 They are yet not adhesive enough and this chapter attempts to provide a
 short summary of the large bulk of experiments by just listing some of
 the more important ones and explaining how they serve the raison d'tre
 of the project.
 All experiments are documented to their finest detail at:
\layout Itemize


\begin_inset LatexCommand \htmlurl{http://www2.cs.man.ac.uk/~schestr0/Experiments/}

\end_inset 


\layout Standard

They were generated using AART which is a newly-constructed tool that is
 shown in Figure 
\begin_inset LatexCommand \vref{cap:Autonomous-Appearance-based-Registration}

\end_inset 

 and explained in Section 
\begin_inset LatexCommand \vref{sec:Environment}

\end_inset 

.
\layout Standard

All results were obtained under MATLAB [WWW-1] which is the working environment
 on which AART operates
\begin_inset Foot
collapsed false

\layout Standard

On a separate note on knowledge- and code-sharing, GUI components and demos
 were made available at MATLAB Central.
 They received nearly 4,000 downloads, accredited to the author and his
 affiliation with ISBE and Manchester University.
 These contributions ranked him amongst the world's top 5 for popularity
 in July 2004.
 Confer [WWW-17] for more information.
\end_inset 

.
\layout Section


\begin_inset LatexCommand \label{sec:Experiments-and-Milestones}

\end_inset 

Milestones 
\layout Comment

Put some experiments here.
\layout Comment

used to say 'in Brief'
\layout Comment

Used to be called Experiments and Milestones 
\layout Standard

From the large pool of experiments which were performed, the next few sections,
 which include much of the 'meat' of this report, select and focus on a
 few which inferred important information and conclusions that ought to
 be highlighted.
\layout Standard

The following experiments can be seen more or less as milestones.
 These are the catalysts for the more interesting and/or perplexing results
 which could be identified amongst the entire set of experiments.
 Each of these will be explicitly or implicitly mentioned later on as minor
 milestones are dealt with roughly chronologically in Section 
\begin_inset LatexCommand \ref{sec:Experiments}

\end_inset 

 (page 
\begin_inset LatexCommand \pageref{sec:Experiments}

\end_inset 

), Section 
\begin_inset LatexCommand \ref{sec:Shapes-Revisited}

\end_inset 

 (page 
\begin_inset LatexCommand \pageref{sec:Shapes-Revisited}

\end_inset 

) and Section 
\begin_inset LatexCommand \vref{sec:Present-Work}

\end_inset 

.
\layout Standard

The milestone are:
\layout Enumerate

Registration target and approach of the model-based evaluation to it.
\layout Enumerate

Comparison and benchmark of different registration methods.
\layout Enumerate

Finding the correlation between the size of the set and the performance
 of the model-based objective function.
\layout Enumerate

Point insertion to compensate for the change in bump height.
\layout Enumerate

Use of the residual of the model to better perform (4).
\layout Enumerate

The optimisation refusing to improve steadily, fixed by dynamically changing
 the precision required from the optimiser.
\layout Enumerate

Finding out that optimisation can go below target even when initialised
 at the correct solution described by a piece-wise linear warp.
\layout Enumerate

Considerable speed-up of the algorithm.
\layout Section

Environment
\begin_inset LatexCommand \label{sec:Environment}

\end_inset 


\layout Standard

From the point when the project commenced, a tool was needed to conduct
 experiments in a systematic manner -- namely a flexible work environment
 for experimental studies.
 The problem which needed to solve was that of simple data registration
 so one dimensional data needed to be generated and then analysed in sensible
 ways, before, throughout and after registration.
\layout Standard

The high-level procedural language MATLAB was used to develop a package
 that can be rapidly modified and tested.
 On top of this package, a graphical user interface was laid
\begin_inset Foot
collapsed false

\layout Standard

The user interface is courtesy of Java and it runs over a Java virtual machine
 (this can be seen as either having pros or cons).
 
\end_inset 

 \SpecialChar ~
and results were displayed in the form of hyper-text.
 As development of this package progressed, it was decided to name it Autonomous
 Appearance-based Registration Test-bed (AART).
 As the name implies, this is primarily a flexible environment in which
 registration tasks can be performed.
 Of particular interest it was registration which is based on appearance
 of images.
 This appearance can be described by the means of a model and the process
 of registration is intended to be free of user intervention, hence it is
 autonomous.
\layout Standard


\begin_inset Float figure
placement H
wide false
collapsed false

\layout Standard
\align center 

\begin_inset Graphics
	filename ./Graphics/AART0.5.22.eps
	scale 40.00

\end_inset 


\layout Caption


\begin_inset LatexCommand \label{cap:Autonomous-Appearance-based-Registration}

\end_inset 


\size small 
Autonomous Appearance-based Registration Test-bed in February 2004.
\end_inset 


\layout Standard

As it presently stands, AART is a stable tool that has a great number of
 run-time options.
 By setting these options, new experiments can be quickly conducted and
 results returned in visual form as well as in rich textual form.
 
\layout Section


\begin_inset LatexCommand \label{sec:Experiments}

\end_inset 

Registration
\layout Comment

July 4th: rearrange images below
\layout Comment

Old name to section: Experiments and Results in Detail
\layout Standard

This large section will provide explanation on work, experiments and some
 results pertaining to the main project goal.
 Most of these results are described in graphics and text and, at this stage,
 no registration video sequences are enclosed
\begin_inset Foot
collapsed false

\layout Standard

It seems likely that a CD-ROM will accompany later surveys (a la thesis).
 AART can generate several movie types with little user involvement.
\end_inset 

.
\layout Subsection

Initial Exploration
\layout Standard

Experiments below will not be sorted purely chronologically and will not
 be listed according to streams of consciousness either.
 They will rather be explained in a logical way which builds coherently
 towards the inference of conclusions and the way in which experiments aided
 the understanding which was so necessary.
 A brief and incomplete list of milestones was included in the earlier part
 of this chapter and although this list is not expected to be complete in
 any sense, it should be able to cover much of the more important experiments
 in sufficient detail for them to be truly understood.
\layout Subsubsection


\begin_inset LatexCommand \label{sub:Generation-of-Data}

\end_inset 

Generation of Data
\layout Standard

It has been implicitly mentioned that presently only 1-D data is practically
 under consideration.
 In order to keep results consistent, much of the time was spent investigating
 a particular class of data -- that which shall be referred to as the bump
\begin_inset Foot
collapsed false

\layout Standard

This is rather a different type of data than the one mentioned in past work
 (Appendix 
\begin_inset LatexCommand \ref{cha:Appendix-BProject-Descrition}

\end_inset 

 where bumps are less composite) and that which has been tested in MDL shape
 optimisation (Chapter 
\begin_inset LatexCommand \ref{cha:MDL Models}

\end_inset 

 where brick topped by a bump is looked at).
\end_inset 

.
 The bump (a half-circle or ellipse) which was being generated varied in
 3 separate ways:
\layout Enumerate

Position
\layout Enumerate

Height
\layout Enumerate

Width
\layout Standard


\begin_inset Float figure
placement H
wide false
collapsed false

\layout Standard
\align center 

\begin_inset Graphics
	filename ./Graphics/bump.eps
	scale 70.00

\end_inset 


\layout Caption


\begin_inset LatexCommand \label{cap:modes}

\end_inset 


\size small 
Illustration of the three variation modes.
\end_inset 


\layout Standard

Dealing with each of the above variation types in turn, position refers
 to the horizontal placement of the bump, height refers to the peak value
 (judged by its Y-component) and width refers to a relative width for the
 bump (see Figure 
\begin_inset LatexCommand \ref{cap:modes}

\end_inset 

).
 Later figures clarify what is meant by these properties visually.
 This synthetic data type was chosen due to few interesting and important
 attributes it possesses.
 It proves to be a difficult problem when treated as raw input for registration,
 but more importantly, it is in fact possible to know what one means by
 a 
\emph on 
correct
\emph default 
 answer to the problem.
 That correct solution is also feasible to identify
\begin_inset Foot
collapsed false

\layout Standard

In real-life circumstances, there will rarely be a correct solution for
 inter-subject registration.
 There may, however, be one for intra-subject registration, e.g.
 in the case of correction for movement.
\end_inset 

.
 As the notion of models is used here persistently, one could expect the
 modes of variation found to reflect on the three pre-defined modes being
 position, height and width.
\layout Standard


\begin_inset Note
collapsed false

\layout Standard

Consider making these unnumbered section.
 Same with future experiments.
 They look bad in TOC
\end_inset 


\layout Standard

Figure 
\begin_inset LatexCommand \ref{cap:Data-being-registered.}

\end_inset 

 shows what the vector representation of the data actually means.
\layout Standard


\begin_inset Float figure
wide false
collapsed false

\layout Standard
\align center 

\begin_inset Graphics
	filename ./Graphics/image_vectors.eps
	scale 70.00

\end_inset 


\layout Caption


\begin_inset LatexCommand \label{cap:Data-being-registered.}

\end_inset 


\size small 
Data being registered.
 The registration process is visualised by an image composed of data vectors.
 The columns are 1-D vectors interpreted as grey-scale pixels.
\end_inset 


\layout Standard

Figure 
\begin_inset LatexCommand \ref{cap:Original-data-set}

\end_inset 

 shows the data in another more fascinating way which can dynamically illustrate
 the change due to registration.
 This representation has been used to form registration videos and it will
 be definitely returned to in future experimentation.
\layout Standard
\align center 

\begin_inset Float figure
placement H
wide false
collapsed false

\layout Standard
\align center 

\begin_inset Graphics
	filename ./Graphics/test_on_target_7-4.eps
	scale 30.00

\end_inset 


\layout Caption


\begin_inset LatexCommand \label{cap:Original-data-set}

\end_inset 


\size small 
Original data set of size 5 before any application of warps.
\end_inset 


\layout Standard

Later in this section, it will be shown what effect warps have on this data.
 Moreover, it is important to mention that the algorithm was applied to
 different synthetic data types although this was rare.
 Comparison is better performed over the same standardised dataset.
 Other data was usually used for reasoning about the correctness of algorithms
 and error detection via more trackable debugging tasks.
 
\layout Standard
\align center 

\begin_inset Float figure
wide false
collapsed false

\layout Standard
\align center 

\begin_inset Graphics
	filename ./Graphics/pixels.eps
	scale 60.00

\end_inset 


\layout Caption


\begin_inset LatexCommand \label{cap:A-larger-example}

\end_inset 


\size small 
A larger example of pixel representation for 1-D bump data.
 This is somewhat of an enhancement to Figure 
\begin_inset LatexCommand \vref{cap:Data-being-registered.}

\end_inset 

.
\end_inset 


\layout Subsubsection

Analysis of Warps
\layout Standard

Throughout the entire year, there was some general interest in how clamped-plate
 splines affect the data and how the model-based objective function affects
 the choice of warps.
 Several of the drawbacks of various families of warps and the problems
 concerned with diffeomorphism were identified, yet these were of greater
 interest to Marsland and Twining who posses knowledge of the more theoretical
 grounds.
 In Figure 
\begin_inset LatexCommand \ref{cap:Warps-shown-as}

\end_inset 

 lies a representation of a warp -- that is -- a reparameterisation curve
 that maps one point coordinate to another (and being a strict one-to-one
 mapping, it is a 
\emph on 
bijection
\emph default 
 as well).
 The idea was explained in some detail in 
\begin_inset LatexCommand \vref{sub:Reparameterisation}

\end_inset 

.
\layout Standard
\align center 

\begin_inset Float figure
placement H
wide false
collapsed false

\layout Standard
\align center 

\begin_inset Graphics
	filename ./Graphics/msd_curves.ps
	scale 30.00

\end_inset 


\layout Caption


\begin_inset LatexCommand \label{cap:Warps-shown-as}

\end_inset 


\size small 
Warps shown as the MSD objective function runs.
 Each row shows the reparameterisation which is applied to one of the 5
 images in the same row.
\end_inset 


\layout Standard

It should be noted that one data instance remains unchanged.
 That is in fact the reference which avoids the data from drifting away
 interminably.
 The left-hand side corresponds to the former iterations, the right-hand
 side -- to the latter ones.
\layout Standard

It was, at the earlier stages of this investigative study, vital to ensure
 that no cases of tearing and folding issues could arise.
 It turned out that one certain type of warp was problematic.
 A warp which was in essence made of a composition of knot-points (or control
 points in a more orthodox terminology for functions), also known as the
 multi-point warps, could produce unwanted effects and usage of that warp
 immediately ceased.
 Instead, a simpler single-point
\begin_inset Foot
collapsed false

\layout Standard

This refers to the number of knot-points that are involved in the calculation
 of the transformation.
 A single point fully describes the Green's function which CPS builds upon.
\end_inset 

 warp has been used since, while the other was permanently conceded.
\layout Comment

Show some warps, correct warps, current warps
\layout Comment

....
\layout Subsubsection


\begin_inset LatexCommand \label{sub:Generation-of-Data}

\end_inset 

Base-line Models
\layout Standard

As a starting point for model construction and understanding, 10 regular
 data instances, which have been used in many of the experiments in up-coming
 sections, were generated and their statistical models built.
\layout Standard


\begin_inset Note
collapsed false

\layout Standard

More here and in between figures
\end_inset 


\layout Standard


\begin_inset Float figure
placement H
wide false
collapsed false

\layout Standard
\align center 

\begin_inset Graphics
	filename ./Graphics/shape_model_10.eps
	scale 65.00

\end_inset 


\layout Caption


\begin_inset LatexCommand \label{cap:Shape-model-of}

\end_inset 

Shape model of 10 data instances at the start.
 The four principal modes are shown with up to 
\begin_inset Formula $\pm2$
\end_inset 

 standard deviations away from the mean.
 
\end_inset 


\layout Standard

It can be seen in Figure 
\begin_inset LatexCommand \ref{cap:Shape-model-of}

\end_inset 

 that shape is rather stable.
 This is because under these specific experiments, it was mainly (if not
 only) intensity that was used to create an appearance model
\begin_inset Foot
collapsed false

\layout Standard

The fact that shape component was chosen to be the reparameterisation curve
 has not been enlightened yet.
\end_inset 

 \SpecialChar ~
(more on this on page 
\begin_inset LatexCommand \pageref{sub:Varying-Weights}

\end_inset 

 in this very same chapter).
\layout Standard


\begin_inset Float figure
placement H
wide false
collapsed false

\layout Standard
\align center 

\begin_inset Graphics
	filename ./Graphics/intensity_model_10.eps
	scale 50.00

\end_inset 


\layout Caption


\begin_inset LatexCommand \label{cap:Intensity-model-of}

\end_inset 


\size small 
Intensity model of 10 data instances at the start.
 The two principal modes are shown with up to 
\begin_inset Formula $\pm2$
\end_inset 

 standard deviations away from the mean.
 
\end_inset 


\layout Standard

Intensity models show some of the effects of height being changed, width
 varying and bump position moving from left to right.
 However, it is all rather fuzzy and the variation modes combine in a mysterious
 way.
 This is in fact why real correspondences need to be learned.
\layout Standard


\begin_inset Float figure
placement H
wide false
collapsed false

\layout Standard
\align center 

\begin_inset Graphics
	filename ./Graphics/combined_model_10.eps
	scale 50.00

\end_inset 


\layout Caption


\begin_inset LatexCommand \label{cap:Combined-(shape-and}

\end_inset 


\size small 
Combined (shape and intensity) model of 10 data instances at the start.
 The two principal modes are shown with up to
\begin_inset Formula $\pm2$
\end_inset 

 standard deviations away from the mean.
 
\end_inset 


\layout Standard

The figure above shows the combination of intensity and shape.
 It is not yet too clear how to analyse it, but it resembles the intensity
 model which is the greater component that the combined model accounts for.
 Shape was quite static so it is expected to be merely invisible in the
 figure above.
\layout Subsubsection

Similarity Measures
\layout Standard

Figure 
\begin_inset LatexCommand \ref{cap:Mean-MSD-measures}

\end_inset 

 shows one of the more useful measures for the model-based objective function.
 The MSD measure shows that the images become mutually similar as the model-base
d objective function proceeds, i.e.
 as the model of the data is minimised in its complexity.
 This confirms that a move is made in the right direction.
\layout Standard
\align center 

\begin_inset Float figure
placement H
wide false
collapsed false

\layout Standard
\align center 

\begin_inset Graphics
	filename ./Graphics/mean_msd_graph-1.eps
	scale 35.00

\end_inset 


\layout Caption


\begin_inset LatexCommand \label{cap:Mean-MSD-measures}

\end_inset 


\size small 
Mean MSD measures at each point during the model-based registration of 10
 data instances.
\end_inset 


\layout Standard

Before investigating some of the different (and almost distinct) registration
 methods, it was worth looking at some measures and the way that these were
 affected as registration took place.
 Figure 
\begin_inset LatexCommand \ref{cap:2-D-Synthetic-data}

\end_inset 

 shows the measures of MSD and MI for a group of 2-D synthetic data
\begin_inset Foot
collapsed false

\layout Standard

The data was generated by extending the 1-D bump data generator.
 It is 
\emph on 
not
\emph default 
 a Gaussian.
\end_inset 

.
 The large image shown in the figures is the reference image and the bottom
 plots show the measures for each of the 4 other images respectively.
\layout Standard
\align center 

\begin_inset Float figure
placement H
wide false
collapsed false

\layout Standard
\align center 

\begin_inset Graphics
	filename ./Graphics/2d_eval_similarity_4.ps
	display none
	scale 35.00

\end_inset 


\layout Caption


\begin_inset LatexCommand \label{cap:2-D-Synthetic-data}

\end_inset 


\size small 
2-D Synthetic data generated and evaluated for similarity against the reference.
\end_inset 


\layout Subsubsection

Generalisation and Specificity
\layout Standard

In the midst of experimentation, peculiar results were found when measurements
 of generalisation ability and specificity had been taken.
 The following is an extensive survey of these.
\layout Standard

Specificity generates a number of random examples from the model and measures
 their distance with respect to the original set.
 Hence, it can be thought of as a measure of compactness.
 As the error bars in Figure 
\begin_inset LatexCommand \ref{cap:Specificity-of-model-based}

\end_inset 

 suggest, there is an improvement in the spread of these values (they spread
 shrinks in size) when the model-based objective function is employed, whereas
 it is not clear how the specificity rises when an MSD-minimising objective
 function is used.
\layout Standard


\begin_inset Note
collapsed false

\layout Standard

TODO: Remove figures.
\end_inset 


\layout Standard
\align center 

\begin_inset Float figure
placement H
wide false
collapsed false

\layout Standard
\align center 

\begin_inset Graphics
	filename ./Graphics/msd_spec_big_test-1.eps
	scale 17.00

\end_inset 


\layout Caption


\begin_inset LatexCommand \label{cap:Specificity-rising-when}

\end_inset 


\size small 
Specificity rising when MSD-based registration is performed.
\end_inset 

 
\begin_inset Float figure
placement H
wide false
collapsed false

\layout Standard
\align center 

\begin_inset Graphics
	filename ./Graphics/spec_bar_model.ps
	scale 17.00

\end_inset 


\layout Caption


\begin_inset LatexCommand \label{cap:Specificity-of-model-based}

\end_inset 


\size small 
Specificity of model-based objective function.
\end_inset 


\layout Standard

Regarding the generalisability, there never appears to be a radical change
 in their range of values or mean values when the model-based objective
 function is applied.
 Likewise was the case for all other objective functions (e.g.
 Figure 
\begin_inset LatexCommand \ref{cap:Generalisation-ability-of-MSD}

\end_inset 

) so it appears as if it can be discarded as a measure of improvement.
 Only Figure 
\begin_inset LatexCommand \ref{cap:For-MSD,-generalisation}

\end_inset 

 suggests that generalisability measures are of some use.
 However, generalisability measure very slowly changes.
\layout Standard
\align center 

\begin_inset Float figure
placement H
wide false
collapsed false

\layout Standard
\align center 

\begin_inset Graphics
	filename ./Graphics/gen_bar_model.ps
	scale 20.00

\end_inset 


\layout Caption


\begin_inset LatexCommand \label{cap:Generalisation-ability-of}

\end_inset 


\size small 
Generalisation ability of model-based objective function.
\end_inset 


\layout Standard
\align center 

\begin_inset Float figure
placement H
wide false
collapsed false

\layout Standard
\align center 

\begin_inset Graphics
	filename ./Graphics/spec_model_10_10.ps
	scale 20.00

\end_inset 


\layout Caption


\begin_inset LatexCommand \label{cap:Specificity-of-the}

\end_inset 


\size small 
Specificity of the model-based objective function as registration proceeds.
\end_inset 


\layout Standard

A curious observation is that the model-based objective function may have
 its value decreasing at the start, yet no apparent improvement can be seen
 in the form of specificity.
 Figure 
\begin_inset LatexCommand \ref{cap:Specificity-of-the}

\end_inset 

 shows the steady value of specificity during the first 100 iterations of
 this model-driven algorithm.
 The model improves, but specificity does not.
 A similar story is said by generalisability (see Figure 
\begin_inset LatexCommand \ref{cap:Generalisation-ability-of}

\end_inset 

), but given the explanation above, it is not at all an unpredictable result.
\layout Standard

More figures on generalisation ability are included for the realisation
 that it is a poor measure in the case of model-based registration.
 it should therefore not be pursued much further unless the algorithms alter.
\layout Standard
\align center 

\begin_inset Float figure
placement H
wide false
collapsed false

\layout Standard
\align center 

\begin_inset Graphics
	filename ./Graphics/gen_model_10_10.ps
	scale 20.00

\end_inset 


\layout Caption


\begin_inset LatexCommand \label{cap:Generalisation-ability-of}

\end_inset 


\size small 
Generalisation ability of the model-based objective function as registration
 proceeds.
\end_inset 


\layout Standard
\align center 

\begin_inset Float figure
placement H
wide false
collapsed false

\layout Standard
\align center 

\begin_inset Graphics
	filename ./Graphics/spec_msd_10_10.ps
	scale 20.00

\end_inset 


\layout Caption


\begin_inset LatexCommand \label{cap:Specificity-of-the}

\end_inset 


\size small 
Specificity of the MSD objective function as registration proceeds.
\end_inset 


\layout Standard
\align center 

\begin_inset Float figure
placement H
wide false
collapsed false

\layout Standard
\align center 

\begin_inset Graphics
	filename ./Graphics/gen_msd_10_10.ps
	scale 25.00

\end_inset 


\layout Caption


\begin_inset LatexCommand \label{cap:Generalisation-ability-of-MSD}

\end_inset 


\size small 
Generalisation ability of the MSD objective function as registration proceeds.
\end_inset 


\layout Standard
\align center 

\begin_inset Float figure
placement H
wide false
collapsed false

\layout Standard
\align center 

\begin_inset Graphics
	filename ./Graphics/spec_graph-1.eps
	scale 25.00

\end_inset 


\layout Caption


\begin_inset LatexCommand \label{cap:Specificity-shown-to}

\end_inset 


\size small 
Specificity shown to be less erratic as the algorithm proceeds with registration.
\end_inset 


\layout Standard
\align center 

\begin_inset Float figure
placement H
wide false
collapsed false

\layout Standard
\align center 

\begin_inset Graphics
	filename ./Graphics/@Gen-MSD-1.eps
	scale 25.00

\end_inset 


\layout Caption


\begin_inset LatexCommand \label{cap:For-MSD,-generalisation}

\end_inset 


\size small 
For MSD, generalisation slowly declines as shown for 2,000 iteration.
 Measurements are made every 100 iterations.
\end_inset 


\layout Standard


\begin_inset Float figure
placement H
wide false
collapsed false

\layout Standard
\align center 

\begin_inset Graphics
	filename ./Graphics/@specificity-1.eps
	scale 25.00

\end_inset 


\layout Caption


\begin_inset LatexCommand \label{cap:Specificity-is-merely}

\end_inset 


\size small 
Specificity is 
\size default 
merely unchan
\size small 
ged as registration proceeds, unlike what is expected.
 It can be seen however, that there is a decline at the start where changes
 to the data are most radical.
\end_inset 


\layout Standard


\begin_inset Float figure
placement H
wide false
collapsed false

\layout Standard
\align center 

\begin_inset Graphics
	filename ./Graphics/@Generalisability-1.eps
	scale 25.00

\end_inset 


\layout Caption


\begin_inset LatexCommand \label{cap:Generalisation-ability-measured}

\end_inset 


\size small 
Generalisation ability measured every 100 warps.
 A total number of 10,000 iterations shows no substantial change to values
 while registration is performed.
\end_inset 


\layout Subsection
\pagebreak_top 
Different Registration Approaches
\layout Standard

The entire progress of this research began with some analysis and experimentatio
n involving various registration schemes in a single dimension.
 These were quite nave implementations
\begin_inset Foot
collapsed false

\layout Standard

More cunning implementations would have involved better 'dialogue' between
 the similarity measures and the warps chosen, for example.
\newline 
Rather than that, each of the two components was treated as a black box,
 fully independent from the other.
\end_inset 

 and MSD performed conspicuously well to result in the best ultimate similarity,
 whereas other methods barely had any positive effect.
\layout Standard

One objective function that would of course be of significant interest was
 that which is based on models.
 As anticipated, its improvements were made smaller and smaller as time
 progressed and for several months it failed to reach a good solution (depicted
 by intermittent red in the figure below).
\layout Standard


\begin_inset Float figure
placement H
wide false
collapsed false

\layout Standard
\align center 

\begin_inset Graphics
	filename ./Graphics/multi_warp_20_zero_constant-2.eps
	scale 30.00

\end_inset 


\layout Caption


\begin_inset LatexCommand \label{cap:Multiple-knot-point-warps}

\end_inset 


\size small 
Multiple knot-point warps show that the curve is exponential when a model-based
 objective function is employed.
\end_inset 


\layout Comment

ADD MANY FIGURES TO THESE SUBSECTIONS
\layout Subsubsection

Model-based Objective Function
\layout Standard

A valid prototype for this registration method was already in place at the
 start.
 The way this function operates has been explained in earlier parts of the
 report.
 Figure 
\begin_inset LatexCommand \ref{cap:Various-measures-shown}

\end_inset 

 shows how measures of MSD, Generalisation ability and specificity change
 at each function evaluation step.
 The changes are expressed per cent with respect to the evaluation taken
 for the previous iteration.
 It appears rather noisy and reflects on the bad forms of this function
 before it was revised.
 As most lines remain flat, it is shown that values go in no particular
 direction
\begin_inset Foot
collapsed false

\layout Standard

This idea is borrowed from technical analysis in finance.
 It can be useful in science as well.
\end_inset 

.
\layout Standard
\align center 

\begin_inset Float figure
placement H
wide false
collapsed false

\layout Standard
\align center 

\begin_inset Graphics
	filename ./Graphics/model_mixed_scoring_10_10.ps
	scale 35.00

\end_inset 


\layout Caption


\begin_inset LatexCommand \label{cap:Various-measures-shown}

\end_inset 


\size small 
Various measures shown as the old model-based algorithm proceeds.
\end_inset 


\layout Standard

Due to this poor performance, rigorous work began to obliterate known issues
 and weaknesses, resulting in an improved model-based objective function.
\layout Subsubsection

Improved Model-based Objective Function
\layout Comment

show 3-D surface here
\layout Comment

STILL TO BE ADDED (the picture
\layout Standard

As already adumbrated in the text
\begin_inset Note
collapsed false

\layout Standard

in aforementioned statements
\end_inset 

, towards the end of April 2004, many solutions were found which substantially
 improved the objective function and finally made it work.
 Further options also made it work relatively efficiently and obtain impressive
 results.
 Details on the changes which were applied will be explained later in this
 section.
\layout Standard

Figure 
\begin_inset LatexCommand \ref{cap:Data-being-visualised}

\end_inset 

 below illustrates how registration practically operates upon the data.
 It can be observed that, in this case, while the model-based objective
 function guides transformation, data bumps align increasingly better.
 Therefore, good registration is finally achieved, driven purely by model
 complexity.
\layout Standard


\begin_inset Float figure
placement H
wide false
collapsed false

\layout Standard
\align center 

\begin_inset Graphics
	filename ./Graphics/msd_gen_5_5-2.eps
	scale 27.00

\end_inset 


\layout Caption


\begin_inset LatexCommand \label{cap:Data-being-visualised}

\end_inset 


\size small 
Data being visualised by AART.
 In this case, 5 bumps are shown at some arbitrary state during registration.
\end_inset 


\layout Standard

See this with reference to a previous figure that was shown on page 
\begin_inset LatexCommand \pageref{cap:Original-data-set}

\end_inset 

.
 The model-based algorithm itself will be explained in Section 
\begin_inset LatexCommand \ref{cha:Reg_Algorithm}

\end_inset 

.
\layout Subsubsection

Emergence of New Methods
\layout Standard

New methods and extensions of existing ones soon began to emerge.
 As part of an evaluation of many techniques, with the aim of justifying
 the use of model-based functions, new ones were created with some logical
 backing.
 The majority of these are detailed below.
\layout Itemize


\series bold 
Pair-wise model based
\series default 
:
\layout Quote

There have been several attempts to properly register data by creating models
 of the reference and each image in the set in turn.
 This is an interesting idea to look at because, in principle, models can
 be proven to be good pair-wise measures as well.
\layout Standard


\begin_inset Note
collapsed false

\layout Standard

Below is from MICCAI merged with some notes
\end_inset 


\layout Itemize


\series bold 
Probability Density Function (PDF):
\layout Quote
\pagebreak_bottom 
Such functions describe the volume of data distributions.
 More uniform data, as one aspires to achieve across all images during registrat
ion, will result in lower such values.
 An exponential PDF was used in the experiments by default although over
 a dozen others are available in AART, including a Gaussian one.
 In line with Cootes' implementation for the ECCV 2004 paper 
\begin_inset LatexCommand \cite{Cootes_reg}

\end_inset 

, this PDF-based function was created and used amongst the different objective
 functions under evaluation.
\layout Itemize


\series bold 
Wavelets:
\layout Quote

A personal suggestion was to use wavelets 
\begin_inset LatexCommand \cite{rabbani_jpeg}

\end_inset 

 as indicator of data complexity.
 It was inspired by Twining's mentioning of Fourier transforms.
 As compression is closely related to MDL, these can provide an accurate
 estimate of the complexity of data and abundance of patterns within that
 data.
 An extensive group of different wavelets are offered by the application
 and, by default, Daubechy was used in the experiments.
 Computationally cheaper alternatives to the wavelets are Fourier and Hough
 transforms, but these have not yet been incorporated into AART.
 All wavelet implementations were supplied by the MATLAB Wavelet Toolbox.
\layout Itemize


\series bold 
Mutual Information:
\layout Quote

This strand of methods 
\begin_inset LatexCommand \cite{Viola,Studholme_nmi}

\end_inset 

 will analyse the peaks of image histograms.
 Normalised MI is currently one of the most robust and widely-used methods
 for 2-D data.
\layout Itemize


\series bold 
Hybrid Objective Functions:
\layout Quote

Much earlier in the year, a combination of objective functions was investigated,
 mainly that of MSD and model-based.
 One such hybrid method performed an MSD-driven routine, followed by a model-bas
ed one.
 Under such approach, it is assumed that the model-based objective function
 is well-behaved near convergence.
 Other schemes combined and altered between MSD- and a model-based objective
 function every fixed number of iterations (the algorithms were operated
 in alternating cycles).
\layout Subsection

Comparisons and Benchmarks
\layout Subsubsection

A Comparative Analysis
\layout Standard

As Form 2 (page 
\begin_inset LatexCommand \pageref{sec:Form-2}

\end_inset 

) indicates, a quantitative analysis of different methods was needed to
 infer something about their behaviours.
 See Figure  
\begin_inset LatexCommand \vref{cap:A-comparative-analysis}

\end_inset 

.
\layout Subsubsection

Comparative Analysis of Objective Functions
\layout Standard

In late 2003 and in early 2004, a comparative analysis of different registration
 methods was conducted.
 Some results are shown in Figure 
\begin_inset LatexCommand \ref{cap:A-comparative-analysis}

\end_inset 

.
\layout Standard


\begin_inset Float figure
placement H
wide false
collapsed false

\layout Standard
\align center 

\begin_inset Graphics
	filename ./Graphics/overlaid.ps
	display none
	scale 70.00

\end_inset 


\layout Caption


\begin_inset LatexCommand \label{cap:A-comparative-analysis}

\end_inset 


\size small 
A comparative analysis of different objective functions.
 It illustrates that the model complexity decreases only for the newly-proposed
 objective functions.
 The Y-Axis value is an indicator of model compactness.
\end_inset 


\layout Standard

One of the primary aims was to benchmark different registration methods
 and come up with comparative results which highlight the up- and down-sides
 of each method.
 There had been a particular interest in the underlying behaviour of each
 method and the quality of registration as evaluated by a model of appearance.
\layout Standard

Months later it was discovered that the registration method which had later
 been proposed had the potential of becoming much more successful.
 Up to a certain point in time, functions used for registration were simply
 unable to get decent results.
 It was revealed that the transformations applied were restricted to remain
 small in extent.
 The problem was resolved by changing this restriction term, whereupon larger,
 more radical transformation were permissibly applied and a good solution
 was shortly approached.
 The issue of speed (or efficiency) remained a worrying factor.
 It had to be addressed in order to make the registration method more practical
 in 2-D (and potentially an even greater number of dimensions).
\layout Standard


\begin_inset Note
collapsed false

\layout Standard

(the one from MICCAI, maybe above)
\end_inset 


\layout Subsubsection

Comparison Quantitatively
\layout Standard

A comparison between most of the methods was conducted and the conditions
 were set to be impartial and well-scaled so that they evaluate a proper
 registration process.
 
\layout Comment

by orders of magnitude higher than other approached.
 However, 
\layout Comment

===
\layout Comment

It can (HOPEFULLY) be seen that the results are better in the sense that
 they lead to a model with less variation, as studied by the principal component
 analysis
\layout Comment

===.
\layout Comment

more accurate and the joining of all images produces a less blurry image.
 
\layout Comment

===
\layout Comment

Say that 
\layout Comment

===
\layout Comment

excellent in 1-D
\layout Comment

===
\layout Comment

The task is hard in 1-D because of the great variation, yet it works.
 (emphasise it is 1-D data!!)
\layout Comment

Easily apply in 2 and 3-D biomedical data, but will be slower.
 
\layout Comment

===
\layout Comment

we have tested in 1-D
\layout Standard

For the results in Table 
\begin_inset LatexCommand \ref{cap:Comparison-of-objective}

\end_inset 

, the number of iterations was set to 50.
 By another terminology
\begin_inset Foot
collapsed false

\layout Standard

In AART, this definition of iteration is repeatedly referred to as 
\emph on 
warping step/s
\emph default 
.
\end_inset 

, this equates to 1000 as each of the twenty data instances was subjected
 to up to 50 transformations.
 For single-point transformations, the placement of the control point was
 random (both in location and magnitude) and for multi-point transformations
 the positioning of points was made random to abstain from data-bias or
 advantageous 
\emph on 
a priori
\emph default 
 knowledge.
 The number of data instances was kept high at 20 in order to allow a substantia
l 
\emph on 
group-wise
\emph default 
 optimisation to be investigated.
 Objective functions based on mutual information remained flat simply due
 to the continuity of the data and the fact that it is one-dimensional.
 The table below shows the different values of 
\begin_inset Formula ${\displaystyle log\prod}\lambda$
\end_inset 

.
\layout Standard


\begin_inset Formula $\lambda$
\end_inset 

 are the Eigen-values derived from the covariance matrix of the appearance
 model which had been constructed from all 20 data instances
\begin_inset Foot
collapsed false

\layout Standard

As 
\begin_inset LatexCommand \vref{sub:The-MDL-based-Objective}

\end_inset 

 explains, an extra term, epsilon, is used to refrain from multiplication
 by 0.
 Due to the finite precision of digital systems, Eigen-values may be assigned
 this zero measure.
\end_inset 

.
 For completeness, differentiation is provided for optimisations which reparamet
erise over all dimensions at once (joint) or do so separately (sequential).
\layout Comment

EXPLAIN WHY MI AND NMI ARE FLAT.
\layout Standard


\begin_inset Float table
wide false
collapsed false

\layout Standard
\align center 

\begin_inset  Tabular
<lyxtabular version="3" rows="12" columns="3">
<features>
<column alignment="center" valignment="top" leftline="true" rightline="true" width="0">
<column alignment="center" valignment="top" leftline="true" width="0">
<column alignment="center" valignment="top" leftline="true" rightline="true" width="0">
<row topline="true" bottomline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

Objective Function
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

Single-point Warp
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

Multi-point Warp
\end_inset 
</cell>
</row>
<row topline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

PDF
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

-137.2658
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

-136.7145
\end_inset 
</cell>
</row>
<row topline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

Wavelets
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

-145.4988
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

-147.7877
\end_inset 
</cell>
</row>
<row topline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

Joint Model-based
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

-149.2192
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

-150.3197
\end_inset 
</cell>
</row>
<row topline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

Sequential Model-based
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

-148.7245
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

-149.9904
\end_inset 
</cell>
</row>
<row topline="true" bottomline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

MSD
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

-143.0227
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

-149.0114
\end_inset 
</cell>
</row>
<row bottomline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

Joint MI
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

-142.3415
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

-136.0651
\end_inset 
</cell>
</row>
<row bottomline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

Sequential MI
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

-142.3712
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

-136.0651
\end_inset 
</cell>
</row>
<row bottomline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

Joint NMI
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

-142.3154
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

-142.3068
\end_inset 
</cell>
</row>
<row bottomline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

Sequential NMI
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

-142.3154
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

-142.3118
\end_inset 
</cell>
</row>
<row bottomline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

Model after MSD
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

-138.6823
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

-47.0961
\end_inset 
</cell>
</row>
<row bottomline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

Mixed Model/MSD
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

-129.3791
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

-105.3422
\end_inset 
</cell>
</row>
</lyxtabular>

\end_inset 


\layout Caption


\begin_inset LatexCommand \label{cap:Comparison-of-objective}

\end_inset 


\size small 
Comparison of objective functions.
 The values indicate an approximation to model complexity (its determinant).
\end_inset 


\layout Subsection

Problems Investigated
\layout Subsubsection

Varying Weights
\begin_inset LatexCommand \label{sub:Varying-Weights}

\end_inset 


\layout Standard

In May 2004, a further investigation of the ratio between shape and intensity
 began.
 As a result, ways of stabilising the objective function at a 
\emph on 
low
\emph default 
 convergence point, may have been identified.
 Otherwise, with this ratio improperly set, convergence (though not a full
 one) continuously appeared well above the correct solution.
 Figure 
\begin_inset LatexCommand \ref{cap:The-old-model-based}

\end_inset 

 shows what happens when the ratio 
\begin_inset Formula $\mathbf{W}_{S}$
\end_inset 

 is inadequately picked.
\layout Standard

In the past (and seldom at present) the value of 
\begin_inset Formula $\mathbf{W}_{S}$
\end_inset 

 was chosen either to be a pre-set constant provided by the user, a value
 which is derived from the image derivatives, or a value that is proportional
 to the variances.
 In either case, it was always found to be overly high.
 When this value winds up taking shape into account, the objective function
 quickly fails to improve as shown below.
\layout Standard
\align center 

\begin_inset Float figure
placement H
wide false
collapsed false

\layout Standard
\align center 

\begin_inset Graphics
	filename ./Graphics/stuck.ps
	display none
	scale 30.00

\end_inset 


\layout Caption


\begin_inset LatexCommand \label{cap:The-old-model-based}

\end_inset 


\size small 
The old model-based objective function which gets stuck due to Ws inappropriatel
y set.
\end_inset 


\layout Standard

Going back to Figure
\begin_inset LatexCommand \vref{cap:Warps-shown-as}

\end_inset 

, it can be seen what the 
\emph on 
shape
\emph default 
 is actually defined to be.
 The combined model is that which takes into account image intensity values
 along with the 
\emph on 
warps
\emph default 
 that accompany these newly-deformed values.
 The problem encountered resulted from the fact that all these curves were
 initially linear
\begin_inset Foot
collapsed false

\layout Standard

The curves were all going from the bottom left to the top right corner,
 meaning that each point mapped onto itself and no changes were made.
\end_inset 

 \SpecialChar ~
and mutually identical.
 In other words, the shape defined for all data instances had no variance
 at all.
 It was therefore hard, using a proper combined model, to 'lure' the objective
 function to depart from that point of low variance.
 Warps were simply thrown away once they had been chosen.
\layout Standard


\begin_inset Note
collapsed false

\layout Standard

Explain the above better (TODO)
\end_inset 


\layout Subsubsection

The Curse of Set Size
\layout Standard

At this stage, the model-based objective function could only cope well with
 set sizes that were rather small.
 It found it difficult to minimise a model by altering just one instance
 whose overall effect on that model was minute.
\layout Standard

This problem was in no sense new.
 In a model-driven objective function, such as in the work of Kotcheff and
 Taylor, alteration of one single data instance does not affect the model
 considerably.
 The greater the set size becomes, the lower the effect which parameterisation
 (or in this case, image warps) have.
 The only exception to this is when a warp is applied uniformly to all data
 instances.
 In the case of registration though, it is impractical.
\layout Standard

In order to deal with large enough problems, where for instance, dozens
 of images need be accounted for, resolutions need to be found that make
 convergence linearly proportional to the size of the set.
 The problem was also well-acquainted in the work on landmarks selection
 where sets remained 10 or 20 in size.
\layout Standard

This fundamental problem suggests that a model-based approach is limited.
 It is not yet sufficiently well-behaved to study a 
\emph on 
population
\emph default 
, only a smaller-scale case study.
\layout Comment

Show figure
\layout Subsubsection

The Hindrance of Speed
\layout Standard

Speed was a worrisome issue, for multi-knot-point warps in particular.
 The calculation of a Green's function output for some given knot-points
 was not the real culprit.
 It was not the centre of slowness of propagation.
 It was its application to an image which is followed by Eigen-analysis
\begin_inset Foot
collapsed false

\layout Standard

There is a serious flaw present because this analysis is cubic in its complexity.
 Profiling is yet to be considered an option for improvements discovery.
\end_inset 

 \SpecialChar ~
which made the approach altogether slow.
 Ways were needed to be discovered to eliminate this as an issue.
 Some of the following solutions are inter-related to speed.
\layout Subsubsection

Optimisation Issues
\layout Standard

The optimisation regime needed to be changed as it often got stuck without
 any constructive paths to a solution being found.
 It was at first unknown whether the objective function was malformed, or
 perhaps its handling by the general-purpose Nelder-Mead optimiser was not
 effective.
 It could be seen that there was no justification in believing that the
 function was truly stuck.
 Sharp drops in value could occasionally be observed, meaning that good
 warps were finally found and applied to the data.
 Figure 
\begin_inset LatexCommand \ref{cap:Drops-which-illustrate}

\end_inset 

 makes it rather crystal-clear.
 
\layout Standard
\align center 

\begin_inset Float figure
placement H
wide false
collapsed false

\layout Standard
\align center 

\begin_inset Graphics
	filename ./Graphics/drops.ps
	display none
	scale 27.00

\end_inset 


\layout Caption


\begin_inset LatexCommand \label{cap:Drops-which-illustrate}

\end_inset 


\size small 
Drops which illustrate the problems with optimisation.
\end_inset 


\layout Standard

Even at present some moderate drops are observed at times.
 With a less stochastic choice of warps, that unwanted effect might vanish.
\layout Subsubsection

Finding the Correct Solution
\begin_inset LatexCommand \label{sub:Finding-the-Correct}

\end_inset 


\layout Standard

One essential step, which can be used to understand the algorithm's behaviour
 and the direction it takes, is that which infers a state which is optimal
 -- that is --- a state that the objective function must reach when it behaves
 correctly.
 Analysis was performed to discover which warps, when applied to the data
 available, give a sensible (or perfect) result, i.e.
 
\emph on 
align
\emph default 
 the data.
 Figure 
\begin_inset LatexCommand \ref{cap:Data-alignment-to}

\end_inset 

 shows a set of correct warps with the corresponding set of results.
 These help in verifying that registration of data is finally obtained.
\layout Standard


\begin_inset Note
collapsed false

\layout Standard

BE ARBITRARILY CHOSEN
\end_inset 


\layout Standard
\align center 

\begin_inset Float figure
placement H
wide false
collapsed false

\layout Standard
\align center 

\begin_inset Graphics
	filename ./Graphics/align.ps
	display none
	scale 30.00

\end_inset 


\layout Caption


\begin_inset LatexCommand \label{cap:Data-alignment-to}

\end_inset 


\size small 
Data alignment to discover correct solution.
 On the left: piece-wise linear warps to be applied to original data; on
 the right: data after alignment.
\end_inset 


\layout Standard


\begin_inset Note
collapsed false

\layout Standard

RSS: Mention different choices of reference.
 DONE
\end_inset 


\layout Standard

The choice of a reference of course effects the 'correct' set of warps,
 but the notion of correctness is unchanged.
 In the case shown, reference is chosen to be the first of the data instances,
 meaning that it is assumed all data needs to be transformed based on that
 one image.
 It is warped to 
\emph on 
fit
\emph default 
 the first image.
 In practice, only the actual value is used to evaluate the performance
 of the model-based objective function.
 This means that this alignment is one amongst several possibilities, but
 its 
\emph on 
value 
\emph default 
provides an excellent estimate.
 Also worthy of mentioning is the fact that an immutable reference is maintained
 for the model-based case.
 This is why results are expected to be ultimately similar the the ones
 above, where that very same reference is chosen.
 
\layout Standard

In AART, advanced caution is dispensed to avoid reference choice that damages
 data integrity.
 It is safer to choose as reference data that is representative of the whole
 set (essentially one which lies in the centre of the multi-dimensional
 cloud in vector scape).
 Reference is chosen which lies closest to the mean of the set.
 Definitions of distance are alterable.
 Currently, sum of squared distances
\begin_inset Foot
collapsed false

\layout Standard

This measure is better immune to large local misalignment.
 This is similar to arguments presented in Equation 
\begin_inset LatexCommand \vpageref{eq: delta start}

\end_inset 

.
\end_inset 

 \SpecialChar ~
or fixed geometrical distances can be used in AART to locate a good reference.
\layout Standard


\begin_inset Note
collapsed false

\layout Standard

RSS: Mention choice of reference closest to mean by various definition.
 DONE
\end_inset 


\layout Comment

TO BE DONE IN THE FUTURE: ALSO LOOK AT ALL MENU ENTRIES TO ENSURE ALL settings
 are in fact mentioned in this report and rather than much material in the
 background, fill this paper with plenty of experiments.
\layout Subsubsection

Registration Target
\layout Standard

As well as knowing how transformations behave and how they affect the data,
 a measure of model quality needed to be established and plotted against
 steps in the algorithm.
 To make this value more meaningful, the value that one aspires to reach
 was estimated and shown in the plot.
 Previous figures, as well as later ones, include this measure, which was
 calculated rather easily having got the correct solution, as described
 in 
\begin_inset LatexCommand \ref{sub:Finding-the-Correct}

\end_inset 

 above.
\layout Subsubsection

Solution and Perturbation
\layout Standard

When the correct solution to registration was known, it was intriguing to
 see how the function would behave near that solution.
 Ideally, it should return to that correct solution quickly and quite controllab
ly (in the sense that no abrupt data changes occur in the process).
 Two types of perturbations were attempted: random noise and a randomly-placed
 CPS warp.
 Results showed that the objective function failed to revert the data to
 its form in the correct solution.
 In fact, the objective function value dropped 
\emph on 
below
\emph default 
 that which was expected.
 This instability of the objective function is explained later in this subsectio
n.
\layout Subsubsection

Interpolation Artifacts
\layout Standard

Whenever a correct solution was calculated, an unwanted artifact appeared
 near the edges of the bump.
 This was later on realised to be a result of interpolation which could
 be resolved simply by increasing the sampling resolution
\begin_inset Foot
collapsed false

\layout Standard

The number of pixels that data comprises is an argument that may be changed.
\end_inset 

.
 This can possibly be seen (although it is rather subtle) on the right column
 in Figure 
\begin_inset LatexCommand \ref{cap:Data-alignment-to}

\end_inset 

.
\layout Subsubsection

Change in Data Generator
\layout Standard

The process involving data generation of bumps was made more accurate so
 that unblemished half-ellipses would be invariantly created.
 This did not produce any better results, though reasoning about the correctness
 of data was no longer a worrying factor.
 Synthesis of data is now a richer component of the program with several
 more configurations to manipulate.
\layout Subsubsection

Objective Function Instability
\layout Standard

Once good results were found, certain similarity to the work of Davies (see
 2002 thesis) was encountered.
 There was a linearly (almost logarithmic) flat drop in the objective function
 value.
 It was decided that such problems need to be resolved at once.
 For both images and shapes, this was now an important issue to address
 in a principled fashion.
\layout Standard


\begin_inset Float figure
placement H
wide false
collapsed false

\layout Standard
\align center 

\begin_inset Graphics
	filename ./Graphics/under_target.ps
	display none
	scale 25.00

\end_inset 


\layout Caption


\begin_inset LatexCommand \label{cap:Evaluation-going-below}

\end_inset 


\size small 
Evaluation going below target when initialised at the registration target.
 The target of registration is indicated by the straight horizontal line.
\end_inset 


\layout Standard

Twining in particular was one person who could suggest ideas or provide
 help on the matter.
 The problem can be overcome by using knowledge on models and comparison
 between models and their constituent reconstructed instances.
 This process of comparison allows the corresponding discrepancies to be
 determined.
\layout Standard
\align left 
Figure 
\begin_inset LatexCommand \ref{cap:Evaluation-going-below}

\end_inset 

 shows that when the registration algorithm is initialised at the conceived
 correct solution, it can still slide below it.
 In fact, it always does.
 This suggests that the algorithm is not controlled properly and that the
 description length term can miss the correct solution.
\begin_inset Float figure
placement H
wide false
collapsed false

\layout Standard
\align center 

\begin_inset Graphics
	filename ./Graphics/10000_-_second_attempt-1.eps
	display none
	scale 30.00

\end_inset 


\layout Caption


\begin_inset LatexCommand \label{cap:A-long-optimisation}

\end_inset 


\size small 
A long optimisation with the successful algorithm shows that it surpasses
 what is questionably the correct solution.
\end_inset 


\layout Standard

Figure 
\begin_inset LatexCommand \ref{cap:A-long-optimisation}

\end_inset 

 should make it clear that given a large enough number of iterations, no
 clear convergence is reached .
 Even more problematically, the value of the objective function slides below
 the point where it ought to have been optimal, by definition.
\layout Subsubsection

Other Synthetic Data under Inspection
\layout Standard

During the process of objective functions investigation, while debugging
 in particular, simple sets of synthetic data were used.
 These are not worth any detailed exploration in this report, but results
 are wholly recorded in the WWW.
 Different data types can be selected from the Patron menu in AART and external
 data can also be imported directly, e.g.
 when real 1-D data becomes of use, if ever.
\layout Subsection

Attempted Solutions
\layout Standard

Having identified many issues, this subsection presents a few ways of circumvent
ing them.
\layout Subsubsection

The Successful Solution
\layout Standard

A successful solution was found to almost the entire problem of registration
 or at least its major weaknesses.
 This was done simply by changing the optimisation so that it searches a
 
\emph on 
valid
\emph default 
 
\emph on 
range
\emph default 
 of possible warps (the space of warps in essence) and runs for a long enough
 period of time to benefit from computational savings.
 Also, an increasingly higher tolerance was sought for the optimiser, whereupon
 registration using statistical models finally become possible and even
 successful.
 More on these solutions and successful heuristics are to be listed in the
 remainder of this broad subsection.
\layout Subsubsection

Speeding up Convergence
\layout Standard

The objective one should be after is the minimisation of some cost -- a
 cost that is associated with the model and the images which are being transform
ed.
 Convergence of the algorithm is declared once that cost can no longer be
 reduced.
 It has been found to be true that very much computational effort is spent
 on refining existing transformations, even when the solution is yet far
 away.
 As it turns out, at early stages of the optimisation, coarse changes to
 the images should suffice.
\layout Standard

Amongst the more important developments of this project, the author managed
 to find a way of substantially decreasing the amount of time which is required
 to register sets of 1-D data.
 This was done primarily by tweaking the optimiser which is involved in
 the process.
 It has been decided to aim for a different optimisation tolerance depending
 on the advancement towards the correct solution.
 By doing do, little time should be spent on obtaining lower costs at the
 early stages of registration.
 This rational observation motivated the re-implementation of a similar
 algorithm in a separate domain
\begin_inset Foot
collapsed false

\layout Standard

This domain is the selection of landmarks in shapes for the construction
 of statistical models of shape.
 Modification of this will be described later.
\end_inset 


\layout Subsubsection

Height Being Forced
\layout Standard

Coming back to Figure 
\begin_inset LatexCommand \vref{cap:Evaluation-going-below}

\end_inset 

, there was a serious flaw that is associated with the function's insufficiently
 constrained form.
 It was possible for the model to be improved by 'cheating' and concealing
 parts of the data.
\layout Standard

There was a period where in order to avoid data breaking and bumps shrivelling,
 a height was being forced to remain the same at the pinnacle of the bump.
 Several different schemes were attempted.
 At times, the position for insertion was projected from the mean and later
 it was derived from the model discrepancy.
 The results were not of very high quality at that stage and Figure 
\begin_inset LatexCommand \ref{cap:Highest-peak-being}

\end_inset 

 shows one such case.
 When run over a long period of time, a sharp tip can be observed which
 is due to points being forced to lie in a single fixed position.
 On other occasions, parts of the image are still being hidden.
 This basically results in gradual darkening of images subjected to registration.
\layout Standard
\align center 

\begin_inset Float figure
wide false
collapsed false

\layout Standard
\align center 

\begin_inset Graphics
	filename ./Graphics/try_multi_point_warp-2.eps
	display none
	scale 30.00

\end_inset 


\layout Caption


\begin_inset LatexCommand \label{cap:Highest-peak-being}

\end_inset 


\size small 
Highest peak being retained in registration.
\end_inset 


\layout Comment

Show figure here
\layout Subsubsection

Point Insertion
\layout Standard

An issue was latterly encountered where data drifted away quite slowly.
 Consequently, convergence could never truly be reached.
 The issue is worrying as it was found in Davies' work as well.
 This leads to the next point which is the model residuals.
 Present work places great emphasis on this matter.
\layout Subsubsection

A Parallel Discovery
\layout Standard

Points are currently being inserted where the variation (among the set of
 data) is the greatest.
 There are different methods to do so (see menu layout in AART for better
 insight).
 It was later realised that this insertion of points is analogous to work
 done by Tomos Williams on shapes and this insertion must take into account
 the model and its discrepancies.
 Observations of this nature actuated the work described in Section 
\begin_inset LatexCommand \ref{sec:Shapes-Revisited}

\end_inset 

.
\layout Section


\begin_inset LatexCommand \label{sec:Shapes-Revisited}

\end_inset 

Shapes Revisited
\layout Standard

Upon returning to the subject of shapes and automatic landmark selection,
 goals could be laid out perfectly well.
 There were the issues of speed and instability of the objective function.
 Also, it was vital to make the code work in the absence of its original
 developers and authors.
 These problems were all shortly embarked upon and some successful solution
 were found.
 Figure 
\begin_inset LatexCommand \ref{cap:The-unregistered-bump}

\end_inset 

 shows the data which was typically handled
\begin_inset Foot
collapsed false

\layout Standard

Examples of human hands were later tested as well .
 They were an easier case that is quicker to reach convergence.
\end_inset 

, namely the brick-and-bump data.
 The 3 principal modes of variation are shown for the raw data at the start
 when points are spread at equally-spaced locations along the curve.
\layout Standard


\begin_inset Note
collapsed false

\layout Standard

getting the code to work with low variation and then making it quicker.
\end_inset 


\layout Standard
\align center 

\begin_inset Float figure
wide false
collapsed false

\layout Standard
\align center 

\begin_inset Graphics
	filename ./Graphics/original_bump.eps
	display none
	scale 35.00

\end_inset 


\layout Caption


\begin_inset LatexCommand \label{cap:The-unregistered-bump}

\end_inset 


\size small 
The unregistered bump data and its three principal modes of variation (
\begin_inset Formula $\pm$
\end_inset 

2 standard deviations).
\end_inset 


\layout Standard

To ease the operation of the code, an interface (Figure 
\begin_inset LatexCommand \ref{cap:The-graphical-user}

\end_inset 

) was built and used to bring the code back into workable order.
 The process otherwise involved manipulation of the code which requires
 the user to know the algorithm.
 This situation proved to be difficult and tolerable at best.
\layout Standard
\align center 

\begin_inset Float figure
wide false
collapsed false

\layout Standard
\align center 

\begin_inset Graphics
	filename ./Graphics/mdlgui_screenshot.eps
	display none
	scale 70.00

\end_inset 


\layout Caption


\size small 

\begin_inset LatexCommand \label{cap:The-graphical-user}

\end_inset 

The graphical user interface for semi- automatic landmark selection as of
 June 2004.
\end_inset 


\layout Subsection

The Successful Use
\layout Standard


\begin_inset Note
collapsed false

\layout Standard

getting the code to work and some results
\end_inset 


\layout Standard

After applying some changes to the code and running some over-night experiments,
 the code could finally be used in a way which made it usable and effective.
 At first, the original bump data was used with varying levels of variation
 that is inherent in the data.
 At a later stage, hand data was used as well to test a more realistic and
 interesting example.
\layout Standard

Once the code was in full working order and an interface was in place, experimen
ts could be set up and run very rapidly.
 The rest of this section describes some of these experiments and their
 corresponding and related equivalents.
 Many of the same ideas were parallelly applied to the code handling images
 and their model-based registration, namely that of AART.
\layout Standard


\begin_inset Note
collapsed false

\layout Standard

TODO: more here
\end_inset 


\layout Subsection

Subsets Selection
\layout Standard

This idea is concerned with sub-division of the problem and localisation
 of computation which otherwise becomes very demanding.
 Since the model constructed is conventionally build from the entire set
 under consideration, there is a clear correlation between the complexity
 of the entire problem and that size of the set.
 This correlation is not linearly proportional to the size of the set either.
 To get decent results (either in landmark selection or image correspondence),
 a very long optimisation is required for increasingly larger sets of data.
 Although the principles are genuine and sophisticated at first sight, they
 suffer from this unappealing relational complexity.
\layout Standard

The next section explains this principle in the context of images.
 It was decided to try to apply the same concepts to shapes after it was
 arguably successful when images were under consideration.
\layout Subsection

Adaptive Precision
\layout Standard

The source of this useful strategy came from the registration algorithm.
 It was found that coarse and hastily-chosen transformation sufficed at
 the former stages of the optimisation.
 It was premature to require a high precision from the optimiser at these
 stages.
 Putting this idea in different terms, the machine chooses to loop laboriously
 looking for very meticulously-chosen warps when, in fact, since all elements
 in the set is dynamic, a slack choice of a warp serves the overall aim.
 Sets are manipulated one instance at a time and the problem appears quite
 different every time a loop is completed.
 By lowering the precision demands, more iterations can fit within a tantamount
 time period (see Figure 
\begin_inset LatexCommand \vref{cap:Adaptive-precision-requirement}

\end_inset 

).
\layout Standard

The subject of precision and its impact on speed will be revisited in Section
 
\begin_inset LatexCommand \ref{sec:Extensions_algorithms}

\end_inset 

.
 It is an essential strategic choice which is suitable for a problem where
 its nature is dynamic
\begin_inset Foot
collapsed false

\layout Standard

As an example, the famous travelling salesman problem speaks of a pre-set
 value for each edge in a graph.
 This means that the problem never changes.
 What if the values of edges changed for each choice of a path? This renowned
 problem would then become less workable then it has become.
 Each choice then introduces a new, yet unknown, optimisation problem.
\end_inset 

.
\layout Section

Present Work
\begin_inset LatexCommand \label{sec:Present-Work}

\end_inset 


\layout Standard

The writing-up of this report unsurprisingly interrupted some experiments
 in progress.
 There are partial results which establish a clearer path to more experiments
 of possible use.
 Future experiments in Chapter 
\begin_inset LatexCommand \ref{cha:Future-Work}

\end_inset 

 describe some of these yet-to-be-performed experiments and their closely-relate
d goals.
\layout Subsection

Model Residuals
\layout Standard

Attempts were made at the identification of the point of convergence for
 the registration algorithm.
 A clear flaw with the cost that had been defined was discovered.
 It turned out that the way in which the algorithm presently evaluates models
 neglects to account for small artifacts.
 These artifacts 
\emph on 
must
\emph default 
 be encapsulated in this model.
 More crucially, these small artifacts which are left-out residuals need
 to form part of the model cost (description length term).
 In their absence, the objective function was able to drift away, thereby
 hiding vital structures in images.
 Not only was the result of registration poorer due to an improper model
 cost, but also it was impossible to contend that one unique solution can
 ever be reached.
\layout Standard


\begin_inset Note
collapsed false

\layout Standard

Rewrite the sentences below.
 TODO
\end_inset 


\layout Standard

It is now realised that the objective function must account for the model
 errors in some way or another.
 This is why the residuals for each image, as reconstructed from the model,
 need to be calculated.
 All inverse warps needs to be calculated first to do so -- a step that
 is not trivial (on-going and future work is scheduled to be done on this).
\layout Standard

Before this incorporation of residuals goes on, it was suggested that the
 shapes problem is looked at again.
 It is believed that description length should have a term accounting for
 model discrepancy so that the optimisation can be made stable.
 Technicality concerning MDL is expected to be discussed with Carole Twining
 in the near future.
 Eventually, a term must be precisely defined to account for the residuals
 and, having solved the problem for the simpler and well-founded case of
 shapes, the less trivial case of image registration can be resumed.
 Several discussion have raised disagreements regarding the way in which
 residuals are defined in the context of appearance models, images and transform
ations.
\layout Standard

To summarise, of current interest is the way in which model residuals can
 nullify erosion of data.
 They can be used to compose a proper description length for models and
 images.
 By resolving such a problem, better registration performance will be yielded.
\layout Subsection

Adaptive Precision for Images
\layout Standard

This work is associated with the change in optimiser tolerance and the context
 is now different.
 This approach was never tried previously, but it seems to get good results
 and it incorporates a novel and elegant algorithm which seeks a multi-scale
 approach to choice of warps.
 Rather than scaling the data, it scales the level of warp quality and,
 in that sense, it is multi-scale in an unorthodox sense.
\layout Standard
\align center 

\begin_inset Float figure
placement H
wide false
collapsed false

\layout Standard
\align center 

\begin_inset Graphics
	filename ./Graphics/autolong.eps
	display none
	scale 30.00

\end_inset 


\layout Caption


\begin_inset LatexCommand \label{cap:Automatic-precision-and}

\end_inset 


\size small 
Automatic precision and the differing rates of convergence for image registratio
n.
\end_inset 


\layout Standard

Figure 
\begin_inset LatexCommand \ref{cap:Automatic-precision-and}

\end_inset 

 shows how the choice of tolerance (or precision homologously) affects the
 rate of convergence.
 What is less obvious to the mind, is the way this optimisation improves
 in terms of time.
 While this is a possible experiment to perform at present, registration
 versus time will be shown only later, when a different approach is discussed.
 
\layout Standard

Figure 
\begin_inset LatexCommand \ref{cap:Adaptive-precision-requirement}

\end_inset 

 shows quite clearly the differing rates of objective function improvements
 in its evaluation.
 Different curvatures correspond to different choices of tolerance.
\layout Standard
\align center 

\begin_inset Float figure
placement H
wide false
collapsed false

\layout Standard
\align center 

\begin_inset Graphics
	filename ./Graphics/adaptive.eps
	display none
	scale 30.00
	keepAspectRatio

\end_inset 


\layout Caption


\begin_inset LatexCommand \label{cap:Adaptive-precision-requirement}

\end_inset 


\size small 
Adaptive precision requirement resulting in different rates of convergence.
 This curve is drawn in the context of shapes and selection of landmark
 point.
\begin_inset Note
collapsed false

\layout Standard

TODO: RSS: Is this for shape?? YES -- DONE
\end_inset 


\end_inset 


\layout Subsection

Varying Set Sizes
\layout Standard

The idea has been discussed before in a lesser extent.
 This subsection shall provide some results along with basic analysis which
 abstains from drawing any final conclusions.
\layout Subsubsection

Shapes Subsets
\layout Standard

The stochastic choice of subsets attempted to speed up the construction
 of models through simplification.
 The choice of subsets was at first made at every single iteration.
 At later stages, such a choice was only made once within a set cycle (e.g.
 10 or 100 iterations).
 This intended to allow the objective function and the algorithm to stabilise
 and deal with a somewhat similar problem repeatedly.
 When subsets are not reshuffled often, the subset under consideration retains
 more commonalities.
\layout Standard

This idea was expected to result in reduction in run-time.
 That is because Eigen-analysis is then being simplified and, along with
 it, the scope of the problem is reduced.
 When sets are smaller, they are strictly easier to handle.
\layout Standard
\align center 

\begin_inset Float figure
wide false
collapsed false

\layout Standard
\align center 

\begin_inset Graphics
	filename ./Graphics/subsets_shapes.eps
	display none
	scale 35.00

\end_inset 


\layout Caption


\begin_inset LatexCommand \label{cap:A-comparison-of}

\end_inset 


\size small 
A comparison of performances in landmark selection.
 Shown above is an algorithm which is based on an entire set versus one
 which is based on a stochastic subset.
 The latter is quicker and it fluctuates due to the varying selection of
 a subset (3 shapes out of 10 in total).
\end_inset 


\layout Standard

Unfortunately, the approach taken above worked badly in terms of time.
 Its performance, as measured by the 
\emph on 
entire
\emph default 
 set of data, was worse as well.
 The first of these is almost a contradiction which is why further work
 must be considered.
 It ought to be discovered that handling of subsets should 
\emph on 
at the least
\emph default 
 reduce the complexity of model construction.
 Regarding the performance, results for images prove otherwise as explained
 below.
 
\layout Subsubsection

Images Subsets
\layout Standard

Earlier experiments suggested similar conclusions to the ones above.
 It appeared as if the approach resulted in slower progress and worse results,
 as deduced from the full model of what was said to be registered data.
\layout Standard

Later on, and quite recently in fact, it was shown that values go lower
 (i.e.
 registration is improved) by using the subset approach.
 Many iteration though were required to show this.
 The subset-driven function caught up with its full-set equivalent and sank
 well below it.
 It was not clear though what had happened to the data, which could as well
 drift away.
 It is indeed possible that it got eroded more quickly for reasons that
 were earlier explained.
\layout Standard

To summarise, subset-driven function are yet to be investigated, but they
 do not seem as powerful as adaptive precision in problems of shapes and
 images, for example.
 They often showed to be worse in terms of time, as well as worse in terms
 of performance.
\layout Section

Conclusions
\layout Standard

Few conclusions were listed already, but what follows is a concise and generic
 summary.
\layout Standard

Registration using statistical models is viable.
 It has clear drawbacks because it is (1) slow; (2) able to drift away (and
 destroy data) and (3) complex.
 When data registration is performed with the methods proposed, models of
 deformation are produced and correspondences identified.
\layout Standard


\begin_inset Note
collapsed false

\layout Standard

Reuse MICCAI results from below
\end_inset 


\layout Standard

Model-based algorithms result in appearance models whose determinant is
 by orders of magnitude lower than that which is measured at the start.
 The execution time they impose is inferior to MI, much as was expected
 all along, but might be superior to that of MSD.
\layout Standard

The MDL term is improperly defined at present since it ignores the model
 discrepancies.
 When MDL is approximated by the determinant of the covariance matrix of
 the model, problems arise and registration (or landmark identification)
 is exacerbated past the stage when convergence should hold.
 Instead of convergence, a logarithmically decreasing 'tail' is observed
 and it indicates the need for objective functions being revised.
\end_inset 


\layout Chapter
\pagebreak_top 
Future Exploration
\layout Standard
\align right 

\size large 

\begin_inset Quotes eld
\end_inset 

W
\size small 
e know nothing in reality; for truth lies in an abyss.
\begin_inset Quotes erd
\end_inset 


\newline 
-- 
\emph on 
Democritus.
\layout Standard


\begin_inset Note
collapsed false

\layout Standard


\noun on 

\begin_inset LatexCommand \label{cha:Future-Work}

\end_inset 


\begin_inset LatexCommand \index{Future Work}

\end_inset 


\noun default 
A 3-D Registration method
\layout Section

Tim...
\layout Section

MSD...
 VXL stuff
\end_inset 


\layout Standard


\begin_inset ERT
status Open

\layout Standard

\backslash 
lettrine{H}{aving} 
\end_inset 

 introduced a small family of methods which successfully solve the problems
 at hand, it would be most desirable to look ahead and make proposals.
 Several deficiencies of the methods are yet to be addressed and various
 extensions implemented.
 While the methods accomplish their goals, there is place for further refinement
 and improvements.
 Generalisations, customisations, and further simplifications can be envisioned
 and they are all motivated by known drawbacks.
\layout Standard

The chapter lists possible paths that take the existing frameworks and enable
 them to perform better and even incorporate additional functionality.
\layout Section

Pitfalls
\layout Standard

Computational loads are an important factor that has become a barrier, particula
rly in 3-D.
 There are particular steps in the algorithm whose computational cost is
 far greater than the remainder.
 Firstly, one must consider the long time that is required to synthesise
 many images from appearance models and subsequently use them in an evaluation.
 The greater the number of synthetic images, the more accurate the results.
 This relationship means that there is no clear point of balance.
 Sufficiency in the evaluation can never be attained.
\layout Standard

Secondly, the more time-consuming process involved the computation of inter-imag
e distances.
 With the added complexity of a third dimension, as well as a shuffle distance
 with large neighbourhood sizes, there is a considerable cost which is proportio
nal to the number of voxels at hand.
\layout Standard

Another problem one can identify lies in the fact that computation of Sensitivit
y and Generalisation is not principled.
 This can be corrected by calculating the self-normalising pseudo-entropy
 of graphs 
\begin_inset LatexCommand \cite{Neemuchwala}

\end_inset 

.
 This graph represents the distances between images (edges) where vertexes
 are individual images.
 Entropic graphs is an area that was explored in great depth, yet it turned
 out to be rather complex due to the need to estimate many parameters, using
 a Monte-Carlo simulation.
 Although efforts to adopt the method have been conceded, there is place
 to propose another paradigm for dealing with this issue.
 The
\emph on 
 ad hoc 
\emph default 
nature of Specificity and Generalisation leaves plenty of room for new measures
 to evolve.
 Whether alternative method would be equally cheap to compute remains an
 unknown.
 As in many such large-scale problem, simplicity has its merits, too.
\layout Standard

The issues are dealt with in depth in the next section.
\layout Section

Extending the Scheme
\layout Standard

There are a few proposed improvements that can further improve the validity
 and accuracy of the metrics.
\layout Subsection

Normalisation
\layout Standard

At present, values returned for various measures are dependent upon the
 size of the sets, the dimensionality and a few other free parameters.
 This makes it difficult to argue about and distinguish between results
 from different experiments, unless all conditions (free parameters) were
 identical.
 For example, an experiment performed with large images and small sets cannot
 trivially be compared against other experiments involving small images
 and very large sets.
 In order for all results to be numerically comparable, there need to be
 a normalisation stage, which accounts for the many free parameters simultaneous
ly.
\layout Subsection

Investigating Robustness
\layout Standard

One aspect which must never be neglected are the boundaries and edge cases.
 It is valuable to know where the methods cease to be valid as noise levels
 supersede the signal.
 Having found the limitations of the method, their robustness can be improved.
 For instance, in the case of model assessment, one can improve the range
 of displacements where results can be differentiated by increasing the
 size of the shuffle neighbourhood.
 Prior experiments showed that the performance is degraded beyond a certain
 shuffle neighbourhood size, but there are other parameters that can be
 varied and their effect on the shuffle neighbourhood is not mutually exclusive.
\layout Subsection

Further Improvement of Sensitivity
\layout Standard

Of particular interest is the notion of sensitivity as it enables one assessment
 method to be compared against another.
 Although sensitivities were shown to culminate at a particular value of
 the shuffle distance, other approaches that had been investigated could
 perhaps entail superior sensitivity, at the expense of computing power.
 It is worth exploring if a more complex approach, e.g.
 one which considers an average or median in a neighbourhood of pixels/voxels,
 outperforms shuffle distance.
\layout Chapter
\pagebreak_top 

\noun on 

\begin_inset LatexCommand \label{cha:Future-Work}

\end_inset 


\begin_inset LatexCommand \index{Future Work}

\end_inset 


\noun default 
Summary and Conclusions
\layout Standard
\align right 

\size large 

\begin_inset Quotes eld
\end_inset 

I
\size small 
f you're not part of the solution, you're part of the precipitate.
\begin_inset Quotes erd
\end_inset 


\newline 
-- 
\emph on 
Henry J.
 Tillman.
\layout Standard


\begin_inset Note
collapsed false

\layout Standard


\noun on 

\begin_inset LatexCommand \label{cha:Future-Work}

\end_inset 


\begin_inset LatexCommand \index{Future Work}

\end_inset 


\noun default 
Automatic Appearance model construction
\layout Section

Tim...
\layout Section

include my work on 3-D registration with results
\layout Standard

Piece-wise affine
\end_inset 


\layout Standard


\begin_inset ERT
status Open

\layout Standard

\backslash 
lettrine{T}{he} 
\end_inset 

 work covered in this thesis can be summarised as follows.
 Firstly, a novel framework was described which non-rigidly registers images
 using a model-based similarity measure.
 This framework is able to deal with any type of images and.
 while it requires a number of images in order to become practical (i.e.
 in order for a sensible model to be built), its performance not depend
 on the type of variation that is contained in the set of images.
 As a result of registering the images using a model-based approach, one
 also obtains an appearance model, which is progressively refined and whose
 quality is dependent on the quality of the registration algorithm.
 This establishes a framework for automatic construction of models that
 requires nothing but a registration algorithm.
\layout Standard

The second part of the work is concerned with assessment.
 Two things are being assessed: the quality of any appearance model (or
 any generative model) and the quality of a groupwise registration.
 This opens up the possibilities of comparing NRR algorithms and hand-tweaking
 them for better performance.
\layout Standard


\begin_inset ERT
status Open

\layout Standard
 
\backslash 
section{Discussion} 
\backslash 
label{sec:Discussion}
\layout Standard
The results of the validation experiment reported in Section 7 are the most important outcome of the work presented here.  They demonstrate a causal relationship between our Specificity and Generalisation measures, and a known (up to an additive constant) mean pixel displacement, $d$. A strong correlation  between these model-based measures and a Generalised Overlap measure, based on ground truth, adds further weight to this interpretation.  The fact that the relationship with $d$ held good over many different instantiations of a very general class of perturbing warps, makes it unlikely (though not impossible) that there is any significant pattern dependence.
\layout Standard
The results obtained with added noise are also encouraging, since it is a reasonable concern that the use of an intensity-based distance measure might make the model-based measures sensitive to noise. In the event, the approach seems robust to quite significant levels of noise.  The fact that the absolute values of specificity and generalisation change when noise is added, mean that they would not be useful for comparing registration results for different image sets.  Their ability to compare the performance of different registration algorithms applied to the same set of images, the main intended use, is, however, unaffected.
\layout Standard
Our results comparing the performance of different registration algorithms demonstrate that the model-based measures, and Specificity in particular, are sufficiently sensitive to misregistration to provide useful discrimination in a practical setting.  There is, however, a potential concern that it is important to address.  It might be argued that using a model-based approach to assessing registration favours methods which use a model-based objective function for registration (as in the experiments reported here). In practice, we do not believe that this is a problem.
\layout Standard
First, as we have argued above, our validation results show that there is a causal relationship between the mean pixel displacement, $d$, and Specificity/Generalisation.  It is thus irrelevant how a registration (or misregistration) has been obtained.  Second, the MDL objective function we optimise in our model-based registration method measures a quite different property of the model to those we use in evaluation, so there is no element of 'self-fulfilling prophecy. In an ideal world it would, of course, be preferable to avoid even the possibility of bias, though it seems unlikely that one could devise a strategy for evaluation that had no relevance to achieving a good registration in the first place. We hope that, in due course, other ground-truth-free methods of evaluation will be developed, allowing a multi-perspective assessment of performance.
\layout Standard
One obvious limitation of our approach to evaluation is that it can {
\backslash 
em only} be applied to groups of images.  This could be considered an important restriction, since many practical applications involve registration of pairs or very short temporal sequences of images.  We would argue that, in fact, this is a necessary restriction, because it is only possible to arrive at a meaningful assessment of registration in the context of a population of images.
\layout Standard
The experiments we have reported were performed in 2-D to limit the computational cost of running the large-scale evaluation for a range of parameter values and with repeated measurements.  The extension to 3-D is, however, trivial, though the calculation of shuffle distance for 3-D images increases the computational cost significantly.  We have implemented the method in 3-D and the time taken to evaluate the registration of 100 190x190x50 images using a shuffle radius of 2.1 and $
\backslash 
mathcal{M} = 1000$ is around 62.5 hours on a modern PC, which is short compared to most registration algorithms.
\layout Standard
There are a number of issues that merit further investigation.  We have studied a particular method of measuring image separation, but others, such as local correlation, would be worth exploring. Another interesting issue is whether it is possible within this framework to localise registration errors.  We have performed some initial experiments, summing the shuffle difference maps between all pairs of images in the registered set. This gives some interesting results, highlighting areas of common misregistration, but it is not clear what quantitative interpretation could be placed on such maps.  Finally, it is clear that our current measures of Specificity and Generalisation are not normalised -- their values depend on the size of the set of registered images, the number of synthetic images generated and so on.  We are currently exploring the possibility of measuring more fundamental properties of the relationship between the real and synthetic image distributions, with a view to achieving a 'natural' normalisation.
\layout Standard

\backslash 
section{Conclusions}
\layout Standard
We have described a method for registering images in a groupwise fashion including the quality of their appearance model in the objective fucntion. Not only does this enable us to reach good results from a groupwise perspective, but it also results in the automated construnction of appearance model, whose quality is assessed.
\layout Standard
 We have also described a model-based approach to evaluating the results of NRR of a group of images. The most important advantage of the new method is that it does not require any ground truth, but depends solely on the registered images themselves.
\layout Standard
We have validated the approach by studying the effect of perturbing, progressively, the registration of an initially registered set of images, comparing the results with those obtained using a 'gold standard' measure based on the overlap of ground-truth anatomical labels.  We have shown that our new method provides measures of registration accuracy that are monotonic functions of the known misregistration, and that one, {
\backslash 
em Specificity}, provides a more sensitive measure of misregistration than the approach based on ground truth.
\layout Standard
The model-based approach requires a distance measure in image space, and we have also demonstrated that the use of shuffle distance, rather than Euclidean distance, improves the sensitivity of the approach.
\layout Standard
We have further validated the approach, and illustrated its application, by performing a comparative evaluation of the results obtained using three different NRR algorithms, demonstrating the superiority of a fully-groupwise algorithm over a repeated pairwise approach.
\layout Standard
It is important to emphasise that our approach is not restricted to evaluating model-based NRR algorithms, though we presented results for one such method; the model-based measures of registration accuracy can be applied to any set of non-rigidly registered images, however they were obtained.  We have discussed the possibility of a bias in favour of model-based methods of registration and conclude that there is no major problem, though it would be desirable to compare results obtained using a range of ground-truth-free methods of evaluation.
\layout Standard

\end_inset 


\layout Standard


\begin_inset Note
collapsed false

\layout Standard


\begin_inset Note
collapsed false

\layout Standard

More QUOTES for Thesis 2006:
\layout Standard

Science does not know its debt to imagination.
 ~Ralph Waldo Emerson
\layout Standard

UPDATE: ALL ADDED
\end_inset 


\layout Section


\begin_inset LatexCommand \label{sec:Brief-Summary}

\end_inset 

Brief Overview
\layout Standard


\begin_inset ERT
status Open

\layout Standard

\backslash 
lettrine{S}{ ome}
\end_inset 

 of the main relevant concepts and techniques in existence have been explained
 and numerous examples have been given, although their number was restricted
 to allow for a broader survey.
 Most such techniques directly relate to the problems which need to be tackled
 and their utilisation in past and present has been thoroughly explained.
 As future experimentation is expected to rely on recent research and is
 most likely to involve similar ideas, algorithms and paradigms, continuous
 reading of technical reports, alongside reproduction of the experiments,
 will be an essential portion of the research approached.
\layout Standard

The problems with current techniques were found to vary from the interest
 in efficiency to possible flaws and gaps, a part of which being driven
 by insufficient correctness arguments and lacking ground-truth.
 Without a doubt, there are phases in current research where heuristics
 take over at the expense of valid implementation that can be reasoned about
 straight-forwardly.
 Many areas are still controversial and common assent is missing and might
 never be reached.
 As instances for the aforesaid claims, a group-wise brain analysis algorithm
 devised a wide range of domain-specific facts (see 
\begin_inset LatexCommand \vref{sub:Concurrent-Advancements}

\end_inset 

).
 Moreover, a major undecided issue is the most advantageous warp type and
 its corresponding complexity that strives to give ideal results per permanent
 time unit.
\layout Standard

This project, much like other projects in this area, attempts to find some
 answers to the questions raised and extricate us from uncertainties and
 disagreements.
 It seeks a theoretical proof which can be backed by empirical evidence.
 It
\begin_inset Note
collapsed false

\layout Standard

DONE -- We should aim for theoretical proof backed by empirical evidence....
 RSS: put it in text like this
\end_inset 

progressively implements a convenient tool for quickly evaluating and profiling
 different ideas and approaches.
 Whether it will be successful in the sense that it should provide inarguable
 answers and discover new techniques that are ingenuous, it is yet unknown.
 This project should draw conclusions regarding performance, feasibility
 and validate or invalidate some results of previous work.
 Preferably it should surpass previous work that it has built upon.
 No results will be taken for granted and a 
\emph on 
critical
\emph default 
 approach will be dispensed at all times.
\layout Standard

Within the second year of the project, it is hoped that an implementation
 of a better warp and model test-bed will be available.
 It should achieve dense correspondence across a set of synthetic (and hopefully
 medical) images in 2-D and 3-D.
 Software should be capable of looking into the behaviour of warps regardless
 of the nature and scale of the data.
 It must also respond within a suitable time period, although the notion
 of 
\begin_inset Quotes eld
\end_inset 

suitable time period
\begin_inset Quotes erd
\end_inset 

 is loosely-defined.
 There is a growing belief that such tool can be of great interest to these
 who use and facilitate active appearance models.
\layout Standard

Nonetheless, there is a real snag as the data under consideration should
 still be modified to approve the successful application of the techniques
 to data of higher dimensionality.
 The run-time and the results that can be retrieved within a limited time-frame
 is then the main impediment.
\layout Standard

Although a partial time-line was specified for this project and its intermediate
 objectives, it is not yet clear where the project will turn and what it
 will eventually accomplish with success.
 It is known, however, what should 
\emph on 
ideally
\emph default 
 be accomplished.
 Semi-annual reports and documents will clarify the emerging plans and intention
s as they become more concrete.
\layout Comment

attention that this project attracts is worth mentioning?
\layout Comment

WHY IS IT CONTROVERSIAL? What makes it difficult.
 Is it at all feasible?
\layout Comment

Significance of Research
\layout Comment

How will it affect future assumption?
\layout Comment

Importance of research?
\layout Comment

What is expected?
\layout Section


\begin_inset LatexCommand \label{sec:Conclusions}

\end_inset 

Conclusions
\layout Standard

The appearance models currently used are not fast and cannot be argued to
 be ideal in any sense.
 A solution to these flaws would be highly desirable.
 While it is not clear how to optimise models or how to evaluate a model
 
\begin_inset LatexCommand \cite{Kotcheff}

\end_inset 

, there are measurable means for arguing about the quality of these models
 comparatively.
 Amongst the main problems that are ordinarily seen in appearance models
 is their inferior performance, although this depends on the functionality
 required.
 Automation could have a significant contribution to such a model, but correspon
dence needs to be achieved first.
 Luckily, issues of correspondence have been investigated largely in the
 past decade so this should not be a peril.
\layout Standard

What is worth investigating even further is the ability of warps to improve
 models and at the same time encapsulate several analysis steps together.
 What is even more reassuring is the proven ability of models to improve
 warps selection and improve on existing group-wise registration methods.
 This improvement relies on the fact that a large-scale collective
\emph on 
 
\emph default 
analysis replaces the weaker, yet computationally inexpensive, pair-wise
 scope.
\layout Comment

Make sure all papers suggested by Taylor are included.
\layout Comment

Do this section at the end when report has a form
\layout Section


\begin_inset LatexCommand \label{sec:Contributions}

\end_inset 

Contributions
\layout Standard


\begin_inset Note
collapsed false

\layout Standard

IMPORTANT: try to re-use this; it's from MICCAI; used to be called Conclusions
 and Contributions
\end_inset 


\layout Standard

Taking a more positive stance, it has been illustrated not only that group-wise
 registration based on appearance model is possible, but also that it surpasses
 registration methods that are based purely on a reference image, as judged
 by the corresponding appearance model.
\layout Standard

The current algorithms are being interpreted rather than compiled and no
 multi-scale approach is yet in use.
 The extension of the algorithms to 2-D and 3-D would require a long time
 to run, but remains practical.
 Compiled implementations might be available within months as well as heuristic
 optimisations that will make run-time more competitive with that of pair-wise
 approaches.
 Furthermore, the results have been shown to be better in a global sense
 and are not dependent on just one individual image.
\layout Standard

Contributions of the work can be subdivided into three aspects:
\layout Enumerate

It provides a benchmark environment and results for many methods, including
 several new ones.
\layout Enumerate

Unprecedented model-based group-wise registration is introduced.
\layout Enumerate

Automatic construction of increasingly better appearance model becomes practicab
le.
 Correspondences are obtained using techniques borrowed from image registration.
 
\layout Section


\begin_inset LatexCommand \label{sec:Final-Discussion}

\end_inset 

Final Discussion
\layout Standard

As described in Chapter 
\begin_inset LatexCommand \ref{cha:Future-Work}

\end_inset 

, the project is now expected to continue along the lines of implementation
 with some reliance on the work and results produced in year one.
 If difficulties often recur, there are various measures that can be taken
 to ensure productive alternatives are chosen.
 The next goal is to obtain dense correspondence across 3-D biomedical data
 using automatic self-instructing algorithms.
 As the project is intended to explore a scarcely known field, caution will
 be taken when time is spent without much potential on the horizon.
\layout Comment

The figure above does not include results obtained from hybrid objective
 functions, although such results have been collected and put on the Web
 site.
\layout Section


\begin_inset LatexCommand \label{sec:Vision}

\end_inset 

Vision
\layout Standard

Given a collection of images describing the same objects, one should be
 able to build a good model autonomously.
 Given sets of images from normals and patients with a common pathology,
 different atlases will be constructed and diagnosis become solvable by
 computers.
\newline 

\newline 

\end_inset 


\layout Standard


\begin_inset Note
collapsed false

\layout Section


\begin_inset LatexCommand \label{sec:General-Progress}

\end_inset 

General Progress
\layout Comment

-Mention excessive work 365 days a year, but phrase it as dedicated work
 on every single day, long hours.
\layout Comment

-Note: this was moved from Experiments section
\layout Standard


\begin_inset ERT
status Open

\layout Standard

\backslash 
lettrine{S}{ everal}
\end_inset 

results have now been shown and discussed, but there are less technical
 matters that must be at least mentioned.
 The establishment of a nave and simple model-based objective function
 was not the main implementation aspect that the author can take credit
 for.
 It was already in place at the beginning of the year, but it lacked many
 of the components that presently make it actually work and achieve good
 results which drive this research onwards.
 Results can now also be obtained rather quickly and flexibly since a front-end
 to the console-based functions was established.
 Technical details about the implementation can be found in the following
 sections on the WWW:
\layout Enumerate


\begin_inset LatexCommand \htmlurl{http://www.danielsorogon.com/Webmaster/Research/NRR}

\end_inset 


\layout Enumerate


\begin_inset LatexCommand \htmlurl{http://www.danielsorogon.com/Webmaster/Research/Model_Based}

\end_inset 


\layout Enumerate


\begin_inset LatexCommand \htmlurl{http://www2.cs.man.ac.uk/~schestr0/Documentation}

\end_inset 


\layout Standard

(1) presents the project's technical aims, (2) explains the algorithms and
 (3) provides a very detailed overview on the application which is called
 AART (also see Figure 
\begin_inset LatexCommand \vref{cap:Autonomous-Appearance-based-Registration}

\end_inset 

).
\layout Standard

Experiments were often performed on several machines to collect different
 results of large registration processes simultaneously.
 Much of the computational power used resided in the Department of Computer
 Science where many of the strong and modern
\begin_inset Foot
collapsed false

\layout Standard

Usually Pentium 4 processor with 256 Megabyte of random access memory (RAM).
 These were not computational servers in essence.
\end_inset 

 \SpecialChar ~
computers laid idly.
\layout Standard

There were some difficulties at getting persistent computational power at
 the very late stages of the year when long-standing clusters of computers
 were stored due to refurbishment work.
 However, that was the point when more theoretical ground was sought, as
 opposed to the analysis of large and cumbersome experiments.
 Such experiments were mainly used to provide apodictic proofs (as described
 in Chapter 
\begin_inset LatexCommand \vref{cha:Experiments}

\end_inset 

).
 Also at that time, work on smaller experiments, which did not concern images,
 became much more appropriate.
\layout Section


\begin_inset LatexCommand \label{sec:Publicity}

\end_inset 

Publicity
\layout Standard

Some preparation and work on paper submission was considered at an early
 stage with the aim of obtaining feedback at the least.
 Furthermore, there was a slim chance of finding a place for the useful
 concepts and methods to be recognised and accepted as valid.
 There was not a high probability of acceptance because all results at the
 time were poor and the text reflected on this.
 The results did not support the premise of the proposed methods of image
 registration.
 The work was still performed in 1-D over synthetic data, making its impact
 futile and the experiments uninteresting.
\layout Standard

In Late February a paper was submitted to Medical Image Computing and Computer-A
ssisted Intervention (MICCAI) 2004.
 It was cautiously recommended for acceptance by only one of the three reviewers.
 The feedback suggested that Guimond 
\emph on 
et al.

\emph default 
 
\begin_inset LatexCommand \cite{Guimond}

\end_inset 

 had performed similar experiments, but the paper suggested otherwise.
 It did not appear as if any groups used models and minimum description
 to guide registration -- neither explicitly nor implicitly.
 Another main unavoidable flaw was the results being available for a 1-D
 case only; no practical medical results were displayed nor discussed (and
 illustration of either one is usually expected by the MICCAI community).
\layout Standard


\begin_inset Note
collapsed false

\layout Standard

Write something about poster, summer schools, etc.
 - DONE
\end_inset 


\layout Standard


\begin_inset Note
collapsed false

\layout Standard

LEFT OUT: 
\begin_inset Quotes eld
\end_inset 

More recently, a revised version of the paper above was submitted to MIUA.
 This happened rather shortly afterwards with the feedback of MICCAI reviewers
 having its impact.
 More importantly, at that stage good result were available to illustrate
 the benefits of the newly-proposed method.
\begin_inset Quotes erd
\end_inset 


\end_inset 


\layout Standard

A poster presentation in the EPSRC summer school in Surrey (Figure 
\begin_inset LatexCommand \ref{cap:poster}

\end_inset 

) attracted a great deal of attention from both the organisers and the attendees.
 It appeared to be a close contender for the best poster prize.
\layout Standard
\align center 

\begin_inset Float figure
wide false
collapsed false

\layout Standard
\align center 

\begin_inset Graphics
	filename ./Graphics/surrey.eps
	display none
	scale 30.00

\end_inset 


\layout Caption


\begin_inset LatexCommand \label{cap:poster}

\end_inset 


\size small 
Down-sized poster.
\end_inset 


\layout Standard


\begin_inset Note
collapsed false

\layout Standard

TODO: Rework this section
\end_inset 


\layout Section


\begin_inset LatexCommand \label{sec:Other-Activities}

\end_inset 

Other Activities
\layout Subsection

Assorted Activities and Contributions
\layout Standard

As this report can be perpetrated a show-case for progress and personal
 endeavour, this section provides an auxiliary note on progress.
 It is also an elaborative note on ways of research conduction from the
 point-of-view which excludes research.
 Below is a roughly random list of activities:
\layout Standard


\begin_inset Note
collapsed false

\layout Standard

1.
 Machine Learning course (AVOID MENTIONING COURSES)
\layout Standard

2.
 Mathematical Methods course
\end_inset 


\layout Itemize

EPSRC Summer School in Surrey attended in June 2004
\layout Itemize

MIUA Summer School in Imperial College to be attended in September 2004
\layout Itemize

Attendance at plenary meetings of the IRC 
\layout Itemize

GSSEM PhD Workshop and other activities and lectures organised by the GSSEM.
\layout Standard


\begin_inset Note
collapsed false

\layout Standard

5.
 Monday research meeting
\end_inset 


\layout Itemize

Contributions to the ISBE Internal Web site.
 
\layout Standard


\begin_inset Note
collapsed false

\layout Standard

2.
 work - conferences, CSS, support pages for LyX and EndNote, etc.
\end_inset 


\layout Itemize

MATLAB repository documentation and contributions to CVS.
\layout Itemize

ISBE-All archiving system constructed.
\layout Standard


\begin_inset Note
collapsed false

\layout Standard

3.
 Wrappers for C++ and MATLAB
\end_inset 


\layout Standard


\begin_inset Note
collapsed false

\layout Standard

1.
 IRC Plenary Meetings (Manchester, Oxford, UCL, Guy's)
\layout Standard

2.
 Collaboration with Carole
\end_inset 


\layout Standard

Some of the later activities can also be seen as contributions.
 Nonetheless, these became merely by-products of documentation for personal
 use.
\layout Standard

I have been working very long hours in the department, estimated at well
 over 60 hours a week.
 The large majority of the time was spent in the early morning and the weekends
 while very little time was spent at home.
\layout Comment

Old there is not much need for the project description notes from the lit-rep.
 Do not forget to recompile properly and send electronic copy...
\layout Comment

...via a link as well as a written and bound one.
 Look at the previous procedures and suggestions written for the lit-rep.
\layout Comment

Old: Written on train to London
\layout Subsection

Miscellaneous Meetings and Collaborations
\layout Standard

A word on mutual and joint work has not been said yet.
 Many of the early experiments on shapes and landmark selection were performed
 in collaboration with Tomos Williams.
 At the later stages, this work was discussed with Rhodri Davies and some
 division of experiments and workload took place.
\layout Standard


\begin_inset Note
collapsed false

\layout Standard

Rhodri
\layout Standard

Carole
\end_inset 


\layout Standard

Collaboration with the structure and function (S&F) group meant that exchange
 of concepts with Carole Twining became mundane.
 Moreover, discussions on developments of the ideas and recent experiments
 (to be potentially work-inspiring) took place on a weekly basis.
\layout Standard

For more accurate listing of various meetings including the Wednesday IRC
 meetings, also see:
\layout Itemize


\begin_inset LatexCommand \htmlurl{http://www.danielsorogon.com/Webmaster/Research/Events/}

\end_inset 


\layout Itemize


\begin_inset LatexCommand \htmlurl{http://www.danielsorogon.com/Webmaster/Research/Meetings}

\end_inset 


\layout Standard

More compressed information and tables are appended 
\begin_inset LatexCommand \vpageref{cha:Appendix-DProgress-Records}

\end_inset 

.
\layout Standard
\align right 

\size large 

\begin_inset Quotes eld
\end_inset 

H
\size small 
appy is he who gets to know the reasons for things.
\begin_inset Quotes erd
\end_inset 


\newline 
-- 
\emph on 
Virgil.
\layout Comment

called Future work plan previously
\layout Comment

CJT in meting: future work needs to be sensible...
 That is a plan for the rest of my project...
 It needs to be an intellectual plans than a detailed timescale and it needs
 to identify...
 For example,..
 Research issues that I need to address!!
\layout Section


\begin_inset LatexCommand \label{sec:Overview}

\end_inset 

Overview
\layout Standard


\begin_inset ERT
status Open

\layout Standard

\backslash 
lettrine{T}{ his}
\end_inset 

 chapter draws a relatively precise picture of future work and possibly
 individual experiments that need to be performed in the course of the next
 year or two.
 It provides some rough guidelines for time, milestones and a loosely-defined
 line of operation that future work needs to take.
 In order to continue experimentation and collaborative chores in an organised
 and productive style, an intellectual plan and a detailed timescale need
 to be identified.
 Possibly, particular emphasis will be put on few specific research issues
 that need to be addressed.
 These issues will be the main lines along which research should move so
 that it is of 
\emph on 
real practical use
\emph default 
.
\layout Standard

There is no real micro-planning involved in this chapter, only a continued
 discussion and survey of assorted (and nonetheless related) items.
\layout Section


\begin_inset LatexCommand \label{sec:Aims}

\end_inset 

Aims
\layout Standard

The aims of the project were formally specified in Form 2 (see Appendix
 
\begin_inset LatexCommand \vref{cha:App C:Year-1-Progress}

\end_inset 

).
 The objectives set for the first year were slightly altered since the time
 of writing of the Literature Report
\begin_inset Foot
collapsed false

\layout Standard

The literature report is located at:
\newline 

\begin_inset LatexCommand \htmlurl{http://www.danielsorogon.com/Webmaster/Research/Literature_Report}

\end_inset 


\end_inset 

.
 While in a rough sense, all objectives set were eventually accomplished,
 more goals and intermediary experiments were proposed and later completed.
 It was known earlier in the year that aims listed in Form 2 cannot be 
\emph on 
necessarily
\emph default 
 the right way to go, but only a formal and inductive set of guidelines.
 This is clearly because of the dependency which one experiment has upon
 another.
 Also, development within the Structure and Function group required attention
 to different aspects of work, as soon as issues began to arise.
 With reference to aims listed in past documents, many of these were not
 at all definite.
 From a non-specific
\begin_inset Foot
collapsed false

\layout Standard

These requirements are intentionally very general.
 They can be applicable to most computer-scientific research.
\end_inset 

 \SpecialChar ~
perspective, it was expected that:
\layout Enumerate

A full reproduction of past experiments should be trivial and possible extension
s realised.
\layout Enumerate

Development of existing code will commence to ultimately build genuine software.
\layout Enumerate

Difficulties should be identified to avoid future impasse.
\layout Enumerate

New practicable experiments should be agreed upon, performed and their results
 recorded.
\layout Enumerate

Comparative figures will show the advancements of new methods.
\layout Enumerate

Critical evaluation of existing work and proposition of new methods will
 hopefully emerge.
\layout Standard

Dealing with each of the above in turn, all previous experiments, as implemented
 by Smith, can be performed within seconds.
 A software package which was constructed was in fact enabling such experiments
 to be analysed in more depth whenever one requires so (referring back to
 Section 
\begin_inset LatexCommand \vref{sec:Environment}

\end_inset 

).
\layout Standard

Future difficulties were identified amongst the Structure and Function group
 and the project supervisor.
 These were frequently recorded and experiments that may suffer from such
 difficulties were avoided.
\layout Standard

The new experiments were shown in previous chapters and comparative figures
 were an integral part of these.
 Not only was a benchmark for commonly-used methods established, but also
 a comparison -- analytic and numeric -- was made .
 Results amongst the different available alternatives justified the use
 of a model-based objective function as well.
\layout Standard

Much more information about progress (and in finer level of detail) can
 be found in the weekly progress report and the sources that these reference.
 Experiment were very usefully put on an HTML-based database
\begin_inset Foot
collapsed false

\layout Standard

Actually, these are hierarchical nested indices of experiments, sorted chronolog
ically.
\end_inset 

 \SpecialChar ~
and can be used as a supplementary resource for this document
\begin_inset Foot
collapsed false

\layout Standard

These have faithfully and quickly served the need to produce figures for
 this report, as well as some of the results which were earlier outlined.
 In fact, the experiments pages can serve as a document of progress in their
 raw state.
 They might require some additional annotation to be legible.
\end_inset 

.
\layout Standard

Proposition of new methods followed the analysis of different mutations
 of the model-based objective functions.
 However, nothing excitingly different or unexpected was discovered.
 It was merely the enhancement and modification of the basic model-based
 objective function that made it more powerful.
\layout Section


\begin_inset LatexCommand \label{sec:Impending-Experiments}

\end_inset 

Impending Work
\layout Standard

This section returns to the explanation of some of the work in progress.
 However, it concentrates on ways of moving forward, i.e.
 ways in which interrupted work is likely to develop.
 While it never will be obvious how experiments shall wind up, it is possible
 to at least propose them and list the expected outcomes, both pessimistically
 and optimistically.
 This is exactly what this section is set to achieve.
\end_inset 


\layout Standard


\begin_inset Note
collapsed false

\layout Standard

Used to be called Impending Experiments (did not fit heading)
\end_inset 


\layout Standard


\begin_inset Note
collapsed false

\layout Section


\begin_inset LatexCommand \label{sec:Future-Milestones}

\end_inset 

Future Milestones
\layout Standard

Milestones for future work on experiments seems a rather good idea.
 The table below does not specify any stringent requirements and does not
 need to be obeyed, yet it can be contributive as future reference.
\layout Standard


\begin_inset Float table
wide false
collapsed false

\layout Standard
\align center 

\begin_inset  Tabular
<lyxtabular version="3" rows="11" columns="2">
<features>
<column alignment="center" valignment="top" leftline="true" rightline="true" width="0">
<column alignment="center" valignment="top" leftline="true" rightline="true" width="0">
<row topline="true" bottomline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard


\series bold 
Experiment(s)
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard


\series bold 
Date to comply with (lenient)
\end_inset 
</cell>
</row>
<row topline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

Speed-up
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

Perpetual
\end_inset 
</cell>
</row>
<row topline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

MDL in models
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

October 2004
\end_inset 
</cell>
</row>
<row topline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

Subsets versus entire set
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

September 2004
\end_inset 
</cell>
</row>
<row topline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

Optimiser investigation
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

October 2004
\end_inset 
</cell>
</row>
<row topline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

Comparison of optimisation regimes
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

November 2004
\end_inset 
</cell>
</row>
<row topline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

Extension to 2-D
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

January 2005
\end_inset 
</cell>
</row>
<row topline="true" bottomline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

Application to 3-D
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

Indefinite
\end_inset 
</cell>
</row>
<row bottomline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

3-D benchmarking
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

Indefinite
\end_inset 
</cell>
</row>
<row bottomline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

Group-specific atlases
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

Hopefully 2005
\end_inset 
</cell>
</row>
<row bottomline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

Automatic appearance models construction
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

Indefinite
\end_inset 
</cell>
</row>
</lyxtabular>

\end_inset 


\layout Caption


\begin_inset LatexCommand \label{cap:year-2-milstones}

\end_inset 


\size small 
Milestones for future experiments.
\layout Comment

(corresponding to this subsection)
\end_inset 


\layout Comment

Maybe Gantt chart
\layout Comment

CJT: Milestones for future that are not strict is a good idea.
\end_inset 


\layout Standard


\begin_inset Note
collapsed false

\layout Chapter
\pagebreak_top 

\noun on 

\begin_inset LatexCommand \label{cha:Summary}

\end_inset 


\begin_inset LatexCommand \index{Summary}

\end_inset 


\noun default 
Results of Model Evaluation
\layout Standard
\align right 

\size large 

\begin_inset Quotes eld
\end_inset 

W
\size small 
e know nothing in reality; for truth lies in an abyss.
\begin_inset Quotes erd
\end_inset 


\newline 
-- 
\emph on 
Democritus.
\layout Standard


\begin_inset Note
collapsed false

\layout Standard

RSS: Rewrite this and connect to quote below...
\end_inset 


\layout Standard
\align right 

\size large 

\begin_inset Quotes eld
\end_inset 

S
\size small 
cience does not know its debt to imagination.
\begin_inset Quotes erd
\end_inset 


\newline 
-- 
\emph on 
Ralph Waldo Emerson,
\layout Standard


\begin_inset Note
collapsed false

\layout Standard

THESIS: Below are the sections that in June seemed to be good for a thesis.
\end_inset 


\layout Chapter
\pagebreak_top 

\noun on 

\begin_inset LatexCommand \label{cha:Summary}

\end_inset 


\begin_inset LatexCommand \index{Summary}

\end_inset 


\noun default 
Perturbation of Registered Data
\layout Standard


\begin_inset Note
collapsed false

\layout Standard

do not forget quotes in chapters
\end_inset 


\layout Chapter
\pagebreak_top 

\noun on 

\begin_inset LatexCommand \label{cha:Summary}

\end_inset 


\begin_inset LatexCommand \index{Summary}

\end_inset 


\noun default 
Results of Registration Assessment
\layout Standard
\align right 

\size large 

\begin_inset Quotes eld
\end_inset 

I
\size small 
f you're not part of the solution, you're part of the precipitate.
\begin_inset Quotes erd
\end_inset 


\newline 
-- 
\emph on 
Henry J.
 Tillman.
\layout Standard


\begin_inset ERT
status Open

\layout Standard

\backslash 
lettrine{T}{ this}
\end_inset 

 thesis.....
\layout Standard


\begin_inset Note
collapsed false

\layout Standard

some one paragraph here...
\layout Standard

Sections should be grafted from continuation report.
 Some sections in this file (thesis.lyx) are predicting a more suitable structure.
\end_inset 


\layout Section

Relation to model-building
\layout Section

Perturbations
\layout Standard

in appendix?
\layout Section

Overlap measures
\layout Section

Comparison of methods
\layout Chapter
\pagebreak_top 

\noun on 

\begin_inset LatexCommand \label{cha:Summary}

\end_inset 


\begin_inset LatexCommand \index{Summary}

\end_inset 


\noun default 
Future Exploration
\layout Section

Normalisation (if not done yet)
\layout Section

3-D extension
\layout Standard

(efficiency, AAM construction is fine)
\layout Chapter
\pagebreak_top 

\noun on 

\begin_inset LatexCommand \label{cha:Summary}

\end_inset 


\begin_inset LatexCommand \index{Summary}

\end_inset 


\noun default 
Conclusions
\layout Standard
\align right 

\size large 

\begin_inset Quotes eld
\end_inset 

R
\size small 
esearch is what I'm doing when I don't know what I'm doing.
\begin_inset Quotes erd
\end_inset 


\newline 
-- 
\emph on 
Wernher Von Braun.
\layout Standard


\begin_inset ERT
status Open

\layout Standard

\backslash 
lettrine{O}{ ne}
\end_inset 

ppendices to follow
\layout Section

AAM and Registration resemblance
\layout Section

Registration minimises model
\layout Section

Perturbation method
\layout Section

...
\layout Section

Active Appearance Models
\layout Standard

ijuhiuhui
\end_inset 


\layout Standard


\begin_inset Note
collapsed false

\layout Standard

RSS 2004: Rewrite this and connect to quote below...
\layout Standard

2005: Remember quote at end or remove it
\end_inset 


\layout Standard


\begin_inset Note
collapsed false

\layout Standard
\pagebreak_top 

\noun on 
Using Residuals in Shape
\layout Standard
\align right 

\begin_inset Quotes eld
\end_inset 

Stupid is as Stupid Does
\begin_inset Quotes erd
\end_inset 


\newline 
-- 
\emph on 
Forrest Gump
\layout Section

Explain here about how Davies' obj.
 func.
 is improved.
 Explain about all work which was done on shape
\layout Standard
\pagebreak_top 

\noun on 
Improving efficiency of Shape Optimisation
\layout Standard
\align right 

\begin_inset Quotes eld
\end_inset 

Stupid is as Stupid Does
\begin_inset Quotes erd
\end_inset 


\newline 
-- 
\emph on 
Forrest Gump
\layout Section

Explain if speed is increased by changing precision.
 Also refer to subsets, etc.
\layout Standard
\pagebreak_top 

\noun on 
Registration using Models
\layout Standard
\align right 

\begin_inset Quotes eld
\end_inset 

Stupid is as Stupid Does
\begin_inset Quotes erd
\end_inset 


\newline 
-- 
\emph on 
Forrest Gump
\layout Standard
\pagebreak_top 

\noun on 
Objective function for Images 
\layout Standard
\align right 

\begin_inset Quotes eld
\end_inset 

Stupid is as Stupid Does
\begin_inset Quotes erd
\end_inset 


\newline 
-- 
\emph on 
Forrest Gump
\layout Standard
\pagebreak_top 

\noun on 
Point Insertion etc.
\layout Standard


\begin_inset Quotes eld
\end_inset 

Stupid is as Stupid Does
\begin_inset Quotes erd
\end_inset 


\newline 
-- 
\emph on 
Forrest Gump
\layout Standard
\pagebreak_top 

\noun on 
Summary
\layout Standard
\align right 

\begin_inset Quotes eld
\end_inset 

Stupid is as Stupid Does
\begin_inset Quotes erd
\end_inset 


\newline 
-- 
\emph on 
Forrest Gump
\layout Standard
\pagebreak_top 

\noun on 
Conclusions
\layout Standard
\align right 

\begin_inset Quotes eld
\end_inset 

Stupid is as Stupid Does
\begin_inset Quotes erd
\end_inset 


\newline 
-- 
\emph on 
Forrest Gump
\layout Standard
\pagebreak_top 

\noun on 
Future Work
\layout Standard
\align right 

\begin_inset Quotes eld
\end_inset 

Stupid is as Stupid Does
\begin_inset Quotes erd
\end_inset 


\newline 
-- 
\emph on 
Forrest Gump
\layout Standard
\pagebreak_top 

\noun on 
Summary
\layout Standard
\pagebreak_top 

\noun on 

\begin_inset LatexCommand \index{Appendices Index}

\end_inset 


\begin_inset LatexCommand \label{cha:Appendices-Index}

\end_inset 

Appendices Index
\layout Standard
\align right 

\size large 

\begin_inset Quotes eld
\end_inset 

N
\size small 
othing is so simple that it cannot be misunderstood
\begin_inset Quotes erd
\end_inset 


\newline 
-- 
\emph on 
Jr.
 Teague.
 
\layout Standard


\begin_inset  Tabular
<lyxtabular version="3" rows="15" columns="2">
<features>
<column alignment="center" valignment="top" width="0">
<column alignment="center" valignment="top" width="0">
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard


\series bold 
\size large 
Appendix A
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard

.
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 \SpecialChar ~

\begin_inset LatexCommand \pageref{cha:Appendix-AElaboration-on}

\end_inset 


\end_inset 
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard

\end_inset 
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard


\series bold 
\size large 
Appendix B
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard

.
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 \SpecialChar ~

\begin_inset LatexCommand \pageref{cha:Appendix-BProject-Descrition}

\end_inset 


\end_inset 
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard

\end_inset 
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard


\series bold 
\size large 
Appendix C
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard

.
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 \SpecialChar ~

\begin_inset LatexCommand \pageref{cha:App C:Year-1-Progress}

\end_inset 


\end_inset 
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard

\end_inset 
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard


\series bold 
\size large 
Appendix D
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard

.
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 \SpecialChar ~

\begin_inset LatexCommand \pageref{cha:Appendix-DAART-Doc}

\end_inset 


\end_inset 
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard

\end_inset 
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard


\series bold 
\size large 
Appendix E
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard

.
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 \SpecialChar ~

\begin_inset LatexCommand \pageref{cha:Appendix-DProgress-Records}

\end_inset 


\end_inset 
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard

\end_inset 
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard


\series bold 
\size large 
Appendix F
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard

.
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 \SpecialChar ~

\begin_inset LatexCommand \pageref{cha:Appendix-EList-of}

\end_inset 


\end_inset 
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard

\end_inset 
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard


\series bold 
\size large 
Appendix G
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard

.
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 \SpecialChar ~

\begin_inset LatexCommand \pageref{cha:Appendix-FAdditional-Resources}

\end_inset 


\end_inset 
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard

\end_inset 
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard


\series bold 
\size large 
Appendix H
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard

.
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 .
 \SpecialChar ~

\begin_inset LatexCommand \pageref{cha:Primary-On-Line-Resources}

\end_inset 


\end_inset 
</cell>
</row>
</lyxtabular>

\end_inset 


\end_inset 


\layout Standard


\begin_inset Note
collapsed false

\layout Chapter


\noun on 

\begin_inset LatexCommand \index{Elaboration on Appearance Models}

\end_inset 


\begin_inset LatexCommand \label{cha:Appendix-AElaboration-on}

\end_inset 


\noun default 
Calculation of Model Complexity
\layout Standard
\align right 

\size large 

\begin_inset Quotes eld
\end_inset 

S
\size small 
cience does not know its debt to imagination.
\begin_inset Quotes erd
\end_inset 


\newline 
-- 
\emph on 
Ralph Waldo Emerson,
\layout Comment

CJT in meeting: Real time stuff might not be relevant
\layout Comment

not worth reviewing applications
\layout Comment

SECTION FROM LIT-REP: REMOVE THIS, BUT KEEP REFERENCES - CHRIS SAYS IT IS
 NOT TOO IMPORTANT: 
\layout Comment


\begin_inset Note
collapsed false

\layout Standard


\begin_inset ERT
status Open

\layout Standard

\backslash 
lettrine{O}{ ne}
\end_inset 


\noun on 
his
\noun default 
 short section describes some of the applications and extensions of shape
 and appearance models.
 These are all of little relevance, if any, to the project under consideration.
\layout Section*

Real-time Active Appearance Models
\layout Standard

Some machines are able to deal with small-sized fitting in real-time 
\begin_inset LatexCommand \cite{Ahlberg,Hansen}

\end_inset 

.
 It is possible to track faces in a video (frame rate should then typically
 be 24 frames/second and 15 at the minimum), but the resolution catered
 for is often relatively low (less than 100x100 pixel).
 Applications that respond so quickly were made far more practical owing
 to a multi-resolution (multi-scale) approach (see 
\begin_inset LatexCommand \ref{cap:Multi-res}

\end_inset 

 below).
 In order to decrease the total run-time, varying increasing image resolutions
 become available for selection at each search iteration.
 Finer resolution images are usually used at the later stages of the search,
 whereas low-resolution (coarse) ones at the very start.
 Since the similarity between the model and the target is poor ab ovo, the
 resolution (and hence the scale of the objects) will have little effect
 on the fitting.
 Some visual examples of AAM search are shown in 
\begin_inset LatexCommand \cite{atlas_aam}

\end_inset 

.
\layout Standard

An additional advantage that a multi-resolution approach offer is its notable
 improvement of structures.
 It even allows fitting to be more robust to large displacements from the
 target.
 This is due to its treatment of a large image as if it was a smaller one
 -- one in which structures are represented by a smaller number of pixels.
\layout Standard


\begin_inset Float figure
wide false
collapsed false

\layout Standard
\align center 

\begin_inset Graphics
	filename ./Graphics/pyramid.eps
	display none
	scale 70.00

\end_inset 


\layout Caption


\begin_inset LatexCommand \label{cap:Multi-res}

\end_inset 


\size small 
A multi-resolution approach illustrated.
 Coarser representations are shown at the top levels and the original image
 lies at the bottom.
\end_inset 


\layout Standard


\begin_inset Note
collapsed false

\layout Standard

CJT: NOT VERY CLEAR ; MULTI-RES IMPROVES STRUCTURES AND WELL AS SPEED --
 ADDED ABOVE
\end_inset 


\layout Comment

CHRIS SAYS THIS IS NOT IMPORTANT
\layout Section*

Other Applications
\layout Standard

Very common uses of AAM's are for medical image analysis and face recognition
\begin_inset Foot
collapsed false

\layout Standard

Much of the popularity of this method has been imputed to face recognition
 tasks.
\end_inset 

.
 Active appearance models possess traits that make them robust and effective
 in the biological domain, whereas industrial inspection, for example, presents
 some inherently different problems.
 These problems are often solved more rapidly by other approaches that are
 based on lower-level knowledge about the image contents.
 Since a broad range of tasks are performed in industrial inspection, however,
 it is also valid to assume that the suitability of top-down approach is
 irrespective of the problem.
 Nonetheless, there has been some successful application of these methods
 to the analysis and segmentation in printed boards.
 Kestra have been doing some successful work in this domain, though it is
 not a main-stream application of statistical models as yet.
\begin_inset Note
collapsed false

\layout Standard

CJT: HAVE ALSO BEEN USED FOR INDUSTRIAL INSPECTION....
 RSS: KESTRA MAYBE? CHIPS? -- DONE - AT LEAST MENTIONED NOW
\end_inset 


\layout Standard

In order to visualise biological shapes and full appearances, a model which
 handles anatomical variability and change needs to be used.
 It must account for natural or pathological changes such as the change
 in form of organs (atlases for different pathologies are suggested in 
\begin_inset LatexCommand \cite{atlases_disease_specific}

\end_inset 

).
 Greater variability can be encountered when aligned images are obtained
 from different subjects in a population (inter-subject), the same subject
 at different time instances (or different sites) or when having to account
 for movement such as the that which occurs due to respiration, the cardiac
 cycle and so forth.
 A separate case to consider is multi-modal imaging which will not be explained
 in any detail although it is a quickly-developing area.
\layout Standard

For an excellent overview on many of the different image analysis techniques,
 the book from Sonka 
\emph on 
et al.

\emph default 
 
\begin_inset LatexCommand \cite{sonka}

\end_inset 

 is a valuable source.
 For a good review of model-based image analysis, papers from Cootes 
\emph on 
et al.

\emph default 
 are an even better source.
 Related and similar insights can be derived from work partially based on
 concepts such as snakes, bending-energy and active contours.
 Such conceptual approaches, 
\begin_inset Note
collapsed false

\layout Standard

along with the chapter on shape models
\end_inset 

 are closely-related to active shape models.
 Sonka 
\emph on 
et al.

\emph default 
 discuss all of these in depth.
\layout Standard


\begin_inset Note
collapsed false

\layout Standard

CJT: WHOLE PARAGRPAH IS QUESTION MARK - RSS: I rewrote some of the statements
 that were doubtful.
\layout Standard

as in project description
\end_inset 


\layout Section*


\begin_inset LatexCommand \label{sec:PCA-Alternative}

\end_inset 

PCA Alternative
\layout Standard

A recently published technique is said to be capable of finding good dense
 correspondence.
 It is described by Tony Jebara.
 Images are said to be better represented as sets of vectors for this specific
 purpose, as opposed to vectorisation where fixed ordering is imposed by
 
\emph on 
concatenation
\emph default 
 of the vectors.
 Pixels are represented by the common 
\begin_inset Formula $(X,Y,I)$
\end_inset 

 tuple and the ordering of these tuples is arbitrary (they are said to analogica
lly be placed in a bag so an alternative notion would be 
\emph on 
sets of pixel
\emph default 
).
 Ways exist in which good configurations for ordering these pixels can be
 found.
 This implies that vectorisation of the pixels is not the sole option for
 effective image representation.
 As the process of pixel ordering takes place, dimensionality reduction
 is indirectly performed which transforms the image into a volumetrically
 minimal subspace and this reduction outperforms principal component analysis
 by orders of magnitude.
 This is one of the points that make this idea so appealing, but it is still
 extremely slow
\begin_inset Foot
collapsed false

\layout Standard

The algorithms currently used for demonstration purposes take 3 days to
 run, but substantial speed-up is expected soon.
\end_inset 

.
\layout Standard

Figure 
\begin_inset LatexCommand \ref{cap:Bag-of-Pixels}

\end_inset 

 pictures the difference between a common approach of pixel ordering versus
 the alternative bag of pixels.
\layout Standard


\begin_inset Float figure
wide false
collapsed false

\layout Standard
\align center 

\begin_inset Graphics
	filename ./Graphics/bag.eps
	display none
	scale 70.00

\end_inset 


\layout Caption


\begin_inset LatexCommand \label{cap:Bag-of-Pixels}

\end_inset 


\size small 
Bag of pixels illustrated versus one conventional approach.
\end_inset 


\end_inset 


\layout Chapter
\pagebreak_top 

\noun on 

\begin_inset LatexCommand \index{Project in Detail}

\end_inset 


\begin_inset LatexCommand \label{cha:Appendix-BProject-Descrition}

\end_inset 


\noun default 
More on Model Evaluation
\layout Standard


\begin_inset Note
collapsed false

\layout Standard


\begin_inset ERT
status Open

\layout Standard

\backslash 
lettrine{O}{ ne}
\end_inset 


\noun on 
his
\noun default 
 appendix describes in some finer detail the past work.
 Such work led to and supported current research which this report describes.
\layout Standard


\begin_inset Note
collapsed false

\layout Standard


\begin_inset Formula $Maybe$
\end_inset 

 put some vague past work text here...
 the one from lit.
 rep.
\end_inset 


\layout Section


\begin_inset LatexCommand \label{sec:Existing-Work-(Active}

\end_inset 

Overview
\layout Standard


\noun on 

\begin_inset Note
collapsed false

\layout Standard

used to be methods- to be moved to Appendices.
 -- ignore please
\end_inset 


\layout Standard

Active appearance models and non-rigid registration were attempted to be
 unified for a period of time before the author's undertaking of the project.
 The following is an overview on the work of Smith from which current developmen
ts stemmed.
\layout Standard


\begin_inset Note
collapsed false

\layout Standard

This is not accurate or precise (this section)
\end_inset 


\layout Subsection

Description of the Approach
\layout Standard


\begin_inset Note
collapsed false

\layout Standard

Left out: 'This was not the first time that such an approach was investigated
 as Subsection 4.4 (COMMENT) shows.'
\end_inset 


\begin_inset Note
collapsed false

\layout Standard

CJT:This last sentence is not correct -- RSS: I commented it out
\end_inset 


\layout Standard

The images after warping had been applied were treated as training data
 for the creation of an appearance model.
 PCA reduced the complexity of that model as required.
 The compactness of the model which could be derived from the the sum of
 variances or the determinant of the covariance matrix
\begin_inset Foot
collapsed false

\layout Standard

This will indicate the 
\emph on 
volume 
\emph default 
of the model's scatter in space.
 The more compact a model appears, the lower this volume.
 More importantly, it is an approximation to the MDL objective function.
\begin_inset Note
collapsed false

\layout Standard

CJT: But more importantly it is an approximation to the MDL objective function;
 RSS: added to footnote
\end_inset 


\end_inset 

 \SpecialChar ~
was then scoring the choice of warps after they had been applied.
 In this way, a better choice of warps could be made so that bad ones quickly
 get discarded and the state of all affected images reverted.
\layout Subsection

Synopsis
\layout Standard

As the above descriptions tacitly suggest, this work was able to show how
 statistical models go hand-by-hand with non-rigid registration.
 In this case, they simple 
\emph on 
evaluated 
\emph default 
the (non-rigid) registration process and distinguished between the many
 alternatives offered by different families of warps, similarity measures
 and so forth.
 Needless to say, the run-time became a real difficulty when ill-chosen
 strategies were attempted.
 Smith took this into consideration in the final evaluation and comparison
 of all different experiments.
\layout Subsection

Concurrent Advancements
\begin_inset LatexCommand \label{sub:Concurrent-Advancements}

\end_inset 


\layout Standard

The work of Marsland, Twining and Taylor 
\begin_inset LatexCommand \cite{Marsland_MICCAI_2003}

\end_inset 

 went a step ahead and investigated a full 2-D model
\begin_inset Foot
collapsed false

\layout Standard

It also used proper MDL terms rather than an approximation as Smith did.
\end_inset 

.
 However, it concentrated on just a simple contour (defined by 12 control
 points) of the skull shape as pictured from an overhead perspective.
 Figure 
\begin_inset LatexCommand \ref{cap:Brain-image-warping(}

\end_inset 

 shows that warps can have an effect on the 
\emph on 
whole 
\emph default 
shape, but still lack some control over local structures such as the ventricles.
 Varying scale can solve problems like this and make the global non-rigid
 registration approach very robust.
 While this work produced elegant results, it did not explore many varying
 options as in the case of Smith.
\layout Standard


\begin_inset Float figure
wide false
collapsed false

\layout Standard
\align center 

\begin_inset Graphics
	filename ./Graphics/brain.eps
	display none
	scale 70.00

\end_inset 


\layout Caption


\begin_inset LatexCommand \label{cap:Brain-image-warping(}

\end_inset 


\size small 
Brain image warping.
 Points on the skull depict knot-points for the splines.
\size default 

\begin_inset Note
collapsed false

\layout Standard

RSS: ( images from Twining and Marsland?).
 UPDATE RSS: Not so!
\end_inset 


\end_inset 


\layout Subsection

Drawbacks
\layout Standard

Drawbacks and gaps do exist and controversial implementation decisions are
 listed later in this appendix.
 There is much work to be done in order to find out which the better performing
 approaches are and the experiments and applications described above provide
 a substantial starting-point.
\layout Standard


\begin_inset Note
collapsed false

\layout Standard

B.1.6 Alternatives -- old subsection
\end_inset 


\layout Section


\begin_inset LatexCommand \label{sec:Alternatives}

\end_inset 

Alternatives
\layout Standard

The main alternatives to non-rigid registration are rigid and affine equivalents
, but these are merely impractical.
 In most real-world applications such as registration of brain-slice images,
 there is a very slim chance of getting satisfactory alignment of structures
 while preserving some continuity unless non-rigid transformations are applied.
 One may argue that affine registration should suffice, but what if parts
 of the brain expand beyond proportion? It therefore appears as if, from
 a registration point-of-view, no obvious alternatives are yet known.
 The ones mentioned above give the best performance yet and comparison with
 the closely-related active appearance models suggests that flexible deformation
 is mandatory, especially for bio-medical data.
 Nonetheless, one could argue that there should be more than just a single
 alternative to be looked at and many different aspects call for attention
 as the earlier parts explain.
 Here is a short summary that may help guide future endeavours
\begin_inset Foot
collapsed false

\layout Standard

Although none of the points is far-fetched, not a single one of them proposes
 an unfamiliar approach; and yet, an open mind is the key to advancements.
\end_inset 

:
\layout Standard


\begin_inset Note
collapsed false

\layout Standard

Merge with the above.
 --DONE
\end_inset 


\layout Enumerate


\series bold 
Speed-up: 
\series default 
The methods operate very slowly for most globally-driven approaches.
 A solution to this is desirable because not only would it stimulate more
 experiments and experiment feedback, but it would also make these methods
 usable and marketable.
\layout Enumerate


\series bold 
Data extension:
\series default 
 The simple existing bump which is generated in MATLAB needs to be extended,
 possibly by conversion to a smoother bump as the one described in the research
 of Davies and Taylor.
\layout Enumerate


\series bold 
Lambda
\series default 
 
\series bold 
coefficient
\series default 
: In practice, when constructing an appearance model for registration's
 sake, an additional weight is assigned to one of two related components.
 The first component is associated with the reparameterisation curve and
 the second corresponds to data values, i.e.
 intensities.
 This weighting term, denoted by Lambda (symbolically 
\begin_inset Formula $\lambda$
\end_inset 

) in the objective function, essentially weighs appearance against shape
 and its value is subjective and dependent upon the problem.
 Experiments can find (and have found before in Smith's work) alternative
 solutions or better assignments for lambda.
\begin_inset Note
collapsed false

\layout Standard

CJT: You didn't explain this before; RSS: I expanded with an explanation.
\end_inset 


\layout Enumerate


\series bold 
Automation: 
\series default 
It would be desirable to create a (compilable) system that copes with the
 full cycle of analysis without outside intervention and without any pre-existen
t data annotation.
 This relates to the strands of artificial intelligence and autonomous systems.
\layout Enumerate


\series bold 
Generalisation:
\series default 
 Many 
\emph on 
ad-hoc
\emph default 
 algorithms are currently used for group-wise registration.
 An more impressive system would deal with arbitrary data without compromise
 to the quality of the results.
\layout Comment

Old: Explain what can be improved, i.e.
 choice of Lambda that will combine the above AAM composites better.
\layout Section


\begin_inset LatexCommand \label{sec:Relevance}

\end_inset 

Relevance
\layout Standard

Along the lines of past research, the possible developments and gains all
 appear to offer various advantages to this system of registration and analysis.
 Unlike many other such projects, this one is open-ended and is dependent
 on the outcomes, discussions and discoveries communicated or published
 in conjunction to one another.
 As a group effort is expected, a high level of interaction and communication
 will be involved.
 This has clearly been the case to date.
 It is important to note that this research is also of relevant to other
 on-going research that takes place locally.
\layout Comment

Relevance of the work can occasionally be confirmed by peers and the more
 dominant figures of authority.
\layout Comment

How relevant is my research to the field? How does it fit together?
\layout Section


\begin_inset LatexCommand \label{sec:Significance}

\end_inset 

Significance
\layout Standard

If this research reaches and obtains its goals, more theoretical and practical
 grounds will be available for future applications of non-rigid registration
 in active appearance models and vice versa.
 
\begin_inset Note
collapsed false

\layout Standard

CJT: There are arguably more papers on AAM's than on ASM's in medical applicatio
n than any other topic (except perhaps NRR) -- RSS: I took out the sentence
\end_inset 


\begin_inset Note
collapsed false

\layout Standard

Left out: 
\begin_inset Quotes eld
\end_inset 

Such goals are quite important as appearance models have not yet become
 as wide-spread as one could argue they should be.
\begin_inset Quotes erd
\end_inset 


\end_inset 

 By making real use of the intensity information that is available in appearance
 models, an exceptional practical strength can be exploited.
 Full image synthesis is an application where no other model type can yet
 be seen as a substitute.
 With more automation in place, higher accuracy, compatibility with other
 technologies, awareness and the like, ultimately, ubiquitous use of the
 technique can be (optimistically) anticipated.
\layout Standard

It is worth pointing out that availability of active appearance models to
 individuals who deal with registration of images would take this technology
 one step ahead.
 This will introduce more concepts, metrics and studies which increase their
 functionality and flexibility.
 Reciprocally, previously 
\begin_inset Quotes eld
\end_inset 

foreign
\begin_inset Quotes erd
\end_inset 

 techniques can extend the functionality of active appearance (and maybe
 shape) models once they are put in the hands of groups with difference
 background and expertise.
 
\layout Standard

As an instance for the first of the two contributions above, a radiologist
 could very comfortably view a highlighted model of an organ that is deformed
 in a natural and sound manner.
 Results and analysis can be managed rather quickly and neatly as automation
 and synthesis generation should be made operable and even interactive
\begin_inset Foot
collapsed false

\layout Standard

A reasonable response time depends on the purpose of the system, the level
 of detail, etc.
\end_inset 

.
\layout Section


\begin_inset LatexCommand \label{sec:Developments}

\end_inset 

Developments
\layout Standard

This section summarises some of the previous preliminary developments; these
 are developments which were made before recent experiments to be listed
 in Chapter 
\begin_inset LatexCommand \vref{cha:Experiments}

\end_inset 

 of this report.
\layout Standard

The simple data used by Smith was proving slightly too cumbersome for responsive
 experimentation on a relatively strong machine (1.8 GHz, 512MB RAM), especially
 owing to the complex algorithms devised for group-wise registration.
 It was at that point advisable that evaluation via profiling toolkits was
 made to hasten the process as much as possible.
 Alternatively, coding of the algorithm in a compiled language as C++ was
 seriously looked at as a possibility.
 The complexity of the departmental VXL library was believed to make a step
 as such less than desirable and no such development has ever been made
 thus far.
\layout Standard

Once speed-up had been taken care of or when it was at least known that
 a nearly flawless well-performing piece of software was at the user's disposal
 (and one which was under control), the simple 1-D data could see the addition
 of a few additional characteristics.
 That new composite
\begin_inset Foot
collapsed false

\layout Standard

It will be prematurely assumed that the new 
\emph on 
synthetic 
\emph default 
data type possesses several distinct morphological attributes.
\end_inset 

 \SpecialChar ~
data had to retain some good commonality and similarity across the set
 of images and it could not be overly more complex and unpredictable in
 comparison with a simple bump.
 A double-humped curve, a round smooth line or even a contour of a a profile
 of a face could be sensible and more challenging choices
\begin_inset Foot
collapsed false

\layout Standard

Some discussions also suggested that data should be similar to that used
 in Davies' thesis, i.e.
 a bump on top of a rectangular brick.
 Analysis based on current understanding then becomes viable too.
\end_inset 

.
 In any case, whichever synthesis of data was eventually selected and experiment
ed with, the choice of control points for the warping then became a more
 crucial issue
\begin_inset Foot
collapsed false

\layout Standard

Warps placement truly seemed tactless and poor at the time, but this needed
 to be confirmed by actual evidence.
\end_inset 

.
 A more localised control via warps then turned into a mandatory one because
 several separate structures exist in the data.
\layout Standard

The experiments of Marsland, Twining and Taylor had already shown the realistic
 application of warps to a medium-resolution two-dimensional data.
 Nonetheless, it was vital to point out that an elliptical shape was dealt
 with and 
\emph on 
a priori 
\emph default 
knowledge of the problem was used to increase the speed of the group-wise
 registration process.
 Control points that characterise the warps were initially placed on a circle
 whose centre was the image centre and radius corresponded to the typical
 position of the skull in standardised imaging.
 If the problem involved point selection for, let us say, knee cartilage
 and no knowledge about the object was available in advance, the results
 would have then taken far more than 10 hours to obtain (as was the case
 for the 12 points distribution around the skull's exterior).
 Edge detection is quite useful in an application of this kind.
 It was highly useful in the case of the skull data, but finding edges that
 form a circle (confer Hough transform) as in a skull is somewhat of a simplifie
d problem.
 Subsequent developments should aim to address many issues exhibiting resemblanc
e to aforementioned ones.
\layout Section


\begin_inset LatexCommand \label{sec:Challenging-Issues}

\end_inset 

Challenging Issues
\layout Standard


\begin_inset Note
collapsed false

\layout Standard

This section is probably out-of-date, but left in anyway because it's in
 an appendix and might not be read.
\end_inset 


\layout Standard

There are several issues that cannot be ignored and should therefore be
 systematically listed.
 Here is a brief unordered list of issues that appear to induce uncertainties
 and confusion:
\layout Enumerate

A sequential series of warps is often an expensive step that results in
 poor productivity.
\layout Enumerate

There is a wide range of warps and there is no consent on which the most
 effective ones are.
 
\layout Enumerate

The existing algorithms are very slow and require long periods of waiting
 time until constructive feedback is received.
\layout Enumerate

An existing system that sometimes struggles with one-dimensional data is
 required to be extended to 2-D and preferably 3-D too.
\layout Enumerate

The data handled by the existing approach tends to be excessively simple.
 Feasibility of such an approach in complex applications is still unknown.
\layout Enumerate

Medical imaging requires high fidelity and reliability.
 Unfortunately, the output from inner-body imaging has a significantly low
 SNR
\begin_inset Foot
collapsed false

\layout Standard

The signal-to-noise ratio in medical images can be lower by orders of magnitude
 in comparison with visual images.
\end_inset 

; this conflicts with the fidelity requirement.
 The accuracy of this approach, e.g.
 the establishment of correspondence, is then unsatisfactory for some of
 the more critical procedures.
 This is exactly why true group-wise registration is important.
 
\begin_inset Note
collapsed false

\layout Standard

CJT: This is exactly why true group-wise is important -- Added to text.
\end_inset 


\layout Enumerate

There is often little knowledge about the structures in an image and random
 warps are then the only reasonable choice, resulting in a slow process.
 Solutions might come up in the form of bottom-up analysis of an unknown
 image.
\layout Standard


\begin_inset Note
collapsed false

\layout Standard

8.
 Unanimous choice of warps type and choice of default complexity for the
 warps is missing.
 Therefore, uncertainty looms over the real performance capabilities, group-wise
 optimisation being a main concern.
\end_inset 


\begin_inset Note
collapsed false

\layout Standard

CJT: No.
 This is not really the issue.
 The real issue is how to solve the problem in a provably correct way.
 RSS: Took that out
\end_inset 


\layout Standard

It is expected that many of the issues above will wind up being taken into
 consideration.
 They may affect the feasibility of the project, lead to failures or halt
 the pursuit for the original aims
\begin_inset Foot
collapsed false

\layout Standard

Chapter 
\begin_inset LatexCommand \ref{cha:Project-Goals}

\end_inset 

 was bound to take a pessimistic point-of-view to describe worst-case scenarios.
 A more optimistic contemplation would have discussed the obtainable goals
 and the factors that make these goals arduous if not impossible to reach.
\end_inset 

.
\layout Standard


\begin_inset Note
collapsed false

\layout Standard

The next chapter proceeds to outlining the plan that will be adhered to
 throughout the forthcoming year.
\end_inset 


\end_inset 


\layout Chapter
\pagebreak_top 

\noun on 

\begin_inset LatexCommand \index{AART Application Documentation}

\end_inset 


\begin_inset LatexCommand \label{cha:Appendix-DAART-Doc}

\end_inset 


\noun default 
Perturbation Framework in Depth
\end_inset 


\layout Standard


\begin_inset Note
collapsed true

\layout Standard


\begin_inset ERT
status Open

\layout Standard

\backslash 
lettrine{O}{ ne}
\end_inset 


\noun on 
ome
\noun default 
 comprehensive and detailed documentation is available on-line at:
\layout Standard


\begin_inset LatexCommand \htmlurl{http://www2.cs.man.ac.uk/~schestr0/Documentation/}

\end_inset 


\layout Standard

In 
\begin_inset LatexCommand \ref{cap:AART-dependencies_struct}

\end_inset 

 below lies an image which depicts the structure of the application.
 It should hopefully provide a reflection of the healthy nature of existing
 dependencies.
\layout Standard
\pagebreak_bottom \align center 

\begin_inset Float figure
wide false
collapsed false

\layout Standard
\align center 

\begin_inset Graphics
	filename ./Graphics/aart_structure.eps
	scale 50.00

\end_inset 


\layout Caption


\begin_inset LatexCommand \label{cap:AART-dependencies_struct}

\end_inset 


\size small 
The dependencies structure of AART.
\end_inset 


\layout Standard

Some statistics on AART:
\layout LyX-Code

Number of  files:         449
\layout LyX-Code

Number of directories:    68
\layout LyX-Code

Total size:               3099 KBytes
\layout LyX-Code

Estimated original LOC:   20,000
\layout LyX-Code

\layout Standard

Corresponding statistics for work on landmark selection:
\layout LyX-Code

Number of  files:         11
\layout LyX-Code

Number of directories:    5
\layout LyX-Code

Total size:               126 KBytes
\layout LyX-Code

Estimated original LOC:   300
\layout Standard

Also to see:
\layout Standard


\begin_inset LatexCommand \htmlurl{http://www.danielsorogon.com/Webmaster/Projects/AART}

\end_inset 


\layout Standard


\begin_inset LatexCommand \htmlurl{http://www.danielsorogon.com/Webmaster/Projects/MDLGUI}

\end_inset 


\end_inset 


\layout Standard


\begin_inset Note
collapsed true

\layout Standard
\pagebreak_top 

\noun on 

\begin_inset LatexCommand \label{cha:App C:Year-1-Progress}

\end_inset 


\begin_inset LatexCommand \index{Year One Progress}

\end_inset 

Year One Progress
\layout Section*


\begin_inset LatexCommand \label{sec:Form-2}

\end_inset 

Form 2
\layout Standard


\series bold 
\bar under 
Date of meeting:
\series default 
\bar default 
 December 15th, 2003.
\newline 

\newline 

\layout Standard
\align center 

\series bold 
\size large 
RESEARCH AIMS & OBJECTIVES
\size default 

\newline 

\layout Standard


\series bold 
\size large 
Synopsis of Research Project and overall aims:
\size default 

\newline 

\layout Itemize

Fully automate obtaining a set of dense correspondences across a set of
 3D medical images as a basis for building statistical models of shape and
 appearance.
\layout Itemize

Develop a new approach with a rigorous theoretical basis and compare its
 performance with existing approaches to the problem.
\layout Itemize

Apply the method(s) developed to demonstrate changes in morphology due to
 disease (or other causes) in a large dataset (eg brain, knee etc).
\layout Standard


\series bold 
\size large 
Objectives of research project for first year (full-time Students) or first
 two years (part-time Students), including literature searching:
\size default 

\newline 

\layout Itemize

Establish benchmark results for correspondences obtained using existing
 non-rigid registration algorithms.
\layout Itemize

Develop an in-depth understanding of the literature on: non-rigid registration,
 active shape/appearance models, and minimum description length methods
 (generally and as applied to shape correspondence).
\layout Itemize

Develop a general understanding of current methods and problems in computer
 vision, with particular emphasis on medical image analysis.
\layout Itemize

Carry out initial experiments using synthetic data to gain an insight into
 the problem of automatic image correspondence and an understanding of the
 key problem areas.
\layout Itemize

Obtain and analyse initial results using both synthetic and real data (possibly
 only 2-D).
\layout Itemize

Develop a plan for future work, based on the experience of the first year.
\layout Standard


\series bold 
\size large 
Key objectives for first 3 months:
\size default 

\newline 

\layout Itemize

Complete machine learning module successfully.
\layout Itemize

Establish a pattern of background reading.
\layout Itemize

Undertake a detailed review of the literature in non-rigid registration,
 active shape/appearance models, and minimum description length methods
 (generally and as applied to shape correspondence).
\layout Itemize

Gain good familiarity with using MATLAB to run computer vision experiments
 and to analyse results.
\layout Itemize

Establish simple 1-D model building framework using MATLAB software from
 Kate Smith.
\layout Itemize

Plan presentation for student seminar.
\layout Standard


\series bold 
\size large 
Key objectives for first year:
\size default 

\newline 

\layout Itemize

See objectives for first year above.
\newline 

\newline 

\layout Standard
\align center 

\series bold 
\size large 
VARIOUS COURSES
\size default 

\newline 

\layout Standard


\begin_inset Float table
placement H
wide false
collapsed false

\layout Standard
\align center 

\begin_inset  Tabular
<lyxtabular version="3" rows="7" columns="2">
<features>
<column alignment="center" valignment="top" leftline="true" width="0">
<column alignment="center" valignment="top" leftline="true" rightline="true" width="0">
<row topline="true" bottomline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard


\series bold 
Course/Seminar Title
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard


\series bold 
Dates (if known)
\end_inset 
</cell>
</row>
<row topline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

Introductory Course
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard

22/09/03 - 26/09/03
\end_inset 
</cell>
</row>
<row topline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

Library Visits
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard

ISBE Research Library: perpetual
\end_inset 
</cell>
</row>
<row topline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

Regulatory Core Courses
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard

1/10/03 - 1/06/03
\end_inset 
</cell>
</row>
<row topline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

Computing Skills and Statistics
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard

N/A
\end_inset 
</cell>
</row>
<row topline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

1st Year Workshop
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard

N/A
\end_inset 
</cell>
</row>
<row topline="true" bottomline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

Health and Safety Training (Compulsory)
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard

N/A
\end_inset 
</cell>
</row>
</lyxtabular>

\end_inset 


\layout Caption


\size small 

\begin_inset LatexCommand \label{cap:The-courses-taken}

\end_inset 

The courses taken at the beginning of the academic year.
\end_inset 


\layout Section*
\pagebreak_top 
Deadlines
\layout Standard

See Table 
\begin_inset LatexCommand \ref{cap:Stricter-deadlines.}

\end_inset 

 for deadlines.
 The one shown further below (Table 
\begin_inset LatexCommand \ref{cap:General-time-guidelines}

\end_inset 

) is for personal guidance only.
\layout Standard


\begin_inset Float table
placement H
wide false
collapsed false

\layout Standard
\align center 

\begin_inset  Tabular
<lyxtabular version="3" rows="11" columns="2">
<features>
<column alignment="center" valignment="top" leftline="true" rightline="true" width="0">
<column alignment="center" valignment="top" leftline="true" rightline="true" width="0">
<row topline="true" bottomline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard


\series bold 
Deadline date
\end_inset 
</cell>
</row>
<row topline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

Existing code mastered
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard

December 20th, 2003
\end_inset 
</cell>
</row>
<row topline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

Submission of 
\series bold 
Literature Report
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard

December 22nd, 2003
\end_inset 
</cell>
</row>
<row topline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

Extension to code completed
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard

January 5th, 2004
\end_inset 
</cell>
</row>
<row topline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

Presentation 
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard

January - February 2004
\end_inset 
</cell>
</row>
<row topline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

Resolving Project Plan
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard

(End of) January 2004
\end_inset 
</cell>
</row>
<row topline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

Progress Report Submission
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard

March 24th, 2004
\end_inset 
</cell>
</row>
<row topline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

First implementation working
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard

(Late) April 2004
\end_inset 
</cell>
</row>
<row topline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

Implementation entirely documented
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard

July 2004
\end_inset 
</cell>
</row>
<row topline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

Experiments performed
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard

August 2004
\end_inset 
</cell>
</row>
<row topline="true" bottomline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

Continuation Report Viva completed
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard

September 1st, 2004
\end_inset 
</cell>
</row>
</lyxtabular>

\end_inset 


\layout Caption


\size small 

\begin_inset LatexCommand \label{cap:Stricter-deadlines.}

\end_inset 

Stricter deadlines.
\end_inset 


\layout Section*

Milestones
\layout Standard

In line with Form 2 (page 
\begin_inset LatexCommand \pageref{sec:Form-2}

\end_inset 

), but from a broader, more formal scope, here are some very rough estimates
 of expected milestones.
 The following chart summarises some of the milestones expected and the
 corresponding deadline dates.
\layout Standard


\begin_inset Float table
placement H
wide false
collapsed false

\layout Standard
\align center 

\begin_inset  Tabular
<lyxtabular version="3" rows="11" columns="2">
<features>
<column alignment="center" valignment="top" leftline="true" rightline="true" width="0">
<column alignment="center" valignment="top" leftline="true" rightline="true" width="0">
<row topline="true" bottomline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard


\series bold 
Recommended completion date
\end_inset 
</cell>
</row>
<row topline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

Literature Report Submission
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

December 15th, 2003
\end_inset 
</cell>
</row>
<row topline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard


\family roman 
\series medium 
\shape up 
\size normal 
\emph off 
\bar no 
\noun off 
\color none
Literature Report 
\family default 
\series default 
\shape default 
\size default 
\emph default 
\bar default 
\noun default 
\color default
Meeting
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

December 22nd, 2003
\end_inset 
</cell>
</row>
<row topline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

Extension to code completed
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

December 27th, 2003
\end_inset 
</cell>
</row>
<row topline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

Presentation 
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

February 2004
\end_inset 
</cell>
</row>
<row topline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

Resolving Project Plan
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

January 2004
\end_inset 
</cell>
</row>
<row topline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

Progress Report Submission
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

March 1st, 2004
\end_inset 
</cell>
</row>
<row topline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

First implementation working
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

April 2004
\end_inset 
</cell>
</row>
<row topline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

Implementation entirely documented
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

July 2004
\end_inset 
</cell>
</row>
<row topline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

Experiments performed
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

August 2004
\end_inset 
</cell>
</row>
<row topline="true" bottomline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

Continuation Report Viva completed
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

August 25th, 2004
\end_inset 
</cell>
</row>
</lyxtabular>

\end_inset 


\layout Caption


\begin_inset LatexCommand \label{cap:General-time-guidelines}

\end_inset 


\size small 
General time guidelines.
\layout Comment

(corresponding to this subsection)
\end_inset 


\layout Comment

Describe the things I have to do by some deadlines.
\layout Comment

Maybe Gantt chart
\layout Standard

The Gantt chart below attempts to assure compliance with the deadlines and
 guarantee that progress will be made as anticipated.
\layout Standard


\begin_inset Float table
placement H
wide false
collapsed false

\layout Standard
\align center 

\begin_inset  Tabular
<lyxtabular version="3" rows="16" columns="6">
<features>
<column alignment="center" valignment="top" leftline="true" rightline="true" width="0">
<column alignment="center" valignment="top" leftline="true" width="0">
<column alignment="center" valignment="top" leftline="true" width="0">
<column alignment="center" valignment="top" leftline="true" width="0">
<column alignment="center" valignment="top" leftline="true" width="0">
<column alignment="center" valignment="top" leftline="true" rightline="true" width="0">
<row topline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard


\series bold 
Dec/03
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard


\series bold 
Jan/04
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard


\series bold 
Feb/04
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard


\series bold 
Mar/04
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard


\series bold 
Apr/04
\end_inset 
</cell>
</row>
<row bottomline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard


\series bold 
May/04
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard


\series bold 
Jun/04
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard


\series bold 
Jul/04
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard


\series bold 
Aug/04
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard


\series bold 
Sep/04
\end_inset 
</cell>
</row>
<row topline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

Literature Report
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard


\begin_inset Formula $\surd$
\end_inset 


\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard

\end_inset 
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard

\end_inset 
</cell>
</row>
<row topline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

Presentation
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard


\begin_inset Formula $\surd$
\end_inset 


\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard


\begin_inset Formula $\surd$
\end_inset 


\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard


\begin_inset Formula $\surd$
\end_inset 


\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard

\end_inset 
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard

\end_inset 
</cell>
</row>
<row topline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

Work on existing code
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard


\begin_inset Formula $\surd$
\end_inset 


\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard


\begin_inset Formula $\surd$
\end_inset 


\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard


\begin_inset Formula $\surd$
\end_inset 


\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard

\end_inset 
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard

\end_inset 
</cell>
</row>
<row topline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

New implementation
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard


\begin_inset Formula $\surd$
\end_inset 


\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard


\begin_inset Formula $\surd$
\end_inset 


\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard


\begin_inset Formula $\surd$
\end_inset 


\end_inset 
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard


\begin_inset Formula $\surd$
\end_inset 


\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard


\begin_inset Formula $\surd$
\end_inset 


\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard


\begin_inset Formula $\surd$
\end_inset 


\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard

\end_inset 
</cell>
</row>
<row topline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

Documentation
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard


\begin_inset Formula $\surd$
\end_inset 


\end_inset 
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard


\begin_inset Formula $\surd$
\end_inset 


\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard


\begin_inset Formula $\surd$
\end_inset 


\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard


\begin_inset Formula $\surd$
\end_inset 


\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard


\begin_inset Formula $\surd$
\end_inset 


\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard

\end_inset 
</cell>
</row>
<row topline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

Experiments
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard

\end_inset 
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard


\begin_inset Formula $\surd$
\end_inset 


\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard


\begin_inset Formula $\surd$
\end_inset 


\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard


\begin_inset Formula $\surd$
\end_inset 


\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard


\begin_inset Formula $\surd$
\end_inset 


\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard

\end_inset 
</cell>
</row>
<row topline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

Continuation Report Viva
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard

\end_inset 
</cell>
</row>
<row bottomline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard


\begin_inset Formula $\surd$
\end_inset 


\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard


\begin_inset Formula $\surd$
\end_inset 


\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard


\begin_inset Formula $\surd$
\end_inset 


\end_inset 
</cell>
</row>
</lyxtabular>

\end_inset 


\layout Caption


\begin_inset LatexCommand \label{cap:Progress-Gantt-Chart}

\end_inset 


\size small 
Progress Gantt chart.
\end_inset 


\layout Standard

Work division that is project-specific and a better summary of the 
\emph on 
technical
\emph default 
 aspects will be entirely left out.
 More accurate aims were formulated in Form 2 for completeness.
\layout Section*

Contingencies
\layout Standard

As some feasibility considerations are yet to be resolved, it is vital that
 alternative directions for this research are realised and suggested.
 One facet of this issue is concerned with times at which 
\emph on 
evaluation
\emph default 
 of progress, development and achievement ought to take place and quality
 reviewed, apart from the formal evaluation in April 2004.
 By recognising dead-ends at the earlier stages of work, wasted effort can
 essentially be avoided.
 There are several types of problems that can come up:
\layout Enumerate

A field is yet too poorly understood and there is a lack of basic knowledge
 to rely upon.
\layout Enumerate

Effort is already invested in the exact same field or problems that the
 project poses are found to be resolved already.
 
\layout Enumerate

The code dealt with is too hard to cope with.
\layout Enumerate

Given algorithms or conventional methods are too slow to work with productively
\begin_inset Foot
collapsed false

\layout Standard

Frequently it appears to be the case that in order to get reasonable results,
 high computational power is mandatory.
 In the absence of this power, experiments might fail or become impractical.
\end_inset 

.
\layout Enumerate

Alternative solutions with greater potential are identified, thereupon requestin
g all attention to be diverted to them exclusively.
\layout Enumerate

Experiments fail to produce the results expected or hoped for.
\layout Enumerate

Progress is held back by time restrictions.
\layout Standard

Obstructions which are prone to happen more frequently would be 4, 5 and
 even quite frustratingly 6.
\layout Standard


\begin_inset Note
collapsed false

\layout Standard

What can go wrong?
\layout Standard

feasibility?
\layout Standard

Direction of research?
\end_inset 


\layout Standard
\pagebreak_top 

\noun on 

\begin_inset LatexCommand \index{Progress Records}

\end_inset 


\begin_inset LatexCommand \label{cha:Appendix-DProgress-Records}

\end_inset 

Progress Records
\layout Standard
\align center 

\begin_inset Graphics
	filename ./Graphics/fancyline.eps
	display none
	scale 57.50

\end_inset 


\layout Standard


\begin_inset Graphics
	filename ./Graphics/t.eps
	display none
	scale 40.00

\end_inset 


\noun on 
his
\noun default 
 appendix gives what is subjectively an abundant amount of information.
 Nevertheless, as part of the essential proof of progress, the following
 should not be left out.
\layout Standard


\begin_inset Float table
placement H
wide false
collapsed false

\layout Standard
\align center 

\begin_inset  Tabular
<lyxtabular version="3" rows="12" columns="2">
<features>
<column alignment="center" valignment="top" leftline="true" width="0">
<column alignment="center" valignment="top" leftline="true" rightline="true" width="0">
<row topline="true" bottomline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

Date
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard

Description
\end_inset 
</cell>
</row>
<row topline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

22-26 September 2003
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard


\family roman 
\series medium 
\shape up 
\size normal 
\emph off 
\bar no 
\noun off 
\color none
Introductory week
\end_inset 
</cell>
</row>
<row topline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard


\family roman 
\series medium 
\shape up 
\size normal 
\emph off 
\bar no 
\noun off 
\color none
6-24 October 2003
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard


\family roman 
\series medium 
\shape up 
\size normal 
\emph off 
\bar no 
\noun off 
\color none
Machine learning
\end_inset 
</cell>
</row>
<row topline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard


\family roman 
\series medium 
\shape up 
\size normal 
\emph off 
\bar no 
\noun off 
\color none
20 January 2004
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard


\family roman 
\series medium 
\shape up 
\size normal 
\emph off 
\bar no 
\noun off 
\color none
Oxford plenary meeting
\end_inset 
</cell>
</row>
<row topline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard


\family roman 
\series medium 
\shape up 
\size normal 
\emph off 
\bar no 
\noun off 
\color none
10, 17 March 2004
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard


\family roman 
\series medium 
\shape up 
\size normal 
\emph off 
\bar no 
\noun off 
\color none
Thesis writing seminar
\end_inset 
</cell>
</row>
<row topline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard


\family roman 
\series medium 
\shape up 
\size normal 
\emph off 
\bar no 
\noun off 
\color none
2, 25 March 2004
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard


\family roman 
\series medium 
\shape up 
\size normal 
\emph off 
\bar no 
\noun off 
\color none
Student presentations
\end_inset 
</cell>
</row>
<row topline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard


\family roman 
\series medium 
\shape up 
\size normal 
\emph off 
\bar no 
\noun off 
\color none
30-31 March 2004
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard


\family roman 
\series medium 
\shape up 
\size normal 
\emph off 
\bar no 
\noun off 
\color none
Manchester plenary meeting
\end_inset 
</cell>
</row>
<row topline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard


\family roman 
\series medium 
\shape up 
\size normal 
\emph off 
\bar no 
\noun off 
\color none
April 2004
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard


\family roman 
\series medium 
\shape up 
\size normal 
\emph off 
\bar no 
\noun off 
\color none
Mathematical methods
\end_inset 
</cell>
</row>
<row topline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard


\family roman 
\series medium 
\shape up 
\size normal 
\emph off 
\bar no 
\noun off 
\color none
27 May 2004
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard


\family roman 
\series medium 
\shape up 
\size normal 
\emph off 
\bar no 
\noun off 
\color none
UCL S&F meeting
\end_inset 
</cell>
</row>
<row topline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard


\family roman 
\series medium 
\shape up 
\size normal 
\emph off 
\bar no 
\noun off 
\color none
2 June 2004
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard


\family roman 
\series medium 
\shape up 
\size normal 
\emph off 
\bar no 
\noun off 
\color none
Ph.D.
 Workshop
\end_inset 
</cell>
</row>
<row topline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard


\family roman 
\series medium 
\shape up 
\size normal 
\emph off 
\bar no 
\noun off 
\color none
21-25 June 2004
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard


\family roman 
\series medium 
\shape up 
\size normal 
\emph off 
\bar no 
\noun off 
\color none
Surrey Summer School
\end_inset 
</cell>
</row>
<row topline="true" bottomline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

13 July
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard

Workshop, Guy's Hospital
\end_inset 
</cell>
</row>
</lyxtabular>

\end_inset 


\layout Caption


\begin_inset LatexCommand \label{cap:Non-technical-record-of}

\end_inset 


\size small 
Non-technical record of progress.
\end_inset 


\layout Standard


\begin_inset Note
collapsed false

\layout Standard

Words HERE
\end_inset 


\layout Standard
\pagebreak_bottom 
Also, a record of meetings, excluding the frequent ones with Carole Twining,
 completes the evidence of progress (see the next page for initials).
\begin_inset Float table
wide false
collapsed false

\layout Standard
\align center 

\begin_inset  Tabular
<lyxtabular version="3" rows="35" columns="3">
<features>
<column alignment="center" valignment="top" leftline="true" width="0">
<column alignment="center" valignment="top" leftline="true" width="0">
<column alignment="center" valignment="top" leftline="true" rightline="true" width="0">
<row topline="true" bottomline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

Date
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard

Attendants
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard

Description
\end_inset 
</cell>
</row>
<row topline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard


\family roman 
\series medium 
\shape up 
\size normal 
\emph off 
\bar no 
\noun off 
\color none
24th September 2003
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard


\family roman 
\series medium 
\shape up 
\size normal 
\emph off 
\bar no 
\noun off 
\color none
SRW
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard


\family roman 
\series medium 
\shape up 
\size normal 
\emph off 
\bar no 
\noun off 
\color none
Issuing of letter
\end_inset 
</cell>
</row>
<row topline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard


\family roman 
\series medium 
\shape up 
\size normal 
\emph off 
\bar no 
\noun off 
\color none
October 2003
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard


\family roman 
\series medium 
\shape up 
\size normal 
\emph off 
\bar no 
\noun off 
\color none
SRW
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard


\begin_inset Formula $\times$
\end_inset 


\end_inset 
</cell>
</row>
<row topline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard


\family roman 
\series medium 
\shape up 
\size normal 
\emph off 
\bar no 
\noun off 
\color none
October 2003
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard


\family roman 
\series medium 
\shape up 
\size normal 
\emph off 
\bar no 
\noun off 
\color none
PB
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard


\family roman 
\series medium 
\shape up 
\size normal 
\emph off 
\bar no 
\noun off 
\color none
Discussion about 
\family default 
\series default 
\shape default 
\size default 
\emph default 
\bar default 
\noun default 
\color default
A
\family roman 
\series medium 
\shape up 
\size normal 
\emph off 
\bar no 
\noun off 
\color none
dvisor
\end_inset 
</cell>
</row>
<row topline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard


\family roman 
\series medium 
\shape up 
\size normal 
\emph off 
\bar no 
\noun off 
\color none
26th November 2003
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard


\family roman 
\series medium 
\shape up 
\size normal 
\emph off 
\bar no 
\noun off 
\color none
SRW
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard


\family roman 
\series medium 
\shape up 
\size normal 
\emph off 
\bar no 
\noun off 
\color none
Advisor/Post-graduate Tutor
\end_inset 
</cell>
</row>
<row topline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard


\family roman 
\series medium 
\shape up 
\size normal 
\emph off 
\bar no 
\noun off 
\color none
17th December 2003
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard


\family roman 
\series medium 
\shape up 
\size normal 
\emph off 
\bar no 
\noun off 
\color none
SRW
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard


\begin_inset Formula $\times$
\end_inset 


\end_inset 
</cell>
</row>
<row topline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard


\family roman 
\series medium 
\shape up 
\size normal 
\emph off 
\bar no 
\noun off 
\color none
8th January 2004
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard

SM
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard


\begin_inset Formula $\times$
\end_inset 


\end_inset 
</cell>
</row>
<row topline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard


\family roman 
\series medium 
\shape up 
\size normal 
\emph off 
\bar no 
\noun off 
\color none
January 2004
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard


\family roman 
\series medium 
\shape up 
\size normal 
\emph off 
\bar no 
\noun off 
\color none
T
\family default 
\series default 
\shape default 
\size default 
\emph default 
\bar default 
\noun default 
\color default
FC
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard


\family roman 
\series medium 
\shape up 
\size normal 
\emph off 
\bar no 
\noun off 
\color none
Registration, MATLAB, etc.
\end_inset 
</cell>
</row>
<row topline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

14th January 2004
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard


\family roman 
\series medium 
\shape up 
\size normal 
\emph off 
\bar no 
\noun off 
\color none
SRW
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard

P
\family roman 
\series medium 
\shape up 
\size normal 
\emph off 
\bar no 
\noun off 
\color none
rogress of work
\end_inset 
</cell>
</row>
<row topline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

16th January 2004
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard


\family roman 
\series medium 
\shape up 
\size normal 
\emph off 
\bar no 
\noun off 
\color none
CJT, SRW, PB
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard


\family roman 
\series medium 
\shape up 
\size normal 
\emph off 
\bar no 
\noun off 
\color none
Literature Report meeting
\end_inset 
</cell>
</row>
<row topline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard


\family roman 
\series medium 
\shape up 
\size normal 
\emph off 
\bar no 
\noun off 
\color none
28th January 2004
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard


\family roman 
\series medium 
\shape up 
\size normal 
\emph off 
\bar no 
\noun off 
\color none
CJT, TFC, SM, CJTw
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard


\family roman 
\series medium 
\shape up 
\size normal 
\emph off 
\bar no 
\noun off 
\color none
S&F GC meeting
\end_inset 
</cell>
</row>
<row topline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard


\family roman 
\series medium 
\shape up 
\size normal 
\emph off 
\bar no 
\noun off 
\color none
4th February 2004
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard

CJT
\family roman 
\series medium 
\shape up 
\size normal 
\emph off 
\bar no 
\noun off 
\color none
, CJTw
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard


\family roman 
\series medium 
\shape up 
\size normal 
\emph off 
\bar no 
\noun off 
\color none
S&F GC meeting
\end_inset 
</cell>
</row>
<row topline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard


\family roman 
\series medium 
\shape up 
\size normal 
\emph off 
\bar no 
\noun off 
\color none
9th February 2004
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard


\family roman 
\series medium 
\shape up 
\size normal 
\emph off 
\bar no 
\noun off 
\color none
SRW
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard

Presentation to be given
\end_inset 
</cell>
</row>
<row topline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard


\family roman 
\series medium 
\shape up 
\size normal 
\emph off 
\bar no 
\noun off 
\color none
11th February 2004
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard


\family roman 
\series medium 
\shape up 
\size normal 
\emph off 
\bar no 
\noun off 
\color none
CJT, TFC, CJTw
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard


\family roman 
\series medium 
\shape up 
\size normal 
\emph off 
\bar no 
\noun off 
\color none
S&F GC meeting
\end_inset 
</cell>
</row>
<row topline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard


\family roman 
\series medium 
\shape up 
\size normal 
\emph off 
\bar no 
\noun off 
\color none
18th February 2004
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard

CJT
\family roman 
\series medium 
\shape up 
\size normal 
\emph off 
\bar no 
\noun off 
\color none
, CJTw
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard


\family roman 
\series medium 
\shape up 
\size normal 
\emph off 
\bar no 
\noun off 
\color none
S&F GC meeting
\end_inset 
</cell>
</row>
<row topline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard


\family roman 
\series medium 
\shape up 
\size normal 
\emph off 
\bar no 
\noun off 
\color none
27th February 2004
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard


\family roman 
\series medium 
\shape up 
\size normal 
\emph off 
\bar no 
\noun off 
\color none
CJT, TFC, CJTw
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard


\family roman 
\series medium 
\shape up 
\size normal 
\emph off 
\bar no 
\noun off 
\color none
Registration Brainstorm
\end_inset 
</cell>
</row>
<row topline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard


\family roman 
\series medium 
\shape up 
\size normal 
\emph off 
\bar no 
\noun off 
\color none
3rd March 2004
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard


\family roman 
\series medium 
\shape up 
\size normal 
\emph off 
\bar no 
\noun off 
\color none
CJT, TFC, CJTw
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard


\family roman 
\series medium 
\shape up 
\size normal 
\emph off 
\bar no 
\noun off 
\color none
S&F GC meeting
\end_inset 
</cell>
</row>
<row topline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard


\family roman 
\series medium 
\shape up 
\size normal 
\emph off 
\bar no 
\noun off 
\color none
8th March 2004
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard


\family roman 
\series medium 
\shape up 
\size normal 
\emph off 
\bar no 
\noun off 
\color none
SRW
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard


\family roman 
\series medium 
\shape up 
\size normal 
\emph off 
\bar no 
\noun off 
\color none
Advanced Modules
\end_inset 
</cell>
</row>
<row topline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard


\family roman 
\series medium 
\shape up 
\size normal 
\emph off 
\bar no 
\noun off 
\color none
12th March 2004
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard


\family roman 
\series medium 
\shape up 
\size normal 
\emph off 
\bar no 
\noun off 
\color none
CJT, TFC, CJTw
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard


\family roman 
\series medium 
\shape up 
\size normal 
\emph off 
\bar no 
\noun off 
\color none
S&F GC meeting
\end_inset 
</cell>
</row>
<row topline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard


\family roman 
\series medium 
\shape up 
\size normal 
\emph off 
\bar no 
\noun off 
\color none
19th March 2004
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard


\family roman 
\series medium 
\shape up 
\size normal 
\emph off 
\bar no 
\noun off 
\color none
CJT, SRW
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard


\family roman 
\series medium 
\shape up 
\size normal 
\emph off 
\bar no 
\noun off 
\color none
Form 4
\end_inset 
</cell>
</row>
<row topline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard


\family roman 
\series medium 
\shape up 
\size normal 
\emph off 
\bar no 
\noun off 
\color none
6th April 2004
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard


\family roman 
\series medium 
\shape up 
\size normal 
\emph off 
\bar no 
\noun off 
\color none
SRW
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard


\family roman 
\series medium 
\shape up 
\size normal 
\emph off 
\bar no 
\noun off 
\color none
Advice on giving a talk
\end_inset 
</cell>
</row>
<row topline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard


\family roman 
\series medium 
\shape up 
\size normal 
\emph off 
\bar no 
\noun off 
\color none
28th April 2004
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard


\family roman 
\series medium 
\shape up 
\size normal 
\emph off 
\bar no 
\noun off 
\color none
CJT, TFC, CJTw
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard


\family roman 
\series medium 
\shape up 
\size normal 
\emph off 
\bar no 
\noun off 
\color none
S&F GC meeting
\end_inset 
</cell>
</row>
<row topline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard


\family roman 
\series medium 
\shape up 
\size normal 
\emph off 
\bar no 
\noun off 
\color none
19th May 2004
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard

CJT
\family roman 
\series medium 
\shape up 
\size normal 
\emph off 
\bar no 
\noun off 
\color none
, CJTw
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard


\family roman 
\series medium 
\shape up 
\size normal 
\emph off 
\bar no 
\noun off 
\color none
S&F GC meeting
\end_inset 
</cell>
</row>
<row topline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard


\family roman 
\series medium 
\shape up 
\size normal 
\emph off 
\bar no 
\noun off 
\color none
24th May 2004
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard


\family roman 
\series medium 
\shape up 
\size normal 
\emph off 
\bar no 
\noun off 
\color none
SRW
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard

C
\family roman 
\series medium 
\shape up 
\size normal 
\emph off 
\bar no 
\noun off 
\color none
urrent activities in ISBE
\end_inset 
</cell>
</row>
<row topline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard


\family roman 
\series medium 
\shape up 
\size normal 
\emph off 
\bar no 
\noun off 
\color none
25th May 2004
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard


\family roman 
\series medium 
\shape up 
\size normal 
\emph off 
\bar no 
\noun off 
\color none
CJT, TFC, CJTw
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard


\family roman 
\series medium 
\shape up 
\size normal 
\emph off 
\bar no 
\noun off 
\color none
S&F GC meeting
\end_inset 
</cell>
</row>
<row topline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard


\family roman 
\series medium 
\shape up 
\size normal 
\emph off 
\bar no 
\noun off 
\color none
2nd June 2004
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard

CJT
\family roman 
\series medium 
\shape up 
\size normal 
\emph off 
\bar no 
\noun off 
\color none
, CJTw
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard


\family roman 
\series medium 
\shape up 
\size normal 
\emph off 
\bar no 
\noun off 
\color none
S&F GC meeting
\end_inset 
</cell>
</row>
<row topline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard


\family roman 
\series medium 
\shape up 
\size normal 
\emph off 
\bar no 
\noun off 
\color none
7th June 2004
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard


\family roman 
\series medium 
\shape up 
\size normal 
\emph off 
\bar no 
\noun off 
\color none
TW
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard


\begin_inset Formula $\times$
\end_inset 


\end_inset 
</cell>
</row>
<row topline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard


\family roman 
\series medium 
\shape up 
\size normal 
\emph off 
\bar no 
\noun off 
\color none
9th June 2004
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard


\family roman 
\series medium 
\shape up 
\size normal 
\emph off 
\bar no 
\noun off 
\color none
TW
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard


\begin_inset Formula $\times$
\end_inset 


\end_inset 
</cell>
</row>
<row topline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard


\family roman 
\series medium 
\shape up 
\size normal 
\emph off 
\bar no 
\noun off 
\color none
10th June 2004
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard

TW
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard


\begin_inset Formula $\times$
\end_inset 


\end_inset 
</cell>
</row>
<row topline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard


\family roman 
\series medium 
\shape up 
\size normal 
\emph off 
\bar no 
\noun off 
\color none
11th June 2004
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard


\family roman 
\series medium 
\shape up 
\size normal 
\emph off 
\bar no 
\noun off 
\color none
C
\family default 
\series default 
\shape default 
\size default 
\emph default 
\bar default 
\noun default 
\color default
JT
\family roman 
\series medium 
\shape up 
\size normal 
\emph off 
\bar no 
\noun off 
\color none
, T
\family default 
\series default 
\shape default 
\size default 
\emph default 
\bar default 
\noun default 
\color default
FC
\family roman 
\series medium 
\shape up 
\size normal 
\emph off 
\bar no 
\noun off 
\color none
, CJTw
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard


\family roman 
\series medium 
\shape up 
\size normal 
\emph off 
\bar no 
\noun off 
\color none
S&F GC meeting
\end_inset 
</cell>
</row>
<row topline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard


\family roman 
\series medium 
\shape up 
\size normal 
\emph off 
\bar no 
\noun off 
\color none
15th June 2004
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard


\family roman 
\series medium 
\shape up 
\size normal 
\emph off 
\bar no 
\noun off 
\color none
C
\family default 
\series default 
\shape default 
\size default 
\emph default 
\bar default 
\noun default 
\color default
JT
\family roman 
\series medium 
\shape up 
\size normal 
\emph off 
\bar no 
\noun off 
\color none
, TW
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard


\begin_inset Formula $\times$
\end_inset 


\end_inset 
</cell>
</row>
<row topline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard


\family roman 
\series medium 
\shape up 
\size normal 
\emph off 
\bar no 
\noun off 
\color none
17th June 2004
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard


\family roman 
\series medium 
\shape up 
\size normal 
\emph off 
\bar no 
\noun off 
\color none
C
\family default 
\series default 
\shape default 
\size default 
\emph default 
\bar default 
\noun default 
\color default
JT
\family roman 
\series medium 
\shape up 
\size normal 
\emph off 
\bar no 
\noun off 
\color none
, CJTw
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard


\family roman 
\series medium 
\shape up 
\size normal 
\emph off 
\bar no 
\noun off 
\color none
S&F GC meeting
\end_inset 
</cell>
</row>
<row topline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard


\family roman 
\series medium 
\shape up 
\size normal 
\emph off 
\bar no 
\noun off 
\color none
17th June 2004
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard


\family roman 
\series medium 
\shape up 
\size normal 
\emph off 
\bar no 
\noun off 
\color none
TW
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard


\begin_inset Formula $\times$
\end_inset 


\end_inset 
</cell>
</row>
<row topline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard


\family roman 
\series medium 
\shape up 
\size normal 
\emph off 
\bar no 
\noun off 
\color none
28th June 2004
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard


\family roman 
\series medium 
\shape up 
\size normal 
\emph off 
\bar no 
\noun off 
\color none
TW
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard


\begin_inset Formula $\times$
\end_inset 


\end_inset 
</cell>
</row>
<row topline="true" bottomline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard


\family roman 
\series medium 
\shape up 
\size normal 
\emph off 
\bar no 
\noun off 
\color none
12th July 2004
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard


\family roman 
\series medium 
\shape up 
\size normal 
\emph off 
\bar no 
\noun off 
\color none
CJT, SRW
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard


\family roman 
\series medium 
\shape up 
\size normal 
\emph off 
\bar no 
\noun off 
\color none
Form 5 Meeting
\end_inset 
</cell>
</row>
</lyxtabular>

\end_inset 


\layout Caption


\size small 

\begin_inset LatexCommand \label{cap:Miscellaneous-work-related-meetings}

\end_inset 

Miscellaneous work-related meetings.
\end_inset 


\layout Standard

CJT \SpecialChar ~
=\SpecialChar ~
Chris Taylor
\newline 
TW\SpecialChar ~
=\SpecialChar ~
Tomos Williams
\newline 
CJTw\SpecialChar ~
=\SpecialChar ~

\family roman 
\series medium 
\shape up 
\size normal 
\emph off 
\bar no 
\noun off 
\color none
Carole Twining
\family default 
\series default 
\shape default 
\size default 
\emph default 
\bar default 
\noun default 
\color default

\newline 
TFC\SpecialChar ~
=\SpecialChar ~

\family roman 
\series medium 
\shape up 
\size normal 
\emph off 
\bar no 
\noun off 
\color none
Tim Cootes
\family default 
\series default 
\shape default 
\size default 
\emph default 
\bar default 
\noun default 
\color default

\newline 
SM\SpecialChar ~
=\SpecialChar ~

\family roman 
\series medium 
\shape up 
\size normal 
\emph off 
\bar no 
\noun off 
\color none
Ste
\family default 
\series default 
\shape default 
\size default 
\emph default 
\bar default 
\noun default 
\color default
ve
\family roman 
\series medium 
\shape up 
\size normal 
\emph off 
\bar no 
\noun off 
\color none
 Marsland
\family default 
\series default 
\shape default 
\size default 
\emph default 
\bar default 
\noun default 
\color default

\newline 
PB\SpecialChar ~
=\SpecialChar ~
Paul Beatty
\layout Standard

Meetings with the supervisor are also omitted (and can be found on the WWW).
\layout Standard
\pagebreak_top 

\noun on 

\begin_inset LatexCommand \index{List of Abbreviations}

\end_inset 


\begin_inset LatexCommand \label{cha:Appendix-EList-of}

\end_inset 

List of Abbreviations
\layout Standard
\align center 

\begin_inset Graphics
	filename ./Graphics/fancyline.eps
	display none
	scale 57.50

\end_inset 


\layout Standard


\begin_inset Graphics
	filename ./Graphics/s.eps
	display none
	scale 40.00

\end_inset 


\noun on 
ome
\noun default 
 of the previously-mentioned acronyms are sorted alphabetically below.
 They should be used as a reference.
\layout Comment

sort alphabetically
\layout Standard


\series bold 
AAM:
\series default 
 Active appearance model
\layout Standard


\series bold 
AART: 
\series default 
Autonomous appearance-based registration test-bed
\layout Standard


\series bold 
ALU:
\series default 
 Arithmetic and logic unit
\layout Standard


\series bold 
ASM:
\series default 
 Active shape model
\layout Standard


\series bold 
COG: 
\series default 
Centre of gravity
\layout Standard


\series bold 
CPS: 
\series default 
Clamped-plate spline
\layout Standard


\series bold 
CT:
\series default 
 Computed tomography
\layout Standard


\series bold 
CVS:
\series default 
 Concurrent versions system
\layout Standard


\series bold 
EPSRC:
\series default 
 Engineering and physical sciences research council 
\layout Standard


\series bold 
GC: 
\series default 
Grand challenge
\layout Standard


\series bold 
GPA: 
\series default 
Generalised procrustes procedure
\layout Standard


\series bold 
GSSEM: 
\series default 
Graduate school of science, engineering and medicine
\layout Standard


\series bold 
GUI: 
\series default 
Graphical user interface
\layout Standard


\series bold 
FFD:
\series default 
 Free-form deformation
\layout Standard


\series bold 
I/O:
\series default 
 Input/output
\layout Standard


\series bold 
IRC:
\series default 
 Interdisciplinary research collaboration
\layout Standard


\series bold 
ISBE:
\series default 
 Imaging science and biomedical engineering
\layout Standard


\series bold 
LOC:
\series default 
 Lines of code
\layout Standard


\series bold 
MDL: 
\series default 
Minimum description length
\layout Standard


\series bold 
MI:
\series default 
 Mutual information
\layout Standard


\series bold 
MIAS: 
\series default 
Medical image and signal 
\layout Standard


\series bold 
MICCAI:
\series default 
 Medical image computing and computer-assisted intervention
\layout Standard


\series bold 
MIUA: 
\series default 
Medical image understanding and analysis
\layout Standard


\series bold 
MSD:
\series default 
 Mean of squared differences
\layout Standard


\series bold 
MRI: 
\series default 
Magnetic resonance imaging
\layout Standard


\series bold 
NMI: 
\series default 
Normalised mutual information
\layout Standard


\series bold 
NRR:
\series default 
 Non-rigid registration
\layout Standard


\series bold 
PCA:
\series default 
 Principal component analysis
\layout Standard


\series bold 
PDF: 
\series default 
Probability density function; Portable document format
\layout Standard


\series bold 
PDM:
\series default 
 Point distribution model
\layout Standard


\series bold 
PET:
\series default 
 Positron emission tomography
\layout Standard


\series bold 
RAM:
\series default 
 Random access memory
\layout Standard


\series bold 
S&F: 
\series default 
Structure and function
\layout Standard


\series bold 
SDM:
\series default 
 Statistical deformation model
\layout Standard


\series bold 
SNR: 
\series default 
Signal-to-noise ratio
\layout Standard


\series bold 
SPM:
\series default 
 Statistical parametric mapping
\layout Standard


\series bold 
SSD:
\series default 
 Sum of squared differences
\layout Standard


\series bold 
TS: 
\series default 
Taboo search
\layout Standard


\series bold 
UCL:
\series default 
 University college london
\layout Standard


\series bold 
WWW:
\series default 
 World wide web
\layout Standard
\pagebreak_top 

\noun on 

\begin_inset LatexCommand \index{Additional Resources}

\end_inset 


\begin_inset LatexCommand \label{cha:Appendix-FAdditional-Resources}

\end_inset 

Additional Resources
\layout Standard
\align center 

\begin_inset Graphics
	filename ./Graphics/fancyline.eps
	display none
	scale 57.50

\end_inset 


\layout Comment

Write some more stuff here on Web pages
\layout Standard


\begin_inset Graphics
	filename ./Graphics/a.eps
	display none
	scale 30.00

\end_inset 


\noun on 
ll
\noun default 
 the existing project information is stored in a non-public domain.
 Please confer the index of all research material on-line at:
\layout Standard


\begin_inset LatexCommand \htmlurl{http://www.danielsorogon.com/Webmaster/Research/resindex.htm}

\end_inset 


\layout Standard

This includes all organisational notes, documents, submissions, posters,
 forms, WWW links, project documentation, code documentation, experiments,
 outputs, logs, and more.
 Any data that has not been covered in this report can be located quite
 easily on that domain.
\layout Standard
\pagebreak_top 

\noun on 

\begin_inset LatexCommand \index{Primary On-Line Resources}

\end_inset 


\begin_inset LatexCommand \label{cha:Primary-On-Line-Resources}

\end_inset 

Primary On-Line Resources
\layout Standard
\align center 

\begin_inset Graphics
	filename ./Graphics/fancyline.eps
	display none
	scale 57.50

\end_inset 


\layout Standard


\series bold 
\size larger 
World Wide Web Bibliography
\layout Standard


\begin_inset Graphics
	filename ./Graphics/a.eps
	display none
	scale 30.00

\end_inset 


\noun on 
s
\noun default 
 much of the reading was based on educational and personal sites from the
 World Wide Web, several of the more dominant sources must be acknowledged.
\layout Itemize


\size small 
[WWW-1] 
\begin_inset LatexCommand \htmlurl{http://www.math.ufl.edu/help/matlab-tutorial/}

\end_inset 


\layout Quote


\size small 
An extensive MATLAB tutorial from the University of Florida.
\layout Itemize


\size small 
[WWW-2] 
\begin_inset LatexCommand \htmlurl{http://www.doc.ic.ac.uk/~dr/}

\end_inset 


\layout Quote


\size small 
Daniel Rueckert's academic pages.
\layout Itemize


\size small 
[WWW-3] 
\begin_inset LatexCommand \htmlurl{http://www-ipg.umds.ac.uk/d.hill/}

\end_inset 


\layout Quote


\size small 
Derek Hill's abstracts and publications.
\layout Itemize


\size small 
[WWW-4]
\series bold 
 
\series default 

\begin_inset LatexCommand \htmlurl{http://www.dcs.gla.ac.uk/~mc/}

\end_inset 


\layout Quote


\size small 
Technical Reports of Matthew Cairn.
\layout Itemize


\size small 
[WWW-5] 
\begin_inset LatexCommand \htmlurl{http://www.imm.dtu.dk/image/research/}

\end_inset 


\layout Quote


\size small 
Related research in the Technical University of Denmark.
\layout Itemize


\size small 
[WWW-6]
\series bold 
 
\series default 

\begin_inset LatexCommand \htmlurl{http://www.ai.mit.edu/~viola/}

\end_inset 


\layout Quote


\size small 
Personal pages maintained by Paul Viola.
\layout Itemize


\size small 
[WWW-7]
\series bold 
 
\series default 

\begin_inset LatexCommand \htmlurl{http://www.isbe.man.ac.uk/~bim/}

\end_inset 


\layout Quote


\size small 
Publications and resources from Tim Cootes who ought to receive accolade
 for his clear explanations of statistical models.
\layout Itemize


\size small 
[WWW-8]
\series bold 
 
\series default 

\begin_inset LatexCommand \htmlurl{http://www.cs.jhu.edu/~wolff/course600.461/}

\end_inset 


\layout Quote


\size small 
Computer Vision at Johns Hopkins University.
\layout Itemize


\size small 
[WWW-9] 
\begin_inset LatexCommand \htmlurl{http://www.cs.wisc.edu/~dyer/cs766.html}

\end_inset 


\layout Quote


\size small 
Computer Vision at the University of Wisconsin.
\layout Itemize


\size small 
[WWW-10]
\series bold 
 
\series default 

\begin_inset LatexCommand \htmlurl{http://www.csse.monash.edu.au/~app/CSE5301/Lnts/L01.pdf}

\end_inset 


\layout Quote


\size small 
Neural networks material from Andrew P.
 Paplinskil.
\layout Itemize


\size small 
[WWW-11]
\series bold 
 
\series default 

\begin_inset LatexCommand \htmlurl{http://www.eg.org/EG/DL/Conf/EG91/papers/EUROGRAPHICS_91pp183_194_abstracthttp://www.eg.org/EG/DL/Conf/EG91/papers/EUROGRAPHICS_91pp183_194_abstract.pdf}

\end_inset 


\layout Quote


\size small 
Short and eloquent explanation on image discrepancy from Peter Shirley.
\layout Itemize


\size small 
[WWW-12] 
\begin_inset LatexCommand \htmlurl{http://www.ics.uci.edu/~eppstein/gina/interpolate.html}

\end_inset 


\layout Quote


\size small 
Explanation on interpolation from David Eppstein.
\layout Itemize


\size small 
[WWW-13]
\series bold 
 
\series default 

\begin_inset LatexCommand \htmlurl{http://www.lans.ece.utexas.edu/~strehl/diss}

\end_inset 


\layout Quote


\size small 
Alexander Strehl's dissertation with relation to mutual information.
\layout Itemize


\size small 
[WWW-14]
\series bold 
 
\series default 

\begin_inset LatexCommand \htmlurl{http://www.mdl-research.org/}

\end_inset 


\layout Quote


\size small 
An extensive resource on minimum description length with interactive examples.
\layout Itemize


\size small 
[WWW-15] 
\begin_inset LatexCommand \htmlurl{http://www-groups.dcs.st-and.ac.uk/~history/Mathematicians/Shannon.html}

\end_inset 


\layout Quote


\size small 
An ample resource for studying about Shannon and his work.
\layout Itemize


\size small 
[WWW-16]
\series bold 
 
\series default 

\begin_inset LatexCommand \htmlurl{http://www.fil.ion.ucl.ac.uk/spm/}

\end_inset 


\layout Quote

The official UCL resource for SPM software, idealogy, etc.
\layout Itemize


\size small 
[WWW-17]
\series bold 
 
\series default 

\begin_inset LatexCommand \htmlurl{http://www.mathworks.nl/matlabcentral/fileexchange/loadAuthor.do?objectType=author&objectId=1094029}

\end_inset 


\layout Quote

The general-purpose code shared by the author of this report.
\end_inset 


\layout Bibliography
\paragraph_spacing single 
\bibitem {Abkar}


\begin_inset LatexCommand \index{Bibliography}

\end_inset 


\size footnotesize 

\begin_inset LatexCommand \label{Bibliography}

\end_inset 

A.
 Abkar and H.
 Hedenmalm, 
\begin_inset Quotes eld
\end_inset 

A Riesz Representation Formula for Super-Biharmonic Functions,
\begin_inset Quotes erd
\end_inset 

 Annales Academie Scientiarum Fennice Mathematica, vol.
 26, pp.
 305--324, 2001.
\layout Bibliography
\paragraph_spacing single 
\bibitem {Ahlberg}


\size footnotesize 
J.
 Ahlberg and R.
 Forchheimer, 
\begin_inset Quotes eld
\end_inset 

Face tracking for model-based coding and face animation,
\begin_inset Quotes erd
\end_inset 

 International Journal of Imaging Systems and Technology, vol.
 13, pp.
 8--22, 2003.
\layout Bibliography
\paragraph_spacing single 
\bibitem {Ashburner}


\size footnotesize 
J.
 Ashburner and K.
 J.
 Friston, "Why Voxel-Based Morphometry Should Be Used," NeuroImage, vol.
 14, pp.
 1238 -- 1243, 2001.
\layout Bibliography
\paragraph_spacing single 
\bibitem {Beg}


\size footnotesize 
M.
 F.
 Beg, M.
 I.
 Miller, T.
 A., and L.
 Younes, "Computational Anatomy: Computing Metrics on Anatomical Shapes,"
 presented at Proceedings of the First IEEE International Symposiumon Biomedical
 Imaging (ISBI'02), 2002.
\layout Bibliography
\paragraph_spacing single 
\bibitem {Baker}


\size footnotesize 
S.
 Baker, I.
 Matthews, and J.
 Schneider, 
\begin_inset Quotes eld
\end_inset 

Automatic construction of active appearance models as an image coding problem,
\begin_inset Quotes erd
\end_inset 

 IEEE Transactions on Pattern Analysis and Machine Intelligence, vol.
 26, pp.
 1380-1384, 2004.
\layout Bibliography
\paragraph_spacing single 
\bibitem {Beeston}


\size footnotesize 
C.
 J.
 Beeston and C.
 J.
 Taylor, 
\begin_inset Quotes eld
\end_inset 

Automatic landmarking of cortical sulci,
\begin_inset Quotes erd
\end_inset 

 in Medical Image Computing and Computer-Assisted Intervention 2000, vol.
 1935, pp.
 125-133.
\layout Bibliography
\paragraph_spacing single 
\bibitem {Beauchemin}


\size footnotesize 
M.
 Beauchemin and K.
 P.
 B.
 Thomson, ``The evaluation of segmentation results and the overlapping area
 matrix,'' International Journal of Remote Sensing, 18(18):3895--3899, 1997.
\layout Bibliography
\paragraph_spacing single 
\bibitem {Beymer_Poggio}


\size footnotesize 
D.
 Beymer and T.
 Poggio.
 
\begin_inset Quotes eld
\end_inset 

Image Representations for Visual Learning,
\begin_inset Quotes erd
\end_inset 

 In Science, vol.
 272, issue 5270, pp.
 1905 -1909.
\layout Bibliography
\paragraph_spacing single 
\bibitem {DR-isbi}


\size footnotesize 
K.
 K.
 Bhatia, J.
 V.
 Hajnal, B.
 K.
 Puri, A.
 D.
 Edwards, and D.
 Rueckert, 
\begin_inset Quotes eld
\end_inset 

Consistent groupwise non-rigid registration for atlas construction,
\begin_inset Quotes erd
\end_inset 

 presented at ISBI, Arlington, VA, USA, 2004.
\layout Bibliography
\paragraph_spacing single 
\bibitem {Bookstein_thin}


\size footnotesize 
F.
 L.
 Bookstein, 
\begin_inset Quotes eld
\end_inset 

Principal Warps: Thin-Plate Spines and the Decomposition of Deformations,
\begin_inset Quotes erd
\end_inset 

 IEEE Transactions on Pattern Analysis and Machine Intelligence, vol.
 11, pp.
 567--585, 1989.
\layout Bibliography
\paragraph_spacing single 
\bibitem {bookstein_brain_warping}


\size footnotesize 
F.
 L.
 Bookstein, "Linear Methods for Nonlinear Maps: Procustes Fits, Thin-Plate
 Splines and the Biometric Analysis of Shape Variability," in Brain Warping,
 A.
 W.
 Toga, Ed.
 San Diego, CA, USA: Academic Press, 1999, pp.
 157--181.
\layout Bibliography
\paragraph_spacing single 
\bibitem {Brett_et_al_auto_landmark_generation}


\size footnotesize 
A.
 D.
 Brett and C.
 J.
 Taylor, 
\begin_inset Quotes eld
\end_inset 

A method of automated landmark generation for automated 3D PDM construction,
\begin_inset Quotes erd
\end_inset 

 Image and Vision Computing, vol.
 18, pp.
 739--748, 2000.
\layout Bibliography
\paragraph_spacing single 
\bibitem {key-10}


\size footnotesize 
P.
 Cachier and D.
 Rey, "Symmetrization of the Non-Rigid Registration Problem Using Inversion-Inva
riant Energies: Application to Multiple Sclerosis," presented at Third Internati
onal Conference on Medical Image Computing and Computer Assisted Intervention
 (MICCAI'00), 2000.
\layout Bibliography
\paragraph_spacing single 
\bibitem {key-11}


\size footnotesize 
V.
 Camion and L.
 Younes, "Geodesic Interpolating Splines," presented at Proceedings of Energy
 Minimisation in Computer Vision and Pattern Recognition (EMMCVPR), 2001.
\layout Bibliography
\paragraph_spacing single 
\bibitem {Crum_MICCAI_2005}


\size footnotesize 
W.
 R.
 Crum, O.
 Camara, D.
 Rueckert, K.
 Bhatia, M.
 Jenkinson, and D.
 L.
 G.
 Hill, ``Generalised overlap measures for assessment of pairwise and groupwise
 image registration and segmentation,'' in Proceedings of Medical Image
 Computing and Computer-Assisted Intervention (MICCAI), Lecture Notes in
 Computer Science, vol.
 3749.
 Springer, 2005, pp.
 99--106.
\layout Bibliography
\paragraph_spacing single 
\bibitem {atlas_aam}


\size footnotesize 
T.
 F.
 Cootes, C.
 Beeston, G.
 J.
 Edwards, and C.
 J.
 Taylor, 
\begin_inset Quotes eld
\end_inset 

A unified framework for atlas matching using Active Appearance Models,
\begin_inset Quotes erd
\end_inset 

 in Information Processing in Medical Imaging, Proceedings, vol.
 1613, Lecture Notes in Computer Science, 1999, pp.
 322--333.
\layout Bibliography
\paragraph_spacing single 
\bibitem {AAM_IEEE}


\size footnotesize 
T.
 F.
 Cootes, G.
 J.
 Edwards, and C.
 J.
 Taylor, 
\begin_inset Quotes eld
\end_inset 

Active appearance models,
\begin_inset Quotes erd
\end_inset 

 IEEE Transactions on Pattern Analysis and Machine Intelligence, vol.
 23, pp.
 681--685, 2001.
\layout Bibliography
\paragraph_spacing single 
\bibitem {Cootes_ECCV_1998}


\size footnotesize 
T.
 Cootes, G.
 Edwards, and C.
 Taylor, ``Active appearance models,'' in Proceedings of the European Conference
 on Computer Vision (ECCV), Lecture Notes in Computer Science, vol.
 1407.
 Springer, 1998, pp.
 484--498.
\layout Bibliography
\paragraph_spacing single 
\bibitem {Crum_BJR}


\size footnotesize 
W.
 R.
 Crum, T Hartkens, and D.
 L.
 G.
 Hill, ``Non-rigid image registration: theory and practice,'' British Journal
 of Radiology, vol.
 77, pp.
 140--153, 2004.
\layout Bibliography
\paragraph_spacing single 
\bibitem {Cootes_reg}


\size footnotesize 
T.
 F.
 Cootes, S.
 Marsland, C.J.
 Twining, K.
 Smith, and C.J.
 Taylor, 
\begin_inset Quotes eld
\end_inset 

Groupwise diffeomorphic non-rigid registration for automatic model building,
\begin_inset Quotes erd
\end_inset 

 In Proceedings of the European Conference of Computer Vision 2004, pp.
 316--32.
\layout Bibliography
\paragraph_spacing single 
\bibitem {Cootes_Piecewise_Affine_BMVC}


\size footnotesize 
T.
 F.
 Cootes, C.
 J.
 Twining, V.
 Petrovic, R.
 Schestowitz, and C.
 J.
 Taylor, ``Groupwise Construction of Appearance Models using Piece-wise
 Affine Deformations.'' in Proceedings of the British Machine Vision Conference
 (BMVC'04), Kingston UK, 2004.
\layout Bibliography
\paragraph_spacing single 
\bibitem {view_based_aam}


\size footnotesize 
T.
 F.
 Cootes, G.
 V.
 Wheeler, K.
 N.
 Walker, and C.
 J.
 Taylor, 
\begin_inset Quotes eld
\end_inset 

View-based active appearance models,
\begin_inset Quotes erd
\end_inset 

 Image and Vision Computing, vol.
 20, pp.
 657--664, 2002.
\layout Bibliography
\paragraph_spacing single 
\bibitem {coupled_view}


\size footnotesize 
T.
 F.
 Cootes, G.
 V.
 Wheeler, K.
 N.
 Walker, and C.
 J.
 Taylor, 
\begin_inset Quotes eld
\end_inset 

Coupled-view active appearance models,
\begin_inset Quotes erd
\end_inset 

 British Machine Vision Conference, vol.
 1, pp.
 52--61, 2000.
\layout Bibliography
\paragraph_spacing single 
\bibitem {Davies_MDL}


\size footnotesize 
R.
 H.
 Davies, C.
 J.
 Twining, T.
 F.
 Cootes, J.
 C.
 Waterton, and C.
 J.
 Taylor, 
\begin_inset Quotes eld
\end_inset 

3D statistical shape models using direct optimisation of description length,
\begin_inset Quotes erd
\end_inset 

 In Proceedings of the European Conference on Computer Vision, Lecture Notes
 in Computer Science, vol.
 2352, pp.
 3--20, 2002,.
\layout Bibliography
\paragraph_spacing single 
\bibitem {Davies_MDL_MI}


\size footnotesize 
R.
 H.
 Davies, C.
 J.
 Twining, T.
 F.
 Cootes, J.
 C.
 Waterton, and C.
 J.
 Taylor, 
\begin_inset Quotes eld
\end_inset 

minimum description length approach to statistical shape modeling,
\begin_inset Quotes erd
\end_inset 

 IEEE Transactions on Medical Imaging, vol.
 21, pp.
 525--537, 2002.
\layout Bibliography
\paragraph_spacing single 
\bibitem {Davies_Hippocampus}


\size footnotesize 
R.
 H.
 Davies, C.
 J.
 Twining, P.
 D.
 Allen, T.
 F.
 Cootes, and C.
 J.
 Taylor, 
\begin_inset Quotes eld
\end_inset 

Shape discrimination in the hippocampus using an MDL model,
\begin_inset Quotes erd
\end_inset 

 in Information Processing in Medical Imaging Proceedings, Lecture Notes
 in Computer Science, vol.
 2732, pp.
 38--50, 2003.
\layout Bibliography
\paragraph_spacing single 
\bibitem {NRR_ISBI2002}


\size footnotesize 
B.
 M.
 Dawant, 
\begin_inset Quotes eld
\end_inset 

Non-Rigid Registration of Medical Images: Purpose and Methods, A Short Survey,
\begin_inset Quotes erd
\end_inset 

 In Proceedings of the First IEEE International Symposium on Biomedical
 Imaging, 2002.
\layout Bibliography
\paragraph_spacing single 
\bibitem {Collins}


\size footnotesize 
S.
 Duchesne, J.
 C.
 Pruessner, and D.
 L.
 Collins, 
\begin_inset Quotes eld
\end_inset 

Appearance-based segmentation of medial temporal lobe structures,
\begin_inset Quotes erd
\end_inset 

 NeuroImage, vol.
 17, pp.
 515--531, 2002.
\layout Bibliography
\paragraph_spacing single 
\bibitem {diffeomorphism_paper}


\size footnotesize 
P.
 Dupuis, U.
 Grenander, and M.
 I.
 Miller, "Variational problems on flows of diffeomorphisms for image matching,"
 Quarterly of Applied Mathematics, vol.
 56, pp.
 587 -- 600, 1998.
\layout Bibliography
\paragraph_spacing single 
\bibitem {Edwards_98_AAM}


\size footnotesize 
G.
 J.
 Edwards, C.
 J.
 T.
 Taylor, and T.
 F.
 Cootes, 
\begin_inset Quotes eld
\end_inset 

Interpreting face images using active appearance models,
\begin_inset Quotes erd
\end_inset 

 In IEEE International Conference on Automatic Face and Gesture Recognition,
 Nara, Japan, 1998.
\layout Bibliography
\paragraph_spacing single 
\bibitem {Edwards}


\size footnotesize 
G.
 J.
 Edwards, T.
 F.
 Cootes, and C.
 J.
 Taylor, ``Face recognition using active appearance models,'' In Proceedings
 of European Conference on Computer Vision, Lecture Notes in Computer Science,
 vol.
 2.
 pp.
 581--595, 1998.
\layout Bibliography
\paragraph_spacing single 
\bibitem {shape_detection}


\size footnotesize 
P.
 F.
 Felzenszwalb, 
\begin_inset Quotes eld
\end_inset 

Representation and detection of deformable shapes,
\begin_inset Quotes erd
\end_inset 

 Computer Vision and Pattern Recognition, vol.
 1, pp.
 102--108, 2003.
\layout Bibliography
\paragraph_spacing single 
\bibitem {Frangi}


\size footnotesize 
A.
 F.
 Frangi, D.
 Rueckert, J.
 A.
 Schnabel, and W.
 J.
 Niessen, ``Automatic construction of multiple-object three-dimensional
 statistical shape models: application to cardiac modelling,'' IEEE Transations
 in Medical Imaging, vol.
 21, pp.
 1151--1166, 2002.
\layout Bibliography
\bibitem {Li_CVPR_01}


\size footnotesize 
Y.
 Li, S.
 Gong, and H.
 Liddel, 
\begin_inset Quotes eld
\end_inset 

Constructing facial identity surfaces,
\begin_inset Quotes erd
\end_inset 

 in Computer Vision and Pattern Recognition, 2001.
\layout Bibliography
\paragraph_spacing single 
\bibitem {key-14}


\size footnotesize 
J.
 Gee, M.
 Reivich, and R.
 Bajcsy, "Elastically deforming 3D atlas to match anatomical brain images,"
 Journal of Computer Assisted Tomography, vol.
 17, pp.
 225-236, 1993.
\layout Bibliography
\paragraph_spacing single 
\bibitem {glover}


\size footnotesize 
F.
 Glover, E.
 D.
 Taillard, and D.
 de Werra, 
\begin_inset Quotes eld
\end_inset 

A user's guide to taboo search,
\begin_inset Quotes erd
\end_inset 

 Annals of Operations Search, pp.
 3--28, 1993.
\layout Bibliography
\paragraph_spacing single 
\bibitem {key-17}


\size footnotesize 
U.
 Grenander and M.
 I.
 Miller, "Computation Anatomy: An Emerging Discipline," in Quarterly of
 Applied Mathematics, vol.
 56, 1998, pp.
 617 -- 694.
\layout Bibliography
\paragraph_spacing single 
\bibitem {key-16}


\size footnotesize 
H.
 C.
 Grunau and G.
 Sweers, "Maximum principles and positive principal eigenfunctions for polyharmo
nic equations," presented at Reaction Diffusion Systems, 1998.
\layout Bibliography
\paragraph_spacing single 
\bibitem {Guimond}


\size footnotesize 
A.
 Guimond, J.
 Meunier, and J.
 Thirion, 
\begin_inset Quotes eld
\end_inset 

Automatic computation of average brain models,
\begin_inset Quotes erd
\end_inset 

 presented at Medical Image Computing and Computer Assisted Intervention
 1998, pp.
 631--640, Cambridge, MA, USA.
 
\layout Bibliography
\paragraph_spacing single 
\bibitem {key-15}


\size footnotesize 
A.
 Guimond, J.
 Meunier, and J.-P.
 Thirion, "Average Brain Models: A Convergence Study," INRIA, Sophia Antipolis
 1999.
\layout Bibliography
\paragraph_spacing single 
\bibitem {Hajnal_book}


\size footnotesize 
J.
 V.
 Hajnal, D.
 L.
 G.
 Hill, and D.
 J.
 Hawkes, 
\begin_inset Quotes eld
\end_inset 

Medical image registration,
\begin_inset Quotes erd
\end_inset 

 Boca Raton, Fla.
 ; London: CRC Press, 2001.
\layout Bibliography
\paragraph_spacing single 
\bibitem {Haker}


\size footnotesize 
S.
 Haker, A.
 Tannenbaum, and R.
 Kikinis, 
\begin_inset Quotes eld
\end_inset 

Mass Preserving Mappings and Image Registration,
\begin_inset Quotes erd
\end_inset 

 presented at Fourth International Conference on Medical Image Computing
 and Computer Assisted Intervention, 2001.
\layout Bibliography
\paragraph_spacing single 
\bibitem {henn_regularise}


\size footnotesize 
S.
 Henn and K.
 Witsch, "Iterative Multigrid Regularisation Techniques for Image Matching,"
 SIAM Journal of Scientific Computing, vol.
 23, pp.
 1077 -- 1093, 2001.
\layout Bibliography
\paragraph_spacing single 
\bibitem {Hansen}


\size footnotesize 
D.
 W.
 Hansen, M.
 Nielsen, J.
 P.
 Hansen, A.
 S.
 Johansen and M.
 B.
 Stegmann, 
\begin_inset Quotes eld
\end_inset 

Tracking eyes using shape and appearance,
\begin_inset Quotes erd
\end_inset 

 IAPR Workshop on Machine Vision Applications, pp.
 201--204, 2002.
\layout Bibliography
\paragraph_spacing single 
\bibitem {Hill_non-rigid}


\size footnotesize 
A.
 Hill, C.
 J.
 Taylor, and A.
 D.
 Brett, 
\begin_inset Quotes eld
\end_inset 

A framework for automatic landmark identification using a new method of
 nonrigid correspondence,
\begin_inset Quotes erd
\end_inset 

 IEEE Transactions on Pattern Analysis and Machine Intelligence, vol.
 22, pp.
 241--251, 2000.
\layout Bibliography
\paragraph_spacing single 
\bibitem {jenkins_thin_plate}


\size footnotesize 
D.
 R.
 Jenkins, "Thin Plate Spline Interpolation on an Annulus," presented at
 Proceedings of the 1999 International conference on Computational Techniques
 and Applications, 2000.
\layout Bibliography
\paragraph_spacing single 
\bibitem {Jebara}


\size footnotesize 
T.
 Jebara, 
\begin_inset Quotes eld
\end_inset 

Images as Bags of Pixels,
\begin_inset Quotes erd
\end_inset 

 presented at International Conference of Computer Vision, Proceedings,
 Nice, France, 2003.
\layout Bibliography
\paragraph_spacing single 
\bibitem {PCA}


\size footnotesize 
I.T.
 Joliffe, 
\begin_inset Quotes eld
\end_inset 

Principal Component Analysis,
\begin_inset Quotes erd
\end_inset 

 Springer Series in Statistics, Springer, New York, 1986.
\layout Bibliography
\paragraph_spacing single 
\bibitem {Joshi_reg}


\size footnotesize 
S.
 C.
 Joshi and M.
 L.
 Miller, 
\begin_inset Quotes eld
\end_inset 

Landmark Matching via Large Deformation Diffeomorphisms,
\begin_inset Quotes erd
\end_inset 

 IEEE Transaction on Image Processing, vol.
 9, pp.
 1357--1370, 2000.
\layout Bibliography
\paragraph_spacing single 
\bibitem {Hellier}


\size footnotesize 
P.
 Hellier, C.
 Barillot, I.
 Corouge, B.
 Giraud, G.
 L.
 Goualher, L.
 Collins, A.
 Evans, G.
 Malandain, and N.
 Ayache, ``Retrospective evaluation of inter-subject brain registration,''
 in Proceedings of Medical Image Computing and Computer-Assisted Intervention
 (MICCAI), Lecture Notes in Computer Science, vol.
 2208.
 Springer, 2001, pp.
 258--265.
\layout Bibliography
\paragraph_spacing single 
\bibitem {Correlation Ratio}


\size footnotesize 
J.
 F.
 Kenney and E.
 S.
 Keeping, 
\begin_inset Quotes eld
\end_inset 

Mathematics of Statistics,
\begin_inset Quotes erd
\end_inset 

 part 2, 2nd edition, Princeton, New Jersey: Van Nostrand, 1951.
\layout Bibliography
\paragraph_spacing single 
\bibitem {Kotcheff}


\size footnotesize 
A.
 C.
 W.
 Kotcheff and C.
 J.
 Taylor, 
\begin_inset Quotes eld
\end_inset 

Automatic construction of eigenshape models by genetic algorithm,
\begin_inset Quotes erd
\end_inset 

 in Information Processing in Medical Imaging, vol.
 1230, pp.
 1--14, Lecture Notes in Computer Science, 1997.
 2005.
\layout Bibliography
\paragraph_spacing single 
\bibitem {Shuffle}


\size footnotesize 
K.
 N.
 Kutulakos, ``Approximate n-view stereo,'' in Proceedings of the European
 Conference on Computer Vision (ECCV), Lecture Notes in Computer Science,
 vol.
 1842.
 Springer, 2000, pp.
 67--83.
\layout Bibliography
\paragraph_spacing single 
\bibitem {Lanitis_prosopo}


\size footnotesize 
A.
 Lanitis, 
\begin_inset Quotes eld
\end_inset 

PROSOPO - A face image synthesis system,
\begin_inset Quotes erd
\end_inset 

 Advances in Informatics, Lecture Notes in Computer Science, vol.
 2563, pp.
 297--315, 2003.
\layout Bibliography
\paragraph_spacing single 
\bibitem {Lanitis_face}


\size footnotesize 
A.
 Lanitis, C.
 J.
 Taylor, and T.
 F.
 Cootes, 
\begin_inset Quotes eld
\end_inset 

Automatic Face Identification System Using Flexible Appearance Models,
\begin_inset Quotes erd
\end_inset 

 Image and Vision Computing, vol.
 13, pp.
 393--401, 1995.
\layout Bibliography
\paragraph_spacing single 
\bibitem {Lanitis_aging}


\size footnotesize 
A.
 Lanitis, C.
 J.
 Taylor, and T.
 F.
 Cootes, 
\begin_inset Quotes eld
\end_inset 

Toward automatic simulation of aging effects on face images,
\begin_inset Quotes erd
\end_inset 

 IEEE Transactions on Pattern Analysis and Machine Intelligence, vol.
 24, pp.
 442--455, 2002.
\layout Bibliography
\paragraph_spacing single 
\bibitem {lebriquer}


\size footnotesize 
L.
 LeBriquer and J.
 Gee, 
\begin_inset Quotes eld
\end_inset 

Design of a statistical model of brain shape,
\begin_inset Quotes erd
\end_inset 

 presented at Proceedings of IPMI, 1997.
\layout Bibliography
\paragraph_spacing single 
\bibitem {lee-b-spline}


\size footnotesize 
S.
 Lee, G.
 Wolberg, and S.
 Y.
 Shin, "Scattered Data Interpolation with Multilevel B-Splines," IEEE Transactio
ns on Visualisation and Computer Graphics, vol.
 3, pp.
 228 -- 244, 1997.
\layout Bibliography
\paragraph_spacing single 
\bibitem {Likar_MI}


\size footnotesize 
B.
 Likar and F.
 Pernus, 
\begin_inset Quotes eld
\end_inset 

A Hierarchical Approach to Elastic Registration Based on Mutual Information,
\begin_inset Quotes erd
\end_inset 

 Image and Vision Computing, vol.
 19, pp.
\layout Bibliography
\paragraph_spacing single 
\bibitem {Lotjonen_and_Makela}


\size footnotesize 
J.
 Ltjnen and T.
 Mkel, 
\begin_inset Quotes eld
\end_inset 

Elastic Matching Using a Deformation Sphere,
\begin_inset Quotes erd
\end_inset 

 presented at Fourth International Conference on Medical Image Computing
 and Computer Assisted Intervention, 2001.
\layout Bibliography
\paragraph_spacing single 
\bibitem {maes_nmi}


\size footnotesize 
F.
 Maes, A.
 Collignon, D.
 Vandermeulen, G.
 Marchal, and P.
 Suetens, 
\begin_inset Quotes eld
\end_inset 

Multimodality image registration by maximization of mutual information,
\begin_inset Quotes erd
\end_inset 

 IEEE Transactions on Medical Imaging, vol.
 16, issue 2, pp.
 187--198, 1997.
\layout Bibliography
\paragraph_spacing single 
\bibitem {Marr}


\size footnotesize 
D.
 Marr, 
\begin_inset Quotes eld
\end_inset 

Understanding complex information processing systems,
\begin_inset Quotes erd
\end_inset 

 Vision, pp.
 19--24, 1982.
\layout Bibliography
\paragraph_spacing single 
\bibitem {Marsland_MICCAI_2003}


\size footnotesize 
S.
 Marsland, C.
 J.
 Twining, and C.
 J.
 Taylor, 
\begin_inset Quotes eld
\end_inset 

Groupwise non-rigid registration using polyharmonic clamped-plate splines,
\begin_inset Quotes erd
\end_inset 

 presented at Medical Image Computing and Computer-Assisted Intervention,
 Montreal, Canada, 2003.
\layout Bibliography
\paragraph_spacing single 
\bibitem {Miller_CVPR2000}


\size footnotesize 
E.
 G.
 Miller, N.
 E.
 Matsakis, and P.
 A.
 Viola, ``Learning from one example through shared densities on transforms,''
 in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognitio
n (CVPR), Volume 1, 2000, pp.
 464--471.
\layout Bibliography
\paragraph_spacing single 
\bibitem {key-24}


\size footnotesize 
M.
 I.
 Miller, S.
 C.
 Joshi, and G.
 E.
 Christensen, "Large Deformation Fluid Diffeomorphisms for Landmark and
 Image Matching," in Brain Warping, A.
 W.
 Toga, Ed.
 San Diego, CA, USA: Academic Press, 1999, pp.
 115 -- 131.
\layout Bibliography
\paragraph_spacing single 
\bibitem {Mitchell}


\size footnotesize 
T.
 Mitchell, 
\begin_inset Quotes eld
\end_inset 

Machine Learning,
\begin_inset Quotes erd
\end_inset 

 New York ; London: McGraw-Hill, 1997.
\layout Bibliography
\paragraph_spacing single 
\bibitem {Najmi}


\size footnotesize 
A.
 Najmi, R.
 A.
 Olshen, and R.
 M.
 Gray, 
\begin_inset Quotes eld
\end_inset 

A criterion for model selection using minimum description length,
\begin_inset Quotes erd
\end_inset 

 in Proceedings Compression and Complexity of Sequences, pp.
 204--214, Salerno, Italy, 1997.
\layout Bibliography
\paragraph_spacing single 
\bibitem {Neemuchwala}


\size footnotesize 
H.
 Neemuchwala, A.
 O.
 Hero, and P.
 Carson, 
\begin_inset Quotes eld
\end_inset 

Image registration using entropy measures and entropic graphs,
\begin_inset Quotes erd
\end_inset 

 European Journal of Signal Processing, 2003.
\layout Bibliography
\paragraph_spacing single 
\bibitem {key-25}


\size footnotesize 
W.
 Peckar, C.
 Schnrr, K.
 Rohr, and H.
 S.
 Stiehl, "Non-Rigid Image Registration using a Parameter-Free Elastic Model,"
 presented at Proceedings of the Ninth British Machine Vision Conference
 (BMVC'98), 1998.
\layout Bibliography
\paragraph_spacing single 
\bibitem {petrou}


\size footnotesize 
M.
 Petrou and P.
 Bosdogianni, 
\begin_inset Quotes eld
\end_inset 

Image processing: the fundamentals,
\begin_inset Quotes erd
\end_inset 

 ISBN 0471 99883 4, 1999.
\layout Bibliography
\paragraph_spacing single 
\bibitem {Pluim_MI}


\size footnotesize 
J.
 P.
 W.
 Pluim, J.
 B.
 A.
 Maintz, and M.
 A.
 Viergever, 
\begin_inset Quotes eld
\end_inset 

Image Registration by Maximisation of Combined Mutual Information and Gradient
 Information,
\begin_inset Quotes erd
\end_inset 

 IEEE Transaction on Medical Imaging, vol.
 19, pp.
 809--814, 2000.
\layout Bibliography
\paragraph_spacing single 
\bibitem {Pluim_multi_res}


\size footnotesize 
J.
 P.
 W.
 Pluim, J.
 B.
 A.
 Maintz, and M.
 A.
 Viergever, 
\begin_inset Quotes eld
\end_inset 

Mutual information matching in multiresolution contexts,
\begin_inset Quotes erd
\end_inset 

 in Image and Vision Computing, vol.
 19, issues 1--2, pp.
 45--52, January 2001.
\layout Bibliography
\paragraph_spacing single 
\bibitem {3d-ultrasound-nrr}


\size footnotesize 
I.
 Praktikis, C.
 Barillot, and P.
 Hellier, "Robust Multi-Scale Non-Rigid Registration of 3D Ultrasound Images,"
 presented at Scale-Space 2001, 2001.
\layout Bibliography
\paragraph_spacing single 
\bibitem {Press}


\size footnotesize 
W.
 H.
 Press, 
\begin_inset Quotes eld
\end_inset 

Numerical recipes in C/C++ : the art of scientific computing.
 
\begin_inset Quotes erd
\end_inset 

 Cambridge: Cambridge University Press, 2002.
\layout Bibliography
\paragraph_spacing single 
\bibitem {rabbani_jpeg}


\size footnotesize 
M.
 Rabbani and R.
 Joshi, 
\begin_inset Quotes eld
\end_inset 

An overview of the JPEG 2000 still image compression standard,
\begin_inset Quotes erd
\end_inset 

 Signal Processing: Image Communication, vol.
 17, pp.
 3--48.
\layout Bibliography
\paragraph_spacing single 
\bibitem {Rissanen_MDL}


\size footnotesize 
J.
 R.
 Rissanen, 
\begin_inset Quotes eld
\end_inset 

Stochastic complexity in statistical inquiry,
\begin_inset Quotes erd
\end_inset 

 presented at World Scientific Series in Computer Science, Singapore, 1989.
\layout Bibliography
\paragraph_spacing single 
\bibitem {Similarity measures}


\size footnotesize 
P.
 Rogelj and S.
 Kovacic, 
\begin_inset Quotes eld
\end_inset 

Similarity Measures for Non-Rigid Registration,
\begin_inset Quotes erd
\end_inset 

 presented at Medical Imaging 2001: Image Processing.
\layout Bibliography
\paragraph_spacing single 
\bibitem {Validation-NRR}


\size footnotesize 
P.
 Rogelj, S.
 Kovacic, and J.
 C.
 Gee, ``Validation of a nonrigid registration algorithm for multimodal data,''
 in Proceedings of Medical Imaging 2002, Image Processing, SPIE Proceedings,
 vol.
 4684, 2002, pp.
 299--307.
\layout Bibliography
\paragraph_spacing single 
\bibitem {key-29}


\size footnotesize 
T.
 Rohlfing and J.
 Maurer, Calvin R., "Intensity-Based Non-Rigid Registration Using Adaptive
 Multilevel Free-Form Deformation with an Incompressibility Constraint,"
 presented at Fourth International Conference on Medical Image Computing
 and Computer Assisted Intervention (MICCAI'01), 2001.
\layout Bibliography
\bibitem {Romdhani_BMVC_99}


\size footnotesize 
S.
 Romdhani, S.
 Gong, and A.
 Psarrou, 
\begin_inset Quotes eld
\end_inset 

A multi-view nonlinear active shape model using kernel PCA.
\begin_inset Quotes erd
\end_inset 

 in Proceedings of the British Machine Vision Conference, pp.
 483-492, 1999.
\layout Bibliography
\paragraph_spacing single 
\bibitem {Rueckert_2003}


\size footnotesize 
D.
 Rueckert, A.
 F.
 Frangi, and J.
 A.
 Schnabel, 
\begin_inset Quotes eld
\end_inset 

Automatic construction of 3-D statistical deformation,
\begin_inset Quotes erd
\end_inset 

 IEEE Transactions on Medical Imaging, vol.
 22, issue 8, pp.
 1014--1025, 2003.
\layout Bibliography
\paragraph_spacing single 
\bibitem {Rueckert_non_rigid}


\size footnotesize 
D.
 Rueckert, A.
 F.
 Frangi and J.
 A.
 Schnabel, 
\begin_inset Quotes eld
\end_inset 

Automatic construction of 3D statistical deformation models using non-rigid
 registration,
\begin_inset Quotes erd
\end_inset 

 presented at Medical Image Computing and Computer-Assisted Intervention
 2001.
\layout Bibliography
\paragraph_spacing single 
\bibitem {schestowitz_isbi}


\size footnotesize 
R.
 S.
 schestowitz, C.
 J.
 Twining, T.
 F.
 Cootes, V.
 S.
 Petrovic, C.
 J.
 Taylor, and B.
 Crum, 
\begin_inset Quotes eld
\end_inset 

Assessing the Accuracy of Non-Rigid Registration With and Without Ground
 Truth,
\begin_inset Quotes erd
\end_inset 

 IEEE International Symposium on Biomedical Imaging (ISBI), 2006.
\layout Bibliography
\paragraph_spacing single 
\bibitem {schestowitz-model-based-nrr}


\size footnotesize 
R.
 S.
 schestowitz, C.
 J.
 Twining, T.
 F.
 Cootes, and C.
 J.
 Taylor, 
\begin_inset Quotes eld
\end_inset 

Image Registration by Model Criteria,
\begin_inset Quotes erd
\end_inset 

 Presented in Proceedings of MIAS-IRC Plenary Meeting, pp.
 16--17, 2004.
\layout Bibliography
\paragraph_spacing single 
\bibitem {schestowitz-model-evaluation}


\size footnotesize 
Roy Schestowitz, Carole Twining, Tim Cootes, Vladimir Petrovic, and Chris
 Taylor, 
\begin_inset Quotes eld
\end_inset 

A Generic Method for Evaluating Appearance Models,
\begin_inset Quotes erd
\end_inset 

 Presented in Proceedings of MIAS-IRC Plenary Meeting, 2006.
 
\layout Bibliography
\paragraph_spacing single 
\bibitem {schnabel}


\size footnotesize 
J.
 A.
 Schnabel, C.
 Tanner, A.
 Castellano-Smith, A.
 Degenhard, M.
 O.
 Leach, D.
 R.
 Hose, D.
 L.
 G.
 Hill, and D.
 J.
 Hawkes, 
\begin_inset Quotes eld
\end_inset 

Validation of non-rigid image registration using finite element methods:
 application to breast MR images,
\begin_inset Quotes erd
\end_inset 

 IEEE Transactions on Medical Imaging, vol.
 22.
\layout Bibliography
\paragraph_spacing single 
\bibitem {Shattuck2001}


\size footnotesize 
D.
 W.
 Shattuck, S.
 R.
 Sandor-Leahy, K.
 A.
 Schaper, D.
 A.
 Rottenberg, and R.
 M.
 Leahy, ``Magnetic resonance image tissue classification using a partial
 volume model,'' NeuroImage, vol.
 13, pp.
 856--876, 2001.
\layout Bibliography
\paragraph_spacing single 
\bibitem {sonka}


\size footnotesize 
M.
 Sonka, V.
 Hlavac, and R.
 Boyle, 
\begin_inset Quotes eld
\end_inset 

Image processing, analysis and machine vision,
\begin_inset Quotes erd
\end_inset 

 Pacific Grove, Calif.
 ; London: PWS Publishing, 1999.
\layout Bibliography
\paragraph_spacing single 
\bibitem {Stegmann}


\size footnotesize 
M.
 B.
 Stegmann, B.
 K.
 Ersboll, and R.
 Larsen, 
\begin_inset Quotes eld
\end_inset 

FAME - A flexible appearance modeling environment,
\begin_inset Quotes erd
\end_inset 

 IEEE Transactions on Medical Imaging, vol.
 22, pp.
 1319--1331, 2003.
\layout Bibliography
\paragraph_spacing single 
\bibitem {Stegmann_cardiac}


\size footnotesize 
M.
 B.
 Stegmann, ``Analysis of 4d cardiac magnetic resonance images,'' Journal
 of The Danish Optical Society, vol.
 4, pp.
 38--39, 2001.
\layout Bibliography
\paragraph_spacing single 
\bibitem {Studholme_nmi}


\size footnotesize 
C.
 Studholme, D.L.G.
 Hill, and D.J.
 Hawkes, 
\begin_inset Quotes eld
\end_inset 

An overlap invariant entropy measure of 3D medical image alignment,
\begin_inset Quotes erd
\end_inset 

 Pattern Recognition, vol.
 32, issue 1, pp.
 71--86, 1999.
\layout Bibliography
\paragraph_spacing single 
\bibitem {Thacker B-Fitting}


\size footnotesize 
N.
 A.
 Thacker, D.
 Prendergast, and P.
 I.
 Rockett., 
\begin_inset Quotes eld
\end_inset 

B-fitting: an estimation technique with automatic parameter selection,
\begin_inset Quotes erd
\end_inset 

 presented at British Machine Vision Conference 1996.
\layout Bibliography
\paragraph_spacing single 
\bibitem {atlases_disease_specific}


\size footnotesize 
P.
 M.
 Thompson, M.
 S.
 Mega, C.
 Vidal, J.
 L.
 Rapoport, and A.
 W.
 Toga, 
\begin_inset Quotes eld
\end_inset 

Detecting Disease-Specific Patterns of Brain Structure using Cortical Pattern
 Matching and a Population-Based Probabilistic Brain Atlas,
\begin_inset Quotes erd
\end_inset 

 presented at Proceedings of the 17th International Conference on Information
 Processing in Medical Imaging, 2001.
\layout Bibliography
\paragraph_spacing single 
\bibitem {Brain_warping_book}


\size footnotesize 
A.
 Toga, 
\begin_inset Quotes eld
\end_inset 

Brain Warping,
\begin_inset Quotes erd
\end_inset 

 San Diego, CA, USA: Academic Press, 1999.
\layout Bibliography
\paragraph_spacing single 
\bibitem {diffeomorphism}


\size footnotesize 
A.
 Trouve, 
\begin_inset Quotes eld
\end_inset 

Diffeomorphisms Groups and Pattern Matching in Image Analysis,
\begin_inset Quotes erd
\end_inset 

 International Journal of Computer Vision, vol.
 28, pp.
 213--221, 1998.
\layout Bibliography
\paragraph_spacing single 
\bibitem {diffeo-in-1d}


\size footnotesize 
A.
 Trouve and L.
 Younes, "Diffeomorphic Matching Problems in One Dimension: Designing and
 Minimizing Matching Functionals," presented at Proceedings of European
 Conference on Computer Vision, 2000.
\layout Bibliography
\paragraph_spacing single 
\bibitem {twining_diffeo}


\size footnotesize 
C.
 J.
 Twining and S.
 Marsland, 
\begin_inset Quotes eld
\end_inset 

Constructing diffeomorphic representations of non-rigid registrations of
 medical images,
\begin_inset Quotes erd
\end_inset 

 presented at Information Processing in Medical Imaging 2003.
\layout Bibliography
\paragraph_spacing single 
\bibitem {CT_bmvc_2004}


\size footnotesize 
C.
 J.
 Twining, S.
 Marsland, and C.
 J.
 Taylor, 
\begin_inset Quotes eld
\end_inset 

Groupwise non-rigid registration: the minimum description length approach,
\begin_inset Quotes erd
\end_inset 

 British Machine Vision Conference 2004.
\layout Bibliography
\paragraph_spacing single 
\bibitem {twining_PCA}


\size footnotesize 
C.
 J.
 Twining and C.
 J.
 Taylor, 
\begin_inset Quotes eld
\end_inset 

The use of kernel principal component analysis to model data distributions,
\begin_inset Quotes erd
\end_inset 

 Pattern Recognition, vol.
 36, pp.
 217--227, 2003.
\layout Bibliography
\paragraph_spacing single 
\bibitem {CPS}


\size footnotesize 
C.
 J.
 Twining, S.
 Marsland, and C.
 J.
 Taylor, ``Measuring geodesic distances on the space of bounded diffeomorphims,'
' in Proceedings of the British Machine Vision Conference (BMVC'02), 2002.
\layout Bibliography
\paragraph_spacing single 
\bibitem {IPMI_2005_ISBE}


\size footnotesize 
C.
 J.
 Twining, T.
 F.
 Cootes, S.
 Marsland, V.
 Petrovic, R.
 Schestowitz, and C.
 J.
 Taylor, ``A unified information-theoretic approach to groupwise non-rigid
 registration and model building.'' in Proceedings of Information Processing
 in Medical Imaging (IPMI), Lecture Notes in Computer Science, vol.
 3565.
 Springer, 2005, pp.
 1--14.
\layout Bibliography
\paragraph_spacing single 
\bibitem {Viola}


\size footnotesize 
P.
 Viola and W.
 M.
 Wells, 
\begin_inset Quotes eld
\end_inset 

Alignment by maximization of mutual information,
\begin_inset Quotes erd
\end_inset 

 International Journal of Computer Vision, vol.
 24, pp.
 137--154, 1997.
\layout Bibliography
\paragraph_spacing single 
\bibitem {walker_corr}


\size footnotesize 
K.
 N.
 Walker, T.
 F.
 Cootes, and C.
 J.
 Taylor, 
\begin_inset Quotes eld
\end_inset 

Determining correspondences for statistical models of appearance,
\begin_inset Quotes erd
\end_inset 

 in Computer Vision - ECCV 2000, Pt I, Proceedings, vol.
 1842, Lecture Notes in Computer Science, 2000, pp.
 829--843.
\layout Bibliography
\paragraph_spacing single 
\bibitem {wang_stats}


\size footnotesize 
Y.
 Wang and L.
 H.
 Staib, 
\begin_inset Quotes eld
\end_inset 

Elastic model based non-rigid registration incorporating statistical shape
 information,
\begin_inset Quotes erd
\end_inset 

 presented at Medical Image Computing and Computer-Assisted Intervention,
 1998.
\layout Bibliography
\paragraph_spacing single 
\bibitem {wang}


\size footnotesize 
L.
 Wang, Y.
 Zhang, and J.
 Feng, ``On the euclidean distance of images,'' IEEE Trans.
 Pattern Anal.
 Machine Intell., vol.
 27, pp.
 1334--1339,
\layout Bibliography
\paragraph_spacing single 
\bibitem {Wang_reg}


\size footnotesize 
Y.
 Wang and L.
 H.
 Staib, 
\begin_inset Quotes eld
\end_inset 

Integrated approaches to non-rigid registration in medical images,
\begin_inset Quotes erd
\end_inset 

 presented at Workshop on Applications of Computer Vision, 1998.
\layout Bibliography
\paragraph_spacing single 
\bibitem {Warfield_non-rigid_atlas}


\size footnotesize 
S.
 K.
 Warfield, J.
 Rexilius, P.
 S.
 Huppi, T.
 E.
 Inder, E.
 G.
 Miller, W.
 M.
 Wells, III, G.
 P.
 Zientara, F.
 A.
 Jolesz, and R.
 Kikinis, 
\begin_inset Quotes eld
\end_inset 

An Entropy Measure to Assess Nonrigid Registration Algorithms for Statistical
 Atlas Construction,
\begin_inset Quotes erd
\end_inset 

 presented at Medical Image Computing and Computer-Assisted Intervention,
 2001.
\layout Bibliography
\paragraph_spacing single 
\bibitem {STPLE}


\size footnotesize 
Warfield SK, Zou KH, Wells WM.
 Simultaneous truth and performance level estimation (STAPLE): an algorithm
 for the validation of image segmentation.
 IEEE Trans Med Imaging.
 2004 Jul;23(7):903--21.
 
\layout Bibliography
\paragraph_spacing single 
\bibitem {West_reg}


\size footnotesize 
J.
 West, J.
 M.
 Fitzpatrick, M.
 Y.
 Wang, B.
 M.
 Dawant, J.
 Maurer, C.
 R., R.
 M.
 Kessler, R.
 J.
 Maciunas, C.
 Barillot, D.
 Lemoine, A.
 Collignon, F.
 Maes, P.
 Suetens, D.
 Vandermeulen, P.
 A.
 van den Elsen, S.
 Napel, T.
 S.
 Sumanaweera, B.
 Harkness, P.
 F.
 Hemler, D.
 L.
 G.
 Hill, D.
 J.
 Hawkes, C.
 Studholme, J.
 B.
 A.
 Maintz, M.
 A.
 Viergever, G.
 Malandain, X.
 Pennec, M.
 E.
 Noz, J.
 Maguire, G.
 Q., M.
 Pollack, C.
 A.
 Pelizzari, R.
 A.
 Robb, D.
 Hanson, and R.
 P.
 Woods, 
\begin_inset Quotes eld
\end_inset 

Comparison and evaluation of retrospective intermodality brain image registratio
n techniques,
\begin_inset Quotes erd
\end_inset 

 Journal of Computer Assisted Tomography, vol.
 21, pp.
 554--566, 1997.
\layout Bibliography
\paragraph_spacing single 
\bibitem {Xu_reg}


\size footnotesize 
M.
 Xu and W.
 L.
 Nowinski, 
\begin_inset Quotes eld
\end_inset 

Talairach-Tournoux Brain Atlas Registration Using a Metalforming Principle-Based
 Finite Element Method,
\begin_inset Quotes erd
\end_inset 

 Medical Image Analysis, vol.
 5, pp.
 271--279, 2001.
\layout Bibliography
\paragraph_spacing single 
\bibitem {Yam}


\size footnotesize 
C.
 Yam, M.
 S.
 Nixon, and J.
 N.
 Carter, 
\begin_inset Quotes eld
\end_inset 

Automated person recognition by walking and running via model-based approaches,
\begin_inset Quotes erd
\end_inset 

 Pattern Recognition, vol.
 37, 2004.
\layout Bibliography
\paragraph_spacing single 
\bibitem {key-31}


\size footnotesize 
L.
 Younes, "Computable Elastic Distances Between Shapes," SIAM Journal of
 Applied Mathematics, vol.
 58, pp.
 565 -- 586, 1998.
\layout Bibliography
\bibitem {Younes_reg}


\size footnotesize 
L.
 Younes, 
\begin_inset Quotes eld
\end_inset 

Deformations, Warping and Object Comparison: A Tutorial,
\begin_inset Quotes erd
\end_inset 

 2000.
\layout Bibliography
\paragraph_spacing single 
\bibitem {Zollei_2005}


\size footnotesize 
L.
 Zollei, E.
 Learned-Miller, E.
 Grimson, and W.
 Wells, ``Efficient population registration of 3D data,'' in Workshop on
 Computer Vision for Biomedical Image Applications: International Conference
 of Computer Vision (ICCV05), 2005.
\layout Bibliography
\paragraph_spacing single 
\bibitem {Zitova_2003}


\size footnotesize 
B.
 Zitova and J.
 Flusser, ``Image registration methods: A survey,'' Image and Vision Computing,
 vol.~21, pp.
 977--1000, 2003.
\layout Standard


\begin_inset Note
collapsed false

\layout Comment

Done: Add more e.g.
 Derek Hill, Carole and Cootes from 2004
\layout Comment

Done: Normalise structure of citations, especially later ones so that they
 are uniform
\layout Comment

Order by stage of appearance or alphabetically
\layout Comment

2006: REMOVE duplicates
\layout Standard


\size small 
\emph on 
Also see the on-line resources listed in Appendix 
\begin_inset LatexCommand \ref{cha:Primary-On-Line-Resources}

\end_inset 

 of this report.
\layout Standard
\align right 

\size footnotesize 
Document was compiled using LaTeX version 3.14159
\layout Standard

===ISBE Literature Survey===
\layout Standard

October notes from Palm
\layout Standard

1.
 Use many papers read already which are on my HDD
\layout Standard

2.
 Sonka...
\layout Standard

3.
 Medical Image registration, Joseph V.
 Hajnal, Derek L.G.
 Hill, David G.
 Hawkes
\layout Standard

4.
 Rhoderi's thesis
\layout Standard

5.
 Rhoderi's 2 papers
\layout Standard

6.
 Journals from October and September
\layout Standard

7.
 Machine Learning (CS643) notes
\layout Standard

8.
 98 AAM paper and later AAM papers
\layout Standard

9.
 Groupwise.pdf
\layout Standard
\paragraph_spacing single 

10.
 A criterion for model selection using MDL - Najmi, Olshen CCS 1997
\end_inset 


\the_end
